{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experiments.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yZNgMh0qN2DE",
        "v6pFr3l1FnEz",
        "y9hgxJ07T6Hh",
        "meUYHSOHs1FM",
        "K5sMX9xCM-xu",
        "Ki0vw_MxaM65",
        "BXflPoaKPIsV",
        "VRvmqr_7KNAX",
        "TtEUxFlJEY6Q",
        "HEFaa-G8_4xS"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toomasliiv/DDD2424Project/blob/master/experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnLOZhASlpYU",
        "colab_type": "code",
        "outputId": "243d0bb8-9f35-43c7-d2c7-77696e853dc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.optimizers\n",
        "import tensorflow.keras.losses\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "import json\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2D2bolj92Yv",
        "colab_type": "code",
        "outputId": "518cba76-8642-417c-a380-b875b393f57b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 40
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NHa8LqG1PPL",
        "colab_type": "text"
      },
      "source": [
        "## Import and check data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ2csDtHhwjh",
        "colab_type": "code",
        "outputId": "ac7c4bae-f835-42bd-8719-b209dfb45584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "# Mount drive to access files\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK1-jvEHkhkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Paths\n",
        "train_y_path = \"/content/drive/My Drive/DD2424Files/train_y.npz\"\n",
        "val_y_path   = \"/content/drive/My Drive/DD2424Files/val_y.npz\"\n",
        "test_y_path  = \"/content/drive/My Drive/DD2424Files/test_y.npz\"\n",
        "\n",
        "train_X_path = \"/content/drive/My Drive/DD2424Files/train_X.npz\"\n",
        "val_X_path   = \"/content/drive/My Drive/DD2424Files/val_X.npz\"\n",
        "test_X_path  = \"/content/drive/My Drive/DD2424Files/test_X.npz\"\n",
        "\n",
        "train_X_mfcc_path = \"/content/drive/My Drive/DD2424Files/train_X_mfcc.npz\"\n",
        "val_X_mfcc_path   = \"/content/drive/My Drive/DD2424Files/val_X_mfcc.npz\"\n",
        "test_X_mfcc_path  = \"/content/drive/My Drive/DD2424Files/test_X_mfcc.npz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz42DCwnlNSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import training and validation data\n",
        "train_y = np.load(train_y_path)['arr_0']\n",
        "train_y = tf.one_hot(train_y, 8)\n",
        "\n",
        "val_y = np.load(val_y_path)['arr_0']\n",
        "val_y = tf.one_hot(val_y, 8)\n",
        "\n",
        "train_X = tf.convert_to_tensor(np.expand_dims(np.load(train_X_path)['arr_0'], -1))\n",
        "val_X = tf.convert_to_tensor(np.expand_dims(np.load(val_X_path)['arr_0'], -1))\n",
        "#train_X_mfcc = np.load(train_X_mfcc_path)['arr_0']\n",
        "#val_X_mfcc = np.load(val_X_mfcc_path)['arr_0']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQL8X6LzdMUR",
        "colab_type": "code",
        "outputId": "81f14b34-b315-4deb-e805-514750c2d695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "# Check the data shape\n",
        "print(train_X.shape)\n",
        "print(val_X.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6397, 96, 1405, 1)\n",
            "(800, 96, 1405, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSBFwyOFOw1c",
        "colab_type": "code",
        "outputId": "beab49a3-99bf-478e-8dbf-784d4e2ffe17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 10708103227913581400, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 17509985430796352467\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 16780262774952405700\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 11150726272\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 3915873134385253483\n",
              " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Uli9KOIl66I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assert assumptions about data\n",
        "\n",
        "MEL_BINS   = 96\n",
        "TIME_STEPS = 1405\n",
        "\n",
        "def check_data(X, y):\n",
        "  assert len(y.shape) == 2\n",
        "  assert len(X.shape) == 4\n",
        "  assert y.shape[0] == X.shape[0]\n",
        "  assert X.shape[1] == MEL_BINS\n",
        "  assert X.shape[2] == TIME_STEPS\n",
        "  assert X.shape[3] == 1\n",
        "\n",
        "check_data(val_X, val_y)\n",
        "check_data(train_X, train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb8UYWuu1xMj",
        "colab_type": "text"
      },
      "source": [
        "## The model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwasJAxusnXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# All model definitions\n",
        "\n",
        "def get_mlp_model():\n",
        "\n",
        "  mlp_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    #tf.keras.layers.Dense(128, activation='relu'),\n",
        "    #tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(8)\n",
        "  ])\n",
        "  return mlp_model\n",
        "\n",
        "#-------------------------------------------------------\n",
        "\n",
        "def cnn1_model(hyperparams):\n",
        "  NUMBER_FILTERS_1 = hyperparams.get(\"number_filters_1\")\n",
        "  KERNEL_SIZE = hyperparams.get(\"kernel_size_1\")\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(NUMBER_FILTERS_1, KERNEL_SIZE, padding = 'same', input_shape = (96, 1405, 1)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(8)                             \n",
        "  ])\n",
        "  return model\n",
        "\n",
        "#-------------------------------------------------------\n",
        "def cnn_k1c2_model(hyperparams):\n",
        "  h = hyperparams\n",
        "\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Input layer\n",
        "  model.add(tf.keras.layers.InputLayer(input_shape = (96, 1405, 1)))\n",
        "\n",
        "  # Batch normalize\n",
        "  model.add(tf.keras.layers.BatchNormalization(axis = 1))\n",
        "\n",
        "  # Convolutional blocks\n",
        "  for i in range(len(h[\"number_filters\"])):\n",
        "    NUMBER_FILTERS = h[\"number_filters\"][i]\n",
        "    KERNEL_SIZE    = h[\"kernel_size\"][i]\n",
        "    POOLING_SIZE   = h[\"pooling_size\"][i]\n",
        "    DROP_OUT_SIZE  = h[\"dropout\"]\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(NUMBER_FILTERS, KERNEL_SIZE, padding = 'same'))\n",
        "    model.add(tf.keras.layers.BatchNormalization(axis = 3))\n",
        "    model.add(tf.keras.layers.Activation(\"elu\"))\n",
        "    model.add(tf.keras.layers.MaxPool2D(POOLING_SIZE))\n",
        "    model.add(tf.keras.layers.Dropout(DROP_OUT_SIZE))\n",
        "\n",
        "\n",
        "  # Classifier block\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  for el in h[\"hidden_layers\"]:\n",
        "    model.add(tf.keras.layers.Dense(el))\n",
        "    model.add(tf.keras.layers.Dropout(h[\"drop_out_hidden\"]))\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(8))\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eFYkHJrnPHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utility functions for saving outputs\n",
        "\n",
        "def plot_history(history, val_string, loss_string):\n",
        "  # Plot results\n",
        "  plt.figure(1)\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Acc')\n",
        "  plt.legend(['Accuracy', 'Validation accuracy'])\n",
        "  plt.title('Accuracy')\n",
        "  plt.ylim([0, 1])\n",
        "  plt.savefig(val_string, dpi = 300)\n",
        "  plt.close()\n",
        "\n",
        "  plt.figure(2)\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend(['Loss', 'Validation loss'])\n",
        "  plt.title('Loss')\n",
        "  plt.savefig(loss_string, dpi = 300)\n",
        "  plt.close()\n",
        "\n",
        "def filename():\n",
        "\treturn str(datetime.datetime.now()).replace(':','.')[2:19]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IoPP5XEA30h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run an experiment\n",
        "\n",
        "def run_experiment(model, model_string, hyperparams):\n",
        "\n",
        "  file_location = \"/content/drive/My Drive/DD2424Files/Results/\" + filename() + \"/\"\n",
        "  os.mkdir(file_location)\n",
        "\n",
        "  # Compile model\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=hyperparams.get(\"learning_rate\"), epsilon=hyperparams.get(\"epsilon\"))\n",
        "  loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True)\n",
        "  metrics = ['accuracy']\n",
        "\n",
        "  model.compile(optimizer = optimizer, loss = loss, metrics = metrics)\n",
        "\n",
        "  # Train model\n",
        "  BATCH_SIZE = hyperparams.get(\"batch_size\")\n",
        "  EPOCHS = hyperparams.get(\"epochs\")\n",
        "  tf.keras.backend.clear_session()\n",
        "\n",
        "  save_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "      file_location + \"models_\" + model_string, monitor='val_accuracy', verbose=0, save_best_only=True,\n",
        "      save_weights_only=False, mode='max', save_freq='epoch')\n",
        "\n",
        "  history = model.fit(train_X, train_y, batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "                          validation_data=(val_X, val_y), verbose=1, callbacks = [save_callback])\n",
        "\n",
        "  # Save stuff\n",
        "  plot_history(history, file_location + \"acc_\" + model_string + \".png\", file_location + \"loss_\" + model_string + \".png\")\n",
        "  json.dump(history.history, open(file_location + \"history_\" + model_string, 'w'))\n",
        "  json.dump(hyperparams, open(file_location + \"hyperparams_\" + model_string, 'w'))\n",
        "\n",
        "  return history\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og_nR0vZS74c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train student model\n",
        "\n",
        "def train_student_model(student_model, teacher_models, X_train, y_train, X_val, y_val, hyperparams, model_string):\n",
        "  tf.keras.backend.clear_session()\n",
        "  file_location=\"/content/drive/My Drive/DD2424Files/Results/\" + filename() + \"/\"\n",
        "  location_name = file_location + \"models_\" + model_string\n",
        "  metrics = ['accuracy']\n",
        "\n",
        "  # Train model\n",
        "  BATCH_SIZE = hyperparams.get(\"batch_size\")\n",
        "  EPOCHS = hyperparams.get(\"epochs\")\n",
        "  \n",
        "\n",
        "  save_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "      location_name, monitor='val_accuracy', verbose=0, save_best_only=True,\n",
        "      save_weights_only=False, mode='max', save_freq='epoch')\n",
        "  \n",
        "  y_train = teacher_models[0].predict(X_train)\n",
        "\n",
        "  for i in range(len(teacher_models)-1):\n",
        "    y_train += teacher_models[i+1].predict(X_train)\n",
        "\n",
        "  y_train /= len(teacher_models)\n",
        "\n",
        "  print(\"shape of y_s_train: {} \".format(y_train.shape))\n",
        "  student_model.compile(optimizer=\"adam\", loss=tf.keras.losses.MSE, metrics= [tf.keras.metrics.CategoricalCrossentropy(from_logits=True), 'accuracy'])\n",
        "  history = student_model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(X_val,y_val), verbose=1, callbacks = [save_callback])\n",
        "  \n",
        "  # Save stuff\n",
        "  plot_history(history, file_location + \"acc_\" + model_string + \".png\", file_location + \"loss_\" + model_string + \".png\")\n",
        "  json.dump(history.history, open(file_location + \"history_\" + model_string, 'w'))\n",
        "  json.dump(hyperparams, open(file_location + \"hyperparams_\" + model_string, 'w'))\n",
        "  \n",
        "  return location_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OiIX0jCPwtH",
        "colab_type": "text"
      },
      "source": [
        "## Student experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8th02z1XPszy",
        "colab_type": "code",
        "outputId": "e7fe70f9-e9cc-49e6-bad3-449d8273254d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Student Experiments\n",
        "\n",
        "# Set up teacher ensemble\n",
        "m = \"/models_cnn_k2c2_deep\"\n",
        "l = \"/content/drive/My Drive/DD2424Files/Results/\"\n",
        "\n",
        "def s(time):\n",
        "  return l + time + m\n",
        "\n",
        "location_strings = [s(\"20-05-12 20.02.37\"), \n",
        "                  s(\"20-05-12 19.45.54\"), \n",
        "                  s(\"20-05-12 19.28.35\"), \n",
        "                  s(\"20-05-12 19.05.12\"), \n",
        "                  s(\"20-05-12 16.31.06\"), \n",
        "                  s(\"20-05-12 18.28.17\")]\n",
        "\n",
        "teacher_models = [None, None, None, None, None]\n",
        "\n",
        "for i in range(5):\n",
        "  teacher_models[i] = tf.keras.models.load_model(location_strings[i])\n",
        "'''\n",
        "# 0 layer student\n",
        "\n",
        "params = {1000000: []}\n",
        "dropouts = {1000000: 0.2}\n",
        "\n",
        "for num in [1000000]:\n",
        "\n",
        "  hyperparams = {\"number_filters\" : params[num],\n",
        "                \"number_params\" : num,\n",
        "                \"kernel_size\" : [],\n",
        "                \"pooling_size\" : [],\n",
        "                \"hidden_layers\": [],\n",
        "                \"epsilon\": 0.01, \n",
        "                \"learning_rate\": 0.01, \n",
        "                \"batch_size\": 32, \n",
        "                \"epochs\": 50,\n",
        "                \"dropout\" : dropouts[num],\n",
        "                \"drop_out_hidden\" : 0\n",
        "                }\n",
        "\n",
        "  model_string = \"cnn_k2c2_0layerstudent\"\n",
        "  student_model = cnn_k1c2_model(hyperparams)\n",
        "\n",
        "  locationString = train_student_model(student_model, teacher_models, train_X, train_y, val_X, val_y, hyperparams, model_string)\n",
        "  print(model.summary())\n",
        "  print(\"location: \" + locationString)\n",
        "\n",
        "\n",
        "# 1 layer student\n",
        "params = {135000: [1], 270000: [2]}\n",
        "dropouts = {135000: 0.2, 270000: 0.4}\n",
        "\n",
        "for num in [135000, 270000]:\n",
        "\n",
        "  hyperparams = {\"number_filters\" : params[num],\n",
        "                \"number_params\" : num,\n",
        "                \"kernel_size\" : [(3, 3)],\n",
        "                \"pooling_size\" : [(2, 4)],\n",
        "                \"hidden_layers\": [],\n",
        "                \"epsilon\": 0.01, \n",
        "                \"learning_rate\": 0.01, \n",
        "                \"batch_size\": 32, \n",
        "                \"epochs\": 50,\n",
        "                \"dropout\": dropouts[num],\n",
        "                \"drop_out_hidden\": 0\n",
        "                }\n",
        "  \n",
        "  model_string = \"cnn_k2c2_1layerstudent\"\n",
        "  student_model = cnn_k1c2_model(hyperparams)\n",
        "\n",
        "  locationString = train_student_model(student_model, teacher_models, train_X, train_y, val_X, val_y, hyperparams, model_string)\n",
        "  print(student_model.summary())\n",
        "  print(\"location: \" + locationString)\n",
        "\n",
        "# 4 layer student\n",
        "\n",
        "params = {2000: [4, 6, 6, 9], 4000: [6, 10, 10, 14], 10000:[10, 16, 16, 28], 50000:\n",
        "          [20, 41, 41, 63], 100000: [29, 59, 59, 90], 250000: [48, 95, 95, 142]}\n",
        "dropouts = {2000: 0.1, 4000: 0.1, 10000: 0.1, 50000: 0.2, 100000: 0.2, 250000: 0.4}\n",
        "\n",
        "for num in [2000, 4000, 10000, 50000, 100000, 250000]:\n",
        "\n",
        "  hyperparams = {\"number_filters\" : params[num],\n",
        "                \"number_params\" : num,\n",
        "                \"kernel_size\" : [(3, 3), (3,3), (3,3), (3,3)],\n",
        "                \"pooling_size\" : [(2,4), (2,4), (3,5), (3,5)],\n",
        "                \"hidden_layers\": [],\n",
        "                \"epsilon\": 0.01, \n",
        "                \"learning_rate\": 0.01, \n",
        "                \"batch_size\": 32, \n",
        "                \"epochs\": 50,\n",
        "                \"dropout\": dropouts[num],\n",
        "                \"drop_out_hidden\": 0\n",
        "                }\n",
        "\n",
        "  model_string = \"cnn_k2c2_4layerstudent\"\n",
        "  student_model = cnn_k1c2_model(hyperparams)\n",
        "\n",
        "  locationString = train_student_model(student_model, teacher_models, train_X, train_y, val_X, val_y, hyperparams, model_string)\n",
        "  print(student_model.summary())\n",
        "  print(\"location: \" + locationString)\n",
        "'''\n",
        "# 5 layer student\n",
        "\n",
        "params = params = {2000: [3, 5, 5, 8, 10], 4000: [4, 8, 8, 12, 16], 10000:[8, 12, 12, 20, 24],\n",
        "                   50000:[15, 30, 30, 45, 60], 100000: [20, 41, 41, 62, 83], 250000: [33, 66, 66, 100, 133]}\n",
        "dropouts = {2000: 0.1, 4000: 0.1, 10000: 0.1, 50000: 0.2, 100000: 0.2, 250000: 0.4}\n",
        "\n",
        "for num in [250000]:\n",
        "\n",
        "  hyperparams = {\"number_filters\" : params[num],\n",
        "                \"number_params\" : num,\n",
        "                \"kernel_size\" : [(3, 3), (3,3), (3,3), (3,3),(3,3)],\n",
        "                \"pooling_size\" : [(2,4), (2,4), (2,4), (3,5), (4,4)],\n",
        "                \"hidden_layers\": [],\n",
        "                \"epsilon\": 0.01, \n",
        "                \"learning_rate\": 0.01, \n",
        "                \"batch_size\": 32, \n",
        "                \"epochs\": 50,\n",
        "                \"dropout\": dropouts[num],\n",
        "                \"drop_out_hidden\": 0\n",
        "                }\n",
        "\n",
        "  model_string = \"cnn_k2c2_5layerstudent\"\n",
        "  student_model = cnn_k1c2_model(hyperparams)\n",
        "\n",
        "  locationString = train_student_model(student_model, teacher_models, train_X, train_y, val_X, val_y, hyperparams, model_string)\n",
        "  print(student_model.summary())\n",
        "  print(\"location: \" + locationString)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of y_s_train: (6397, 8) \n",
            "Epoch 1/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 3.9504 - categorical_crossentropy: -9.7773 - accuracy: 0.2323WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-14 22.05.53/models_cnn_k2c2_5layerstudent/assets\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 3.9504 - categorical_crossentropy: -9.7773 - accuracy: 0.2323 - val_loss: 1.3284 - val_categorical_crossentropy: 2.1578 - val_accuracy: 0.2163\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 2.2842 - categorical_crossentropy: -14.7839 - accuracy: 0.3570INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-14 22.05.53/models_cnn_k2c2_5layerstudent/assets\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 2.2842 - categorical_crossentropy: -14.7839 - accuracy: 0.3570 - val_loss: 1.7178 - val_categorical_crossentropy: 2.0981 - val_accuracy: 0.2362\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.8289 - categorical_crossentropy: -16.7632 - accuracy: 0.4324INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-14 22.05.53/models_cnn_k2c2_5layerstudent/assets\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 1.8289 - categorical_crossentropy: -16.7632 - accuracy: 0.4324 - val_loss: 2.6134 - val_categorical_crossentropy: 2.0709 - val_accuracy: 0.2450\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.5295 - categorical_crossentropy: -18.6745 - accuracy: 0.4882INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-14 22.05.53/models_cnn_k2c2_5layerstudent/assets\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 1.5295 - categorical_crossentropy: -18.6745 - accuracy: 0.4882 - val_loss: 3.0604 - val_categorical_crossentropy: 1.9384 - val_accuracy: 0.3175\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.2238 - categorical_crossentropy: -20.5300 - accuracy: 0.5543INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-14 22.05.53/models_cnn_k2c2_5layerstudent/assets\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 1.2238 - categorical_crossentropy: -20.5300 - accuracy: 0.5543 - val_loss: 2.2840 - val_categorical_crossentropy: 1.5830 - val_accuracy: 0.4412\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.0468 - categorical_crossentropy: -21.7220 - accuracy: 0.6104INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-14 22.05.53/models_cnn_k2c2_5layerstudent/assets\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 1.0468 - categorical_crossentropy: -21.7220 - accuracy: 0.6104 - val_loss: 2.2888 - val_categorical_crossentropy: 1.4882 - val_accuracy: 0.4787\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.9225 - categorical_crossentropy: -22.6038 - accuracy: 0.6411 - val_loss: 2.5338 - val_categorical_crossentropy: 1.5300 - val_accuracy: 0.4750\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.8311 - categorical_crossentropy: -23.2239 - accuracy: 0.6619 - val_loss: 2.9994 - val_categorical_crossentropy: 1.5544 - val_accuracy: 0.4487\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 18s 92ms/step - loss: 0.7637 - categorical_crossentropy: -23.6371 - accuracy: 0.6825 - val_loss: 2.6656 - val_categorical_crossentropy: 1.4905 - val_accuracy: 0.4663\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.7215 - categorical_crossentropy: -23.9593 - accuracy: 0.6950INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-14 22.05.53/models_cnn_k2c2_5layerstudent/assets\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.7215 - categorical_crossentropy: -23.9593 - accuracy: 0.6950 - val_loss: 3.0756 - val_categorical_crossentropy: 1.4220 - val_accuracy: 0.5175\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6818 - categorical_crossentropy: -24.2183 - accuracy: 0.7063INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-14 22.05.53/models_cnn_k2c2_5layerstudent/assets\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.6818 - categorical_crossentropy: -24.2183 - accuracy: 0.7063 - val_loss: 2.6505 - val_categorical_crossentropy: 1.3629 - val_accuracy: 0.5412\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 18s 92ms/step - loss: 0.6337 - categorical_crossentropy: -24.5300 - accuracy: 0.7136 - val_loss: 2.6973 - val_categorical_crossentropy: 1.3708 - val_accuracy: 0.5337\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6142 - categorical_crossentropy: -24.7045 - accuracy: 0.7253INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-14 22.05.53/models_cnn_k2c2_5layerstudent/assets\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.6142 - categorical_crossentropy: -24.7045 - accuracy: 0.7253 - val_loss: 2.5957 - val_categorical_crossentropy: 1.3081 - val_accuracy: 0.5663\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.5817 - categorical_crossentropy: -24.8963 - accuracy: 0.7338 - val_loss: 2.8819 - val_categorical_crossentropy: 1.3597 - val_accuracy: 0.5300\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 18s 92ms/step - loss: 0.5702 - categorical_crossentropy: -25.0160 - accuracy: 0.7322 - val_loss: 3.2790 - val_categorical_crossentropy: 1.4248 - val_accuracy: 0.5175\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.5324 - categorical_crossentropy: -25.2855 - accuracy: 0.7408 - val_loss: 2.9953 - val_categorical_crossentropy: 1.3780 - val_accuracy: 0.5425\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5182 - categorical_crossentropy: -25.3446 - accuracy: 0.7407INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-14 22.05.53/models_cnn_k2c2_5layerstudent/assets\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.5182 - categorical_crossentropy: -25.3446 - accuracy: 0.7407 - val_loss: 2.8502 - val_categorical_crossentropy: 1.3448 - val_accuracy: 0.5713\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 18s 92ms/step - loss: 0.4997 - categorical_crossentropy: -25.5601 - accuracy: 0.7558 - val_loss: 2.8355 - val_categorical_crossentropy: 1.3178 - val_accuracy: 0.5587\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.4954 - categorical_crossentropy: -25.5286 - accuracy: 0.7474INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-14 22.05.53/models_cnn_k2c2_5layerstudent/assets\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.4954 - categorical_crossentropy: -25.5286 - accuracy: 0.7474 - val_loss: 3.0397 - val_categorical_crossentropy: 1.2759 - val_accuracy: 0.5788\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.4799 - categorical_crossentropy: -25.6394 - accuracy: 0.7655INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-14 22.05.53/models_cnn_k2c2_5layerstudent/assets\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.4799 - categorical_crossentropy: -25.6394 - accuracy: 0.7655 - val_loss: 2.8889 - val_categorical_crossentropy: 1.2685 - val_accuracy: 0.5825\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.4686 - categorical_crossentropy: -25.7711 - accuracy: 0.7710INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-14 22.05.53/models_cnn_k2c2_5layerstudent/assets\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.4686 - categorical_crossentropy: -25.7711 - accuracy: 0.7710 - val_loss: 2.8383 - val_categorical_crossentropy: 1.2559 - val_accuracy: 0.5925\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.4693 - categorical_crossentropy: -25.7307 - accuracy: 0.7705 - val_loss: 3.0560 - val_categorical_crossentropy: 1.3295 - val_accuracy: 0.5575\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.4595 - categorical_crossentropy: -25.8146 - accuracy: 0.7758INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-14 22.05.53/models_cnn_k2c2_5layerstudent/assets\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.4595 - categorical_crossentropy: -25.8146 - accuracy: 0.7758 - val_loss: 2.7245 - val_categorical_crossentropy: 1.2268 - val_accuracy: 0.5962\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 18s 92ms/step - loss: 0.4461 - categorical_crossentropy: -25.8861 - accuracy: 0.7782 - val_loss: 2.8990 - val_categorical_crossentropy: 1.2600 - val_accuracy: 0.5888\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.4398 - categorical_crossentropy: -26.0047 - accuracy: 0.7751 - val_loss: 2.9413 - val_categorical_crossentropy: 1.2618 - val_accuracy: 0.5775\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.4234 - categorical_crossentropy: -26.1026 - accuracy: 0.7810INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-14 22.05.53/models_cnn_k2c2_5layerstudent/assets\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.4234 - categorical_crossentropy: -26.1026 - accuracy: 0.7810 - val_loss: 2.9963 - val_categorical_crossentropy: 1.2239 - val_accuracy: 0.6037\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.4243 - categorical_crossentropy: -26.0533 - accuracy: 0.7908 - val_loss: 3.1122 - val_categorical_crossentropy: 1.2528 - val_accuracy: 0.5913\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 18s 92ms/step - loss: 0.4189 - categorical_crossentropy: -26.1110 - accuracy: 0.7891 - val_loss: 3.5062 - val_categorical_crossentropy: 1.2961 - val_accuracy: 0.5738\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.4061 - categorical_crossentropy: -26.2888 - accuracy: 0.7907 - val_loss: 3.0115 - val_categorical_crossentropy: 1.2543 - val_accuracy: 0.5950\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.4067 - categorical_crossentropy: -26.2232 - accuracy: 0.7885 - val_loss: 3.2149 - val_categorical_crossentropy: 1.2853 - val_accuracy: 0.5650\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.4027 - categorical_crossentropy: -26.2770 - accuracy: 0.7904 - val_loss: 3.1996 - val_categorical_crossentropy: 1.2288 - val_accuracy: 0.6000\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 18s 92ms/step - loss: 0.3819 - categorical_crossentropy: -26.3971 - accuracy: 0.7994 - val_loss: 3.1479 - val_categorical_crossentropy: 1.2300 - val_accuracy: 0.6037\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.3952 - categorical_crossentropy: -26.3454 - accuracy: 0.7918INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-14 22.05.53/models_cnn_k2c2_5layerstudent/assets\n",
            "200/200 [==============================] - 22s 111ms/step - loss: 0.3952 - categorical_crossentropy: -26.3454 - accuracy: 0.7918 - val_loss: 3.4530 - val_categorical_crossentropy: 1.2314 - val_accuracy: 0.6087\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.3919 - categorical_crossentropy: -26.3623 - accuracy: 0.7949 - val_loss: 3.1169 - val_categorical_crossentropy: 1.2238 - val_accuracy: 0.6087\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.3793 - categorical_crossentropy: -26.4270 - accuracy: 0.7997 - val_loss: 3.1524 - val_categorical_crossentropy: 1.2158 - val_accuracy: 0.6075\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.3804 - categorical_crossentropy: -26.4808 - accuracy: 0.8093 - val_loss: 3.1822 - val_categorical_crossentropy: 1.2262 - val_accuracy: 0.6012\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.3671 - categorical_crossentropy: -26.5310 - accuracy: 0.7990INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-14 22.05.53/models_cnn_k2c2_5layerstudent/assets\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.3671 - categorical_crossentropy: -26.5310 - accuracy: 0.7990 - val_loss: 3.1575 - val_categorical_crossentropy: 1.1996 - val_accuracy: 0.6263\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.3688 - categorical_crossentropy: -26.5549 - accuracy: 0.7990 - val_loss: 3.1859 - val_categorical_crossentropy: 1.2337 - val_accuracy: 0.6075\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.3762 - categorical_crossentropy: -26.4663 - accuracy: 0.8018 - val_loss: 3.2832 - val_categorical_crossentropy: 1.2443 - val_accuracy: 0.5913\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.3612 - categorical_crossentropy: -26.6602 - accuracy: 0.7988 - val_loss: 3.1419 - val_categorical_crossentropy: 1.2037 - val_accuracy: 0.6100\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.3606 - categorical_crossentropy: -26.5819 - accuracy: 0.8030 - val_loss: 3.0632 - val_categorical_crossentropy: 1.2015 - val_accuracy: 0.6212\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 18s 92ms/step - loss: 0.3543 - categorical_crossentropy: -26.6752 - accuracy: 0.8115 - val_loss: 3.1594 - val_categorical_crossentropy: 1.2098 - val_accuracy: 0.6062\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.3643 - categorical_crossentropy: -26.5755 - accuracy: 0.8046 - val_loss: 3.3861 - val_categorical_crossentropy: 1.2131 - val_accuracy: 0.6200\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.3508 - categorical_crossentropy: -26.6769 - accuracy: 0.8099 - val_loss: 3.4502 - val_categorical_crossentropy: 1.2289 - val_accuracy: 0.6075\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 18s 92ms/step - loss: 0.3563 - categorical_crossentropy: -26.6714 - accuracy: 0.8127 - val_loss: 3.1997 - val_categorical_crossentropy: 1.2269 - val_accuracy: 0.5962\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.3536 - categorical_crossentropy: -26.6842 - accuracy: 0.8090 - val_loss: 3.5452 - val_categorical_crossentropy: 1.2471 - val_accuracy: 0.5975\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.3552 - categorical_crossentropy: -26.6799 - accuracy: 0.8048 - val_loss: 3.0485 - val_categorical_crossentropy: 1.2441 - val_accuracy: 0.5838\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.3466 - categorical_crossentropy: -26.7117 - accuracy: 0.8137 - val_loss: 3.1607 - val_categorical_crossentropy: 1.2247 - val_accuracy: 0.6100\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.3383 - categorical_crossentropy: -26.8320 - accuracy: 0.8157 - val_loss: 2.8517 - val_categorical_crossentropy: 1.1970 - val_accuracy: 0.6187\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.3363 - categorical_crossentropy: -26.7709 - accuracy: 0.8194 - val_loss: 3.2324 - val_categorical_crossentropy: 1.2126 - val_accuracy: 0.6050\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 33)      330       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 33)      132       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 33)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 48, 351, 33)       0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 48, 351, 33)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 351, 66)       19668     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 351, 66)       264       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 48, 351, 66)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 87, 66)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 87, 66)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 87, 66)        39270     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 87, 66)        264       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 87, 66)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 21, 66)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 12, 21, 66)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 12, 21, 100)       59500     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 12, 21, 100)       400       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 12, 21, 100)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 100)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4, 4, 100)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 4, 4, 133)         119833    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 4, 4, 133)         532       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 4, 4, 133)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 133)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1, 1, 133)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 133)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 1072      \n",
            "=================================================================\n",
            "Total params: 241,649\n",
            "Trainable params: 240,661\n",
            "Non-trainable params: 988\n",
            "_________________________________________________________________\n",
            "None\n",
            "location: /content/drive/My Drive/DD2424Files/Results/20-05-14 22.05.53/models_cnn_k2c2_5layerstudent\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZNgMh0qN2DE",
        "colab_type": "text"
      },
      "source": [
        "## Student experiment 1 layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cMJSN-MN0Kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Student experiment 1 layer\n",
        "# Deep k2c2\n",
        "\n",
        "# Teacher ensamble\n",
        "  \n",
        "m = \"/models_cnn_k2c2_deep\"\n",
        "l = \"/content/drive/My Drive/DD2424Files/Results/\"\n",
        "\n",
        "def s(time):\n",
        "  return l + time + m\n",
        "\n",
        "location_strings = [s(\"20-05-12 20.02.37\"), \n",
        "                  s(\"20-05-12 19.45.54\"), \n",
        "                  s(\"20-05-12 19.28.35\"), \n",
        "                  s(\"20-05-12 19.05.12\"), \n",
        "                  s(\"20-05-12 16.31.06\"), \n",
        "                  s(\"20-05-12 18.28.17\")]\n",
        "\n",
        "teacher_models = [None, None, None, None, None]\n",
        "\n",
        "for i in range(5):\n",
        "  teacher_models[i] = tf.keras.models.load_model(location_strings[i])\n",
        "\n",
        "# Student model\n",
        "\n",
        "params = {135000: [1], 270000: [2]}\n",
        "dropouts = {135000: [0.2], 270000: [0.4]}\n",
        "\n",
        "for num in [135000, 270000]:\n",
        "\n",
        "  hyperparams = {\"number_filters\" : params[num],\n",
        "                \"number_params\" : num,\n",
        "                \"kernel_size\" : [(3, 3)],\n",
        "                \"pooling_size\" : [(2,4)],\n",
        "                \"hidden_layers\": [],\n",
        "                \"epsilon\": 0.01, \n",
        "                \"learning_rate\": 0.01, \n",
        "                \"batch_size\": 32, \n",
        "                \"epochs\": 50,\n",
        "                \"dropout\" : dropouts[i],\n",
        "                \"drop_out_hidden\" : 0\n",
        "                }\n",
        "  \n",
        "  model_string = \"cnn_k2c2_1layerstudent\"\n",
        "  student_model = cnn_k1c2_model(hyperparams)\n",
        "\n",
        "  model = train_student_model(student_model, teacher_models, train_X, train_y, val_X, val_y, hyperparams, model_string)\n",
        "  model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6pFr3l1FnEz",
        "colab_type": "text"
      },
      "source": [
        "##Student Experiment 2 layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-zIWPhSDZh0",
        "colab_type": "code",
        "outputId": "7c49ee1a-fc68-4bab-e5a8-63b21d957503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "source": [
        "# Student experiment 2 layer\n",
        "# Deep k2c2\n",
        "\n",
        "# Teacher ensamble\n",
        "  \n",
        "m = \"/models_cnn_k2c2_deep\"\n",
        "l = \"/content/drive/My Drive/DD2424Files/Results/\"\n",
        "\n",
        "def s(time):\n",
        "  return l + time + m\n",
        "\n",
        "location_strings = [s(\"20-05-12 20.02.37\"), \n",
        "                  s(\"20-05-12 19.45.54\"), \n",
        "                  s(\"20-05-12 19.28.35\"), \n",
        "                  s(\"20-05-12 19.05.12\"), \n",
        "                  s(\"20-05-12 16.31.06\"), \n",
        "                  s(\"20-05-12 18.28.17\")]\n",
        "\n",
        "teacher_models = [None, None, None, None, None]\n",
        "\n",
        "for i in range(5):\n",
        "  teacher_models[i] = tf.keras.models.load_model(location_strings[i])\n",
        "\n",
        "# Student model\n",
        "params = {17000: [1, 1], 50000: [2, 3], 100000: [3, 6], 250000: [8, 15]}\n",
        "dropouts = {17000: 0.1, 50000: 0.2, 100000: 0.2, 250000: 0.4}\n",
        "\n",
        "for num in [17000, 50000, 250000]:\n",
        "\n",
        "  hyperparams = {\"number_filters\" : params[num],\n",
        "                \"number_params\" : num,\n",
        "                \"kernel_size\" : [(3, 3), (3,3)],\n",
        "                \"pooling_size\" : [(2,4), (2,4)],\n",
        "                \"hidden_layers\": [],\n",
        "                \"epsilon\": 0.01, \n",
        "                \"learning_rate\": 0.01, \n",
        "                \"batch_size\": 32, \n",
        "                \"epochs\": 100,\n",
        "                \"dropout\" : dropouts[num],\n",
        "                \"drop_out_hidden\" : 0\n",
        "                }\n",
        "  \n",
        "  model_string = \"cnn_k2c2_2layer\"\n",
        "  student_model = cnn_k1c2_model(hyperparams)\n",
        "\n",
        "  model = train_student_model(student_model, teacher_models, train_X, train_y, val_X, val_y, hyperparams, model_string)\n",
        "  model.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of y_s_train: (6397, 8) \n",
            "Epoch 1/100\n",
            "199/200 [============================>.] - ETA: 0s - loss: 3.2853 - categorical_crossentropy: -8.5900 - accuracy: 0.2307INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-14 18.14.03/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 3.2821 - categorical_crossentropy: -8.5894 - accuracy: 0.2310 - val_loss: 1.6654 - val_categorical_crossentropy: 1.8901 - val_accuracy: 0.2887\n",
            "Epoch 2/100\n",
            "199/200 [============================>.] - ETA: 0s - loss: 2.4214 - categorical_crossentropy: -12.7105 - accuracy: 0.3642INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-14 18.14.03/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 9s 46ms/step - loss: 2.4198 - categorical_crossentropy: -12.7186 - accuracy: 0.3645 - val_loss: 1.9953 - val_categorical_crossentropy: 1.7996 - val_accuracy: 0.3587\n",
            "Epoch 3/100\n",
            "199/200 [============================>.] - ETA: 0s - loss: 2.0681 - categorical_crossentropy: -13.8746 - accuracy: 0.4144"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-3d16a1eda75a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0mstudent_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_k1c2_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_student_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-c2ae4ff09d58>\u001b[0m in \u001b[0;36mtrain_student_model\u001b[0;34m(student_model, teacher_models, X_train, y_train, X_val, y_val, hyperparams, model_string)\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shape of y_s_train: {} \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mstudent_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msave_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;31m# Save stuff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    874\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1175\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       \u001b[0;31m# For multi-worker training, back up the weights and current training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1212\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \"\"\"\n\u001b[1;32m   1051\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 1052\u001b[0;31m                     signatures, options)\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0;32m--> 138\u001b[0;31m                           signatures, options)\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# we use the default replica context here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_default_replica_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m       \u001b[0msave_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m   _, exported_graph, object_saver, asset_info = _build_meta_graph(\n\u001b[0;32m--> 951\u001b[0;31m       obj, export_dir, signatures, options, meta_graph_def)\n\u001b[0m\u001b[1;32m    952\u001b[0m   \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model_schema_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_SCHEMA_VERSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, export_dir, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   object_graph_proto = _serialize_object_graph(saveable_view,\n\u001b[0;32m-> 1037\u001b[0;31m                                                asset_info.asset_index)\n\u001b[0m\u001b[1;32m   1038\u001b[0m   \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_graph_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_serialize_object_graph\u001b[0;34m(saveable_view, asset_file_def_index)\u001b[0m\n\u001b[1;32m    695\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_proto\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveable_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     _write_object_proto(obj, obj_proto, asset_file_def_index,\n\u001b[0;32m--> 697\u001b[0;31m                         saveable_view.function_name_map)\n\u001b[0m\u001b[1;32m    698\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_write_object_proto\u001b[0;34m(obj, proto, asset_file_def_index, function_name_map)\u001b[0m\n\u001b[1;32m    717\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdef_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m     proto.function.CopyFrom(function_serialization.serialize_function(\n\u001b[0;32m--> 719\u001b[0;31m         obj, function_name_map))\n\u001b[0m\u001b[1;32m    720\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConcreteFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     proto.bare_concrete_function.CopyFrom(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/function_serialization.py\u001b[0m in \u001b[0;36mserialize_function\u001b[0;34m(function, name_map)\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_spec_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mall_concrete_functions\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m       \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_all_concrete_functions_for_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mconcrete_function\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_concrete_functions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     proto.concrete_functions.append(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_list_all_concrete_functions_for_serialization\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0mconcrete_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseen_signatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m       \u001b[0mconcrete_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayerCall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    957\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mhas\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0myet\u001b[0m \u001b[0mbeen\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0mconcrete\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m     \"\"\"\n\u001b[0;32m--> 959\u001b[0;31m     \u001b[0mconcrete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m     \u001b[0mconcrete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    875\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       concrete = self._stateful_fn._get_concrete_function_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 877\u001b[0;31m           *args, **kwargs)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2507\u001b[0m       \u001b[0mnum_positional\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2508\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2509\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcaptured\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2510\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2511\u001b[0m         \u001b[0mnum_positional\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/object_identity.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooJ56Y45wVph",
        "colab_type": "text"
      },
      "source": [
        "## Student experiment 3 layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXf5btCowZzk",
        "colab_type": "code",
        "outputId": "48d6d1cf-2e51-4d50-aa53-3b5ff1756326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Student experiment 3 layer\n",
        "\n",
        "# Teacher ensamble\n",
        "  \n",
        "m = \"/models_cnn_k2c2_deep\"\n",
        "l = \"/content/drive/My Drive/DD2424Files/Results/\"\n",
        "\n",
        "def s(time):\n",
        "  return l + time + m\n",
        "\n",
        "location_strings = [s(\"20-05-12 20.02.37\"), \n",
        "                  s(\"20-05-12 19.45.54\"), \n",
        "                  s(\"20-05-12 19.28.35\"), \n",
        "                  s(\"20-05-12 19.05.12\"), \n",
        "                  s(\"20-05-12 16.31.06\"), \n",
        "                  s(\"20-05-12 18.28.17\")]\n",
        "\n",
        "teacher_models = [None, None, None, None, None]\n",
        "\n",
        "for i in range(5):\n",
        "  teacher_models[i] = tf.keras.models.load_model(location_strings[i])\n",
        "\n",
        "# Student model\n",
        "params = {2000: [1,1,2], 4000: [2, 3, 3], 10000:[5, 8, 8], 50000:[16, 32, 32], 100000: [27, 54, 54], 250000: [51, 101, 101]}\n",
        "dropouts = {2000: 0.1, 4000: 0.1, 10000: 0.1, 50000: 0.2, 100000: 0.2, 250000: 0.4}\n",
        "\n",
        "for num in [2000, 4000, 10000, 50000, 100000, 250000]:\n",
        "\n",
        "  hyperparams = {\"number_filters\" : params[num],\n",
        "                \"number_params\" : num,\n",
        "                \"kernel_size\" : [(3, 3), (3,3), (3,3)],\n",
        "                \"pooling_size\" : [(2,4), (2,4), (3,5)],\n",
        "                \"hidden_layers\": [],\n",
        "                \"epsilon\": 0.01, \n",
        "                \"learning_rate\": 0.01, \n",
        "                \"batch_size\": 32, \n",
        "                \"epochs\": 100,\n",
        "                \"dropout\" : dropouts[num],\n",
        "                \"drop_out_hidden\" : 0\n",
        "                }\n",
        "\n",
        "\n",
        "  model_string = \"cnn_k2c2_3layer_student\"\n",
        "  student_model = cnn_k1c2_model(hyperparams)\n",
        "\n",
        "  location_string = train_student_model(student_model, teacher_models, train_X, train_y, val_X, val_y, hyperparams, model_string)\n",
        "  print(location_string)\n",
        "  student_model.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of y_s_train: (6397, 8) \n",
            "Epoch 1/100\n",
            "199/200 [============================>.] - ETA: 0s - loss: 3.9060 - categorical_crossentropy: -6.2667 - accuracy: 0.1716INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.08.37/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 3.9026 - categorical_crossentropy: -6.2773 - accuracy: 0.1723 - val_loss: 0.7223 - val_categorical_crossentropy: 2.0589 - val_accuracy: 0.2025\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 2.9385 - categorical_crossentropy: -8.0998 - accuracy: 0.2246INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.08.37/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 14s 70ms/step - loss: 2.9385 - categorical_crossentropy: -8.0998 - accuracy: 0.2246 - val_loss: 1.0010 - val_categorical_crossentropy: 1.9928 - val_accuracy: 0.2300\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 2.6680 - categorical_crossentropy: -9.1604 - accuracy: 0.2676INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.08.37/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 14s 70ms/step - loss: 2.6680 - categorical_crossentropy: -9.1604 - accuracy: 0.2676 - val_loss: 1.0426 - val_categorical_crossentropy: 1.9562 - val_accuracy: 0.2475\n",
            "Epoch 4/100\n",
            "199/200 [============================>.] - ETA: 0s - loss: 2.4984 - categorical_crossentropy: -9.9529 - accuracy: 0.2968INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.08.37/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 14s 71ms/step - loss: 2.5011 - categorical_crossentropy: -9.9545 - accuracy: 0.2967 - val_loss: 0.9486 - val_categorical_crossentropy: 1.9091 - val_accuracy: 0.2713\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 2.3862 - categorical_crossentropy: -10.6862 - accuracy: 0.3250INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.08.37/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 2.3862 - categorical_crossentropy: -10.6862 - accuracy: 0.3250 - val_loss: 1.0823 - val_categorical_crossentropy: 1.8841 - val_accuracy: 0.2725\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 2.2895 - categorical_crossentropy: -11.2286 - accuracy: 0.3478INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.08.37/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 2.2895 - categorical_crossentropy: -11.2286 - accuracy: 0.3478 - val_loss: 1.2269 - val_categorical_crossentropy: 1.8969 - val_accuracy: 0.3038\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 2.1884 - categorical_crossentropy: -11.9521 - accuracy: 0.3794INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.08.37/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 14s 71ms/step - loss: 2.1884 - categorical_crossentropy: -11.9521 - accuracy: 0.3794 - val_loss: 1.0154 - val_categorical_crossentropy: 1.8429 - val_accuracy: 0.3237\n",
            "Epoch 8/100\n",
            "199/200 [============================>.] - ETA: 0s - loss: 2.0946 - categorical_crossentropy: -12.5491 - accuracy: 0.3971INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.08.37/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 14s 71ms/step - loss: 2.0958 - categorical_crossentropy: -12.5347 - accuracy: 0.3966 - val_loss: 1.2442 - val_categorical_crossentropy: 1.8485 - val_accuracy: 0.3288\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 2.0085 - categorical_crossentropy: -13.1556 - accuracy: 0.4293 - val_loss: 1.7264 - val_categorical_crossentropy: 1.8914 - val_accuracy: 0.3288\n",
            "Epoch 10/100\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.9208 - categorical_crossentropy: -13.8788 - accuracy: 0.4540INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.08.37/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 1.9185 - categorical_crossentropy: -13.9011 - accuracy: 0.4544 - val_loss: 1.6845 - val_categorical_crossentropy: 1.8413 - val_accuracy: 0.3525\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 1.8478 - categorical_crossentropy: -14.4814 - accuracy: 0.4630 - val_loss: 1.7908 - val_categorical_crossentropy: 1.8434 - val_accuracy: 0.3438\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 1.8010 - categorical_crossentropy: -14.8658 - accuracy: 0.4807 - val_loss: 1.8641 - val_categorical_crossentropy: 1.8403 - val_accuracy: 0.3388\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.7502 - categorical_crossentropy: -15.1957 - accuracy: 0.4899 - val_loss: 1.8405 - val_categorical_crossentropy: 1.8325 - val_accuracy: 0.3475\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.7267 - categorical_crossentropy: -15.4738 - accuracy: 0.4941 - val_loss: 2.0604 - val_categorical_crossentropy: 1.8554 - val_accuracy: 0.3438\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.6938 - categorical_crossentropy: -15.7228 - accuracy: 0.5107 - val_loss: 1.9976 - val_categorical_crossentropy: 1.8322 - val_accuracy: 0.3487\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.6561 - categorical_crossentropy: -15.9676 - accuracy: 0.5123 - val_loss: 2.0657 - val_categorical_crossentropy: 1.8482 - val_accuracy: 0.3400\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.6513 - categorical_crossentropy: -16.1148 - accuracy: 0.5185 - val_loss: 2.1580 - val_categorical_crossentropy: 1.8695 - val_accuracy: 0.3450\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.6226 - categorical_crossentropy: -16.2950 - accuracy: 0.5257 - val_loss: 2.3247 - val_categorical_crossentropy: 1.8719 - val_accuracy: 0.3363\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.6217 - categorical_crossentropy: -16.3601 - accuracy: 0.5213 - val_loss: 2.2568 - val_categorical_crossentropy: 1.8597 - val_accuracy: 0.3475\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.5793 - categorical_crossentropy: -16.7099 - accuracy: 0.5282 - val_loss: 2.1548 - val_categorical_crossentropy: 1.8289 - val_accuracy: 0.3487\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 1.5710 - categorical_crossentropy: -16.7403 - accuracy: 0.5320 - val_loss: 2.4574 - val_categorical_crossentropy: 1.9154 - val_accuracy: 0.3313\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 1.5684 - categorical_crossentropy: -16.8533 - accuracy: 0.5323 - val_loss: 2.3771 - val_categorical_crossentropy: 1.8969 - val_accuracy: 0.3338\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 1.5614 - categorical_crossentropy: -16.8239 - accuracy: 0.5327 - val_loss: 2.3372 - val_categorical_crossentropy: 1.8610 - val_accuracy: 0.3313\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.5392 - categorical_crossentropy: -16.9987 - accuracy: 0.5342 - val_loss: 2.2039 - val_categorical_crossentropy: 1.8438 - val_accuracy: 0.3288\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.5202 - categorical_crossentropy: -17.1921 - accuracy: 0.5396 - val_loss: 2.3750 - val_categorical_crossentropy: 1.8866 - val_accuracy: 0.3212\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.5072 - categorical_crossentropy: -17.3881 - accuracy: 0.5478 - val_loss: 2.3457 - val_categorical_crossentropy: 1.8913 - val_accuracy: 0.3187\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.4832 - categorical_crossentropy: -17.4296 - accuracy: 0.5448 - val_loss: 2.5372 - val_categorical_crossentropy: 1.8861 - val_accuracy: 0.3175\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.4551 - categorical_crossentropy: -17.7350 - accuracy: 0.5482 - val_loss: 2.4841 - val_categorical_crossentropy: 1.8874 - val_accuracy: 0.3175\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.4503 - categorical_crossentropy: -17.7790 - accuracy: 0.5504 - val_loss: 2.3585 - val_categorical_crossentropy: 1.8551 - val_accuracy: 0.3262\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.4486 - categorical_crossentropy: -17.8717 - accuracy: 0.5520 - val_loss: 2.4694 - val_categorical_crossentropy: 1.9089 - val_accuracy: 0.3050\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.4253 - categorical_crossentropy: -17.9791 - accuracy: 0.5557 - val_loss: 2.6039 - val_categorical_crossentropy: 1.9149 - val_accuracy: 0.3075\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.4059 - categorical_crossentropy: -18.0856 - accuracy: 0.5593 - val_loss: 2.6193 - val_categorical_crossentropy: 1.8864 - val_accuracy: 0.3237\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.3968 - categorical_crossentropy: -18.2424 - accuracy: 0.5598 - val_loss: 2.6742 - val_categorical_crossentropy: 1.9157 - val_accuracy: 0.3125\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.3830 - categorical_crossentropy: -18.3501 - accuracy: 0.5659 - val_loss: 2.5317 - val_categorical_crossentropy: 1.8753 - val_accuracy: 0.3175\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.3838 - categorical_crossentropy: -18.4647 - accuracy: 0.5610 - val_loss: 2.5893 - val_categorical_crossentropy: 1.9129 - val_accuracy: 0.3113\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.3834 - categorical_crossentropy: -18.2790 - accuracy: 0.5626 - val_loss: 2.5403 - val_categorical_crossentropy: 1.8686 - val_accuracy: 0.3137\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.3773 - categorical_crossentropy: -18.4105 - accuracy: 0.5615 - val_loss: 2.7134 - val_categorical_crossentropy: 1.8843 - val_accuracy: 0.3200\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.3641 - categorical_crossentropy: -18.4931 - accuracy: 0.5629 - val_loss: 2.6629 - val_categorical_crossentropy: 1.9048 - val_accuracy: 0.3137\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.3500 - categorical_crossentropy: -18.6655 - accuracy: 0.5692 - val_loss: 2.5612 - val_categorical_crossentropy: 1.8861 - val_accuracy: 0.3113\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.3510 - categorical_crossentropy: -18.5741 - accuracy: 0.5657 - val_loss: 2.5091 - val_categorical_crossentropy: 1.8189 - val_accuracy: 0.3300\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 1.3340 - categorical_crossentropy: -18.7208 - accuracy: 0.5676 - val_loss: 2.6105 - val_categorical_crossentropy: 1.8454 - val_accuracy: 0.3300\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.3408 - categorical_crossentropy: -18.7040 - accuracy: 0.5715 - val_loss: 2.6724 - val_categorical_crossentropy: 1.8874 - val_accuracy: 0.3137\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.3245 - categorical_crossentropy: -18.8351 - accuracy: 0.5689 - val_loss: 2.4740 - val_categorical_crossentropy: 1.8341 - val_accuracy: 0.3250\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.3231 - categorical_crossentropy: -18.8622 - accuracy: 0.5725 - val_loss: 2.5547 - val_categorical_crossentropy: 1.8617 - val_accuracy: 0.3200\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.3141 - categorical_crossentropy: -18.8757 - accuracy: 0.5706 - val_loss: 2.6807 - val_categorical_crossentropy: 1.8534 - val_accuracy: 0.3237\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.3129 - categorical_crossentropy: -18.9043 - accuracy: 0.5703 - val_loss: 2.7566 - val_categorical_crossentropy: 1.8930 - val_accuracy: 0.3100\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.3114 - categorical_crossentropy: -18.9697 - accuracy: 0.5687 - val_loss: 2.4988 - val_categorical_crossentropy: 1.8017 - val_accuracy: 0.3338\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.3049 - categorical_crossentropy: -18.9990 - accuracy: 0.5692 - val_loss: 2.4855 - val_categorical_crossentropy: 1.8158 - val_accuracy: 0.3300\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.3065 - categorical_crossentropy: -18.9260 - accuracy: 0.5742 - val_loss: 2.4800 - val_categorical_crossentropy: 1.7928 - val_accuracy: 0.3425\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.3219 - categorical_crossentropy: -18.9557 - accuracy: 0.5690 - val_loss: 2.6126 - val_categorical_crossentropy: 1.8399 - val_accuracy: 0.3250\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2984 - categorical_crossentropy: -18.9464 - accuracy: 0.5784 - val_loss: 2.6251 - val_categorical_crossentropy: 1.8186 - val_accuracy: 0.3350\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2966 - categorical_crossentropy: -19.0030 - accuracy: 0.5746 - val_loss: 2.6276 - val_categorical_crossentropy: 1.8047 - val_accuracy: 0.3462\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2890 - categorical_crossentropy: -19.1240 - accuracy: 0.5723 - val_loss: 2.5303 - val_categorical_crossentropy: 1.7801 - val_accuracy: 0.3413\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2969 - categorical_crossentropy: -19.0860 - accuracy: 0.5782 - val_loss: 2.5273 - val_categorical_crossentropy: 1.7996 - val_accuracy: 0.3388\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2891 - categorical_crossentropy: -19.1431 - accuracy: 0.5726 - val_loss: 2.4455 - val_categorical_crossentropy: 1.7908 - val_accuracy: 0.3400\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2780 - categorical_crossentropy: -19.1848 - accuracy: 0.5842 - val_loss: 2.6353 - val_categorical_crossentropy: 1.8373 - val_accuracy: 0.3300\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2777 - categorical_crossentropy: -19.2433 - accuracy: 0.5815 - val_loss: 2.4574 - val_categorical_crossentropy: 1.7554 - val_accuracy: 0.3450\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2799 - categorical_crossentropy: -19.1782 - accuracy: 0.5726 - val_loss: 2.4430 - val_categorical_crossentropy: 1.7664 - val_accuracy: 0.3475\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2818 - categorical_crossentropy: -19.1725 - accuracy: 0.5778 - val_loss: 2.4530 - val_categorical_crossentropy: 1.7764 - val_accuracy: 0.3487\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2715 - categorical_crossentropy: -19.2470 - accuracy: 0.5795 - val_loss: 2.6303 - val_categorical_crossentropy: 1.8385 - val_accuracy: 0.3363\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2641 - categorical_crossentropy: -19.3192 - accuracy: 0.5787 - val_loss: 2.6315 - val_categorical_crossentropy: 1.8552 - val_accuracy: 0.3275\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2718 - categorical_crossentropy: -19.2600 - accuracy: 0.5818 - val_loss: 2.5340 - val_categorical_crossentropy: 1.8177 - val_accuracy: 0.3438\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2594 - categorical_crossentropy: -19.3587 - accuracy: 0.5828 - val_loss: 2.5156 - val_categorical_crossentropy: 1.8082 - val_accuracy: 0.3462\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2552 - categorical_crossentropy: -19.3561 - accuracy: 0.5804 - val_loss: 2.6504 - val_categorical_crossentropy: 1.8084 - val_accuracy: 0.3450\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2673 - categorical_crossentropy: -19.3221 - accuracy: 0.5801 - val_loss: 2.7486 - val_categorical_crossentropy: 1.8433 - val_accuracy: 0.3388\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 1.2569 - categorical_crossentropy: -19.3261 - accuracy: 0.5771 - val_loss: 2.5929 - val_categorical_crossentropy: 1.7987 - val_accuracy: 0.3425\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2434 - categorical_crossentropy: -19.4674 - accuracy: 0.5843 - val_loss: 2.6040 - val_categorical_crossentropy: 1.8012 - val_accuracy: 0.3425\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2565 - categorical_crossentropy: -19.4385 - accuracy: 0.5743 - val_loss: 2.4660 - val_categorical_crossentropy: 1.7750 - val_accuracy: 0.3475\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2407 - categorical_crossentropy: -19.4650 - accuracy: 0.5826 - val_loss: 2.8405 - val_categorical_crossentropy: 1.8905 - val_accuracy: 0.3375\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2454 - categorical_crossentropy: -19.5119 - accuracy: 0.5818 - val_loss: 2.6119 - val_categorical_crossentropy: 1.8037 - val_accuracy: 0.3487\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2441 - categorical_crossentropy: -19.3947 - accuracy: 0.5831 - val_loss: 2.6621 - val_categorical_crossentropy: 1.7846 - val_accuracy: 0.3487\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2317 - categorical_crossentropy: -19.5535 - accuracy: 0.5826 - val_loss: 2.7499 - val_categorical_crossentropy: 1.8244 - val_accuracy: 0.3462\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2344 - categorical_crossentropy: -19.5587 - accuracy: 0.5861 - val_loss: 2.6182 - val_categorical_crossentropy: 1.8112 - val_accuracy: 0.3475\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2358 - categorical_crossentropy: -19.5576 - accuracy: 0.5861 - val_loss: 2.6077 - val_categorical_crossentropy: 1.8000 - val_accuracy: 0.3512\n",
            "Epoch 75/100\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.2242 - categorical_crossentropy: -19.5453 - accuracy: 0.5895INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.08.37/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 14s 70ms/step - loss: 1.2253 - categorical_crossentropy: -19.5538 - accuracy: 0.5890 - val_loss: 2.6220 - val_categorical_crossentropy: 1.7745 - val_accuracy: 0.3575\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2205 - categorical_crossentropy: -19.7340 - accuracy: 0.5862 - val_loss: 2.8999 - val_categorical_crossentropy: 1.8868 - val_accuracy: 0.3350\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2297 - categorical_crossentropy: -19.5888 - accuracy: 0.5812 - val_loss: 2.5790 - val_categorical_crossentropy: 1.8071 - val_accuracy: 0.3500\n",
            "Epoch 78/100\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.2245 - categorical_crossentropy: -19.6069 - accuracy: 0.5840INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.08.37/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 1.2263 - categorical_crossentropy: -19.6070 - accuracy: 0.5837 - val_loss: 2.6897 - val_categorical_crossentropy: 1.7781 - val_accuracy: 0.3625\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2216 - categorical_crossentropy: -19.7149 - accuracy: 0.5829 - val_loss: 2.4891 - val_categorical_crossentropy: 1.7767 - val_accuracy: 0.3575\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2270 - categorical_crossentropy: -19.5740 - accuracy: 0.5806 - val_loss: 2.5861 - val_categorical_crossentropy: 1.7877 - val_accuracy: 0.3537\n",
            "Epoch 81/100\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.2042 - categorical_crossentropy: -19.7946 - accuracy: 0.5936INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.08.37/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 14s 70ms/step - loss: 1.2065 - categorical_crossentropy: -19.7635 - accuracy: 0.5929 - val_loss: 2.6821 - val_categorical_crossentropy: 1.7903 - val_accuracy: 0.3638\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2274 - categorical_crossentropy: -19.6267 - accuracy: 0.5906 - val_loss: 2.6848 - val_categorical_crossentropy: 1.8066 - val_accuracy: 0.3562\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2115 - categorical_crossentropy: -19.7811 - accuracy: 0.5897 - val_loss: 2.6326 - val_categorical_crossentropy: 1.7883 - val_accuracy: 0.3587\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2147 - categorical_crossentropy: -19.7131 - accuracy: 0.5770 - val_loss: 2.6309 - val_categorical_crossentropy: 1.8107 - val_accuracy: 0.3475\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2262 - categorical_crossentropy: -19.5670 - accuracy: 0.5821 - val_loss: 2.5321 - val_categorical_crossentropy: 1.7729 - val_accuracy: 0.3562\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 1.2157 - categorical_crossentropy: -19.7218 - accuracy: 0.5779 - val_loss: 2.6349 - val_categorical_crossentropy: 1.8119 - val_accuracy: 0.3537\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2121 - categorical_crossentropy: -19.6887 - accuracy: 0.5964 - val_loss: 2.5957 - val_categorical_crossentropy: 1.8158 - val_accuracy: 0.3500\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2065 - categorical_crossentropy: -19.7937 - accuracy: 0.5865 - val_loss: 2.6128 - val_categorical_crossentropy: 1.7757 - val_accuracy: 0.3625\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2098 - categorical_crossentropy: -19.7709 - accuracy: 0.5893 - val_loss: 2.6314 - val_categorical_crossentropy: 1.8272 - val_accuracy: 0.3425\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.1891 - categorical_crossentropy: -19.9784 - accuracy: 0.5861 - val_loss: 2.5315 - val_categorical_crossentropy: 1.7486 - val_accuracy: 0.3512\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2053 - categorical_crossentropy: -19.8184 - accuracy: 0.5862 - val_loss: 2.7798 - val_categorical_crossentropy: 1.8225 - val_accuracy: 0.3550\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.1981 - categorical_crossentropy: -19.7948 - accuracy: 0.5965 - val_loss: 2.8369 - val_categorical_crossentropy: 1.8574 - val_accuracy: 0.3425\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.1993 - categorical_crossentropy: -19.8769 - accuracy: 0.5959 - val_loss: 2.5565 - val_categorical_crossentropy: 1.7649 - val_accuracy: 0.3587\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2112 - categorical_crossentropy: -19.7644 - accuracy: 0.5868 - val_loss: 2.5922 - val_categorical_crossentropy: 1.7684 - val_accuracy: 0.3600\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.1896 - categorical_crossentropy: -19.8732 - accuracy: 0.5839 - val_loss: 2.7626 - val_categorical_crossentropy: 1.7925 - val_accuracy: 0.3537\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.1919 - categorical_crossentropy: -19.9634 - accuracy: 0.5915 - val_loss: 2.6990 - val_categorical_crossentropy: 1.8126 - val_accuracy: 0.3550\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.1997 - categorical_crossentropy: -19.8422 - accuracy: 0.5854 - val_loss: 2.6193 - val_categorical_crossentropy: 1.7857 - val_accuracy: 0.3575\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.1869 - categorical_crossentropy: -19.9188 - accuracy: 0.5912 - val_loss: 2.8348 - val_categorical_crossentropy: 1.8109 - val_accuracy: 0.3462\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.1897 - categorical_crossentropy: -19.9274 - accuracy: 0.5890 - val_loss: 2.7833 - val_categorical_crossentropy: 1.7940 - val_accuracy: 0.3537\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.1918 - categorical_crossentropy: -19.9161 - accuracy: 0.5856 - val_loss: 2.8022 - val_categorical_crossentropy: 1.8412 - val_accuracy: 0.3450\n",
            "/content/drive/My Drive/DD2424Files/Results/20-05-15 21.08.37/models_cnn_k2c2_3layer_student\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 1)       10        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 1)       4         \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 1)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 48, 351, 1)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 48, 351, 1)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 351, 1)        10        \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 351, 1)        4         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 48, 351, 1)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 87, 1)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 87, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 87, 2)         20        \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 87, 2)         8         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 87, 2)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 17, 2)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 17, 2)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 272)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 2184      \n",
            "=================================================================\n",
            "Total params: 2,624\n",
            "Trainable params: 2,424\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n",
            "shape of y_s_train: (6397, 8) \n",
            "Epoch 1/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 3.0373 - categorical_crossentropy: -8.4519 - accuracy: 0.2622INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.28.31/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 3.0373 - categorical_crossentropy: -8.4519 - accuracy: 0.2622 - val_loss: 1.0071 - val_categorical_crossentropy: 1.7726 - val_accuracy: 0.3288\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 2.2211 - categorical_crossentropy: -12.8877 - accuracy: 0.3766INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.28.31/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 2.2211 - categorical_crossentropy: -12.8877 - accuracy: 0.3766 - val_loss: 1.6850 - val_categorical_crossentropy: 1.7282 - val_accuracy: 0.3787\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.8969 - categorical_crossentropy: -15.2694 - accuracy: 0.4360INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.28.31/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 1.8969 - categorical_crossentropy: -15.2694 - accuracy: 0.4360 - val_loss: 1.9706 - val_categorical_crossentropy: 1.6938 - val_accuracy: 0.3825\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.6617 - categorical_crossentropy: -16.7329 - accuracy: 0.4868INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.28.31/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 1.6617 - categorical_crossentropy: -16.7329 - accuracy: 0.4868 - val_loss: 2.4909 - val_categorical_crossentropy: 1.6902 - val_accuracy: 0.4137\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.5358 - categorical_crossentropy: -17.5977 - accuracy: 0.5032 - val_loss: 3.2209 - val_categorical_crossentropy: 1.7887 - val_accuracy: 0.3900\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4508 - categorical_crossentropy: -18.1470 - accuracy: 0.5213 - val_loss: 3.2548 - val_categorical_crossentropy: 1.7374 - val_accuracy: 0.4050\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4013 - categorical_crossentropy: -18.5053 - accuracy: 0.5332 - val_loss: 3.1615 - val_categorical_crossentropy: 1.6696 - val_accuracy: 0.4125\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3511 - categorical_crossentropy: -18.8772 - accuracy: 0.5446INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.28.31/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 1.3511 - categorical_crossentropy: -18.8772 - accuracy: 0.5446 - val_loss: 2.4626 - val_categorical_crossentropy: 1.5866 - val_accuracy: 0.4387\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.2951 - categorical_crossentropy: -19.1880 - accuracy: 0.5612 - val_loss: 2.9995 - val_categorical_crossentropy: 1.6463 - val_accuracy: 0.4062\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.2622 - categorical_crossentropy: -19.4517 - accuracy: 0.5728 - val_loss: 3.2284 - val_categorical_crossentropy: 1.6436 - val_accuracy: 0.4263\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.2417 - categorical_crossentropy: -19.7196 - accuracy: 0.5795 - val_loss: 3.2985 - val_categorical_crossentropy: 1.6677 - val_accuracy: 0.4062\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.2119 - categorical_crossentropy: -19.8210 - accuracy: 0.5826 - val_loss: 3.1892 - val_categorical_crossentropy: 1.6117 - val_accuracy: 0.4162\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.1902 - categorical_crossentropy: -20.0432 - accuracy: 0.5854 - val_loss: 3.9387 - val_categorical_crossentropy: 1.7695 - val_accuracy: 0.3887\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.1693 - categorical_crossentropy: -20.2173 - accuracy: 0.5903 - val_loss: 2.9869 - val_categorical_crossentropy: 1.5748 - val_accuracy: 0.4363\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.1676 - categorical_crossentropy: -20.1251 - accuracy: 0.5914 - val_loss: 3.0705 - val_categorical_crossentropy: 1.5961 - val_accuracy: 0.4313\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.1349 - categorical_crossentropy: -20.4390 - accuracy: 0.5932 - val_loss: 4.0570 - val_categorical_crossentropy: 1.7517 - val_accuracy: 0.4013\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.1090 - categorical_crossentropy: -20.6458 - accuracy: 0.6070 - val_loss: 3.4093 - val_categorical_crossentropy: 1.6694 - val_accuracy: 0.4062\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.1023 - categorical_crossentropy: -20.6630 - accuracy: 0.6076 - val_loss: 3.2205 - val_categorical_crossentropy: 1.6046 - val_accuracy: 0.4263\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.0922 - categorical_crossentropy: -20.7912 - accuracy: 0.6061 - val_loss: 3.4274 - val_categorical_crossentropy: 1.6542 - val_accuracy: 0.4038\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.0920 - categorical_crossentropy: -20.7400 - accuracy: 0.6165INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.28.31/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 1.0920 - categorical_crossentropy: -20.7400 - accuracy: 0.6165 - val_loss: 3.1746 - val_categorical_crossentropy: 1.5733 - val_accuracy: 0.4425\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.0736 - categorical_crossentropy: -20.8803 - accuracy: 0.6104 - val_loss: 3.2904 - val_categorical_crossentropy: 1.6107 - val_accuracy: 0.4250\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.0610 - categorical_crossentropy: -20.9823 - accuracy: 0.6198 - val_loss: 4.1580 - val_categorical_crossentropy: 1.7500 - val_accuracy: 0.3950\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.0518 - categorical_crossentropy: -21.0549 - accuracy: 0.6184 - val_loss: 3.5386 - val_categorical_crossentropy: 1.6410 - val_accuracy: 0.4238\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.0482 - categorical_crossentropy: -21.0875 - accuracy: 0.6254 - val_loss: 3.5574 - val_categorical_crossentropy: 1.6630 - val_accuracy: 0.4013\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.0210 - categorical_crossentropy: -21.3117 - accuracy: 0.6330 - val_loss: 3.4335 - val_categorical_crossentropy: 1.6525 - val_accuracy: 0.4000\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.0198 - categorical_crossentropy: -21.2682 - accuracy: 0.6253 - val_loss: 3.1879 - val_categorical_crossentropy: 1.5645 - val_accuracy: 0.4412\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.0108 - categorical_crossentropy: -21.4746 - accuracy: 0.6323 - val_loss: 3.7197 - val_categorical_crossentropy: 1.6906 - val_accuracy: 0.4025\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.0134 - categorical_crossentropy: -21.3456 - accuracy: 0.6267 - val_loss: 3.7954 - val_categorical_crossentropy: 1.6786 - val_accuracy: 0.4050\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9926 - categorical_crossentropy: -21.4760 - accuracy: 0.6380 - val_loss: 3.4418 - val_categorical_crossentropy: 1.6405 - val_accuracy: 0.4162\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9915 - categorical_crossentropy: -21.5351 - accuracy: 0.6390 - val_loss: 3.2676 - val_categorical_crossentropy: 1.5572 - val_accuracy: 0.4400\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9802 - categorical_crossentropy: -21.6734 - accuracy: 0.6401 - val_loss: 3.9872 - val_categorical_crossentropy: 1.6767 - val_accuracy: 0.4263\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9770 - categorical_crossentropy: -21.6847 - accuracy: 0.6390 - val_loss: 3.5910 - val_categorical_crossentropy: 1.6231 - val_accuracy: 0.4338\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.9704 - categorical_crossentropy: -21.7749 - accuracy: 0.6486INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.28.31/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.9704 - categorical_crossentropy: -21.7749 - accuracy: 0.6486 - val_loss: 3.1592 - val_categorical_crossentropy: 1.5393 - val_accuracy: 0.4550\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.9730 - categorical_crossentropy: -21.6851 - accuracy: 0.6425 - val_loss: 3.9567 - val_categorical_crossentropy: 1.6618 - val_accuracy: 0.4288\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9683 - categorical_crossentropy: -21.7805 - accuracy: 0.6417 - val_loss: 3.6864 - val_categorical_crossentropy: 1.6152 - val_accuracy: 0.4400\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9653 - categorical_crossentropy: -21.7959 - accuracy: 0.6456 - val_loss: 3.7646 - val_categorical_crossentropy: 1.6773 - val_accuracy: 0.4100\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9581 - categorical_crossentropy: -21.7882 - accuracy: 0.6400 - val_loss: 3.9106 - val_categorical_crossentropy: 1.6741 - val_accuracy: 0.4125\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9590 - categorical_crossentropy: -21.8438 - accuracy: 0.6439 - val_loss: 3.9051 - val_categorical_crossentropy: 1.6984 - val_accuracy: 0.4075\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9493 - categorical_crossentropy: -21.9168 - accuracy: 0.6437 - val_loss: 3.7453 - val_categorical_crossentropy: 1.6552 - val_accuracy: 0.4250\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9419 - categorical_crossentropy: -21.9360 - accuracy: 0.6480 - val_loss: 4.2348 - val_categorical_crossentropy: 1.7137 - val_accuracy: 0.4150\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9405 - categorical_crossentropy: -21.9968 - accuracy: 0.6500 - val_loss: 3.3161 - val_categorical_crossentropy: 1.5984 - val_accuracy: 0.4363\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9459 - categorical_crossentropy: -21.9475 - accuracy: 0.6519 - val_loss: 3.5779 - val_categorical_crossentropy: 1.6405 - val_accuracy: 0.4238\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9280 - categorical_crossentropy: -22.0495 - accuracy: 0.6511 - val_loss: 3.8416 - val_categorical_crossentropy: 1.6328 - val_accuracy: 0.4300\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9405 - categorical_crossentropy: -22.0408 - accuracy: 0.6573 - val_loss: 3.9999 - val_categorical_crossentropy: 1.6874 - val_accuracy: 0.4212\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9316 - categorical_crossentropy: -22.0339 - accuracy: 0.6478 - val_loss: 3.8820 - val_categorical_crossentropy: 1.6859 - val_accuracy: 0.4187\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9355 - categorical_crossentropy: -22.0524 - accuracy: 0.6501 - val_loss: 3.9817 - val_categorical_crossentropy: 1.6983 - val_accuracy: 0.4112\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9303 - categorical_crossentropy: -22.0380 - accuracy: 0.6505 - val_loss: 3.4829 - val_categorical_crossentropy: 1.5916 - val_accuracy: 0.4375\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9326 - categorical_crossentropy: -22.0850 - accuracy: 0.6566 - val_loss: 3.3782 - val_categorical_crossentropy: 1.5882 - val_accuracy: 0.4525\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9286 - categorical_crossentropy: -22.0633 - accuracy: 0.6501 - val_loss: 4.2195 - val_categorical_crossentropy: 1.7174 - val_accuracy: 0.4100\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9285 - categorical_crossentropy: -22.1062 - accuracy: 0.6509 - val_loss: 3.9218 - val_categorical_crossentropy: 1.6497 - val_accuracy: 0.4387\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9225 - categorical_crossentropy: -22.1396 - accuracy: 0.6548 - val_loss: 3.9674 - val_categorical_crossentropy: 1.6616 - val_accuracy: 0.4238\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9232 - categorical_crossentropy: -22.1251 - accuracy: 0.6516 - val_loss: 4.1358 - val_categorical_crossentropy: 1.7032 - val_accuracy: 0.4175\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 12s 59ms/step - loss: 0.9083 - categorical_crossentropy: -22.2318 - accuracy: 0.6589 - val_loss: 3.9541 - val_categorical_crossentropy: 1.6800 - val_accuracy: 0.4212\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 12s 59ms/step - loss: 0.9122 - categorical_crossentropy: -22.2204 - accuracy: 0.6561 - val_loss: 3.7546 - val_categorical_crossentropy: 1.6502 - val_accuracy: 0.4288\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9049 - categorical_crossentropy: -22.2766 - accuracy: 0.6612 - val_loss: 3.6535 - val_categorical_crossentropy: 1.6153 - val_accuracy: 0.4538\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9041 - categorical_crossentropy: -22.3157 - accuracy: 0.6562 - val_loss: 4.0816 - val_categorical_crossentropy: 1.6980 - val_accuracy: 0.4288\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.9000 - categorical_crossentropy: -22.2891 - accuracy: 0.6602 - val_loss: 3.9037 - val_categorical_crossentropy: 1.6574 - val_accuracy: 0.4350\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 12s 59ms/step - loss: 0.8972 - categorical_crossentropy: -22.3050 - accuracy: 0.6603 - val_loss: 3.7637 - val_categorical_crossentropy: 1.6322 - val_accuracy: 0.4512\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 12s 59ms/step - loss: 0.9033 - categorical_crossentropy: -22.3286 - accuracy: 0.6598 - val_loss: 3.6344 - val_categorical_crossentropy: 1.6371 - val_accuracy: 0.4412\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8968 - categorical_crossentropy: -22.3237 - accuracy: 0.6627 - val_loss: 4.0123 - val_categorical_crossentropy: 1.6654 - val_accuracy: 0.4350\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8971 - categorical_crossentropy: -22.4221 - accuracy: 0.6577 - val_loss: 3.5551 - val_categorical_crossentropy: 1.6187 - val_accuracy: 0.4487\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8981 - categorical_crossentropy: -22.2532 - accuracy: 0.6597 - val_loss: 3.9541 - val_categorical_crossentropy: 1.6675 - val_accuracy: 0.4225\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 12s 59ms/step - loss: 0.8878 - categorical_crossentropy: -22.4804 - accuracy: 0.6598 - val_loss: 3.5900 - val_categorical_crossentropy: 1.6489 - val_accuracy: 0.4350\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 12s 59ms/step - loss: 0.8931 - categorical_crossentropy: -22.3363 - accuracy: 0.6622 - val_loss: 3.7658 - val_categorical_crossentropy: 1.6445 - val_accuracy: 0.4325\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8853 - categorical_crossentropy: -22.4739 - accuracy: 0.6623 - val_loss: 3.5606 - val_categorical_crossentropy: 1.6164 - val_accuracy: 0.4525\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 12s 59ms/step - loss: 0.8791 - categorical_crossentropy: -22.4827 - accuracy: 0.6602 - val_loss: 3.8319 - val_categorical_crossentropy: 1.6328 - val_accuracy: 0.4338\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 12s 59ms/step - loss: 0.8892 - categorical_crossentropy: -22.4756 - accuracy: 0.6572 - val_loss: 3.8228 - val_categorical_crossentropy: 1.6700 - val_accuracy: 0.4313\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 12s 59ms/step - loss: 0.8699 - categorical_crossentropy: -22.5045 - accuracy: 0.6627 - val_loss: 3.6505 - val_categorical_crossentropy: 1.5939 - val_accuracy: 0.4512\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 12s 59ms/step - loss: 0.8829 - categorical_crossentropy: -22.4489 - accuracy: 0.6608 - val_loss: 3.6412 - val_categorical_crossentropy: 1.6390 - val_accuracy: 0.4363\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8701 - categorical_crossentropy: -22.5771 - accuracy: 0.6575 - val_loss: 4.0572 - val_categorical_crossentropy: 1.7169 - val_accuracy: 0.4100\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 12s 59ms/step - loss: 0.8672 - categorical_crossentropy: -22.5519 - accuracy: 0.6641 - val_loss: 3.8820 - val_categorical_crossentropy: 1.6381 - val_accuracy: 0.4412\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8851 - categorical_crossentropy: -22.4414 - accuracy: 0.6633 - val_loss: 3.6278 - val_categorical_crossentropy: 1.6185 - val_accuracy: 0.4475\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8797 - categorical_crossentropy: -22.5102 - accuracy: 0.6575 - val_loss: 4.0951 - val_categorical_crossentropy: 1.6334 - val_accuracy: 0.4425\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8817 - categorical_crossentropy: -22.5059 - accuracy: 0.6606 - val_loss: 3.6391 - val_categorical_crossentropy: 1.6143 - val_accuracy: 0.4425\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8640 - categorical_crossentropy: -22.6062 - accuracy: 0.6602 - val_loss: 3.3089 - val_categorical_crossentropy: 1.5868 - val_accuracy: 0.4487\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8520 - categorical_crossentropy: -22.6635 - accuracy: 0.6650 - val_loss: 3.5158 - val_categorical_crossentropy: 1.6065 - val_accuracy: 0.4525\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.8587 - categorical_crossentropy: -22.6907 - accuracy: 0.6567INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.28.31/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.8587 - categorical_crossentropy: -22.6907 - accuracy: 0.6567 - val_loss: 3.5124 - val_categorical_crossentropy: 1.5735 - val_accuracy: 0.4600\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.8641 - categorical_crossentropy: -22.5856 - accuracy: 0.6698 - val_loss: 3.6175 - val_categorical_crossentropy: 1.6174 - val_accuracy: 0.4500\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8611 - categorical_crossentropy: -22.6448 - accuracy: 0.6642 - val_loss: 3.7092 - val_categorical_crossentropy: 1.6450 - val_accuracy: 0.4313\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8730 - categorical_crossentropy: -22.5520 - accuracy: 0.6589 - val_loss: 3.5619 - val_categorical_crossentropy: 1.5970 - val_accuracy: 0.4512\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8678 - categorical_crossentropy: -22.6012 - accuracy: 0.6681 - val_loss: 3.4817 - val_categorical_crossentropy: 1.5931 - val_accuracy: 0.4462\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8596 - categorical_crossentropy: -22.6686 - accuracy: 0.6616 - val_loss: 3.7579 - val_categorical_crossentropy: 1.6468 - val_accuracy: 0.4363\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8585 - categorical_crossentropy: -22.6488 - accuracy: 0.6659 - val_loss: 3.5383 - val_categorical_crossentropy: 1.5660 - val_accuracy: 0.4437\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8537 - categorical_crossentropy: -22.6835 - accuracy: 0.6634 - val_loss: 3.7456 - val_categorical_crossentropy: 1.6140 - val_accuracy: 0.4412\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8643 - categorical_crossentropy: -22.6799 - accuracy: 0.6589 - val_loss: 3.9024 - val_categorical_crossentropy: 1.6294 - val_accuracy: 0.4400\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 12s 59ms/step - loss: 0.8593 - categorical_crossentropy: -22.6355 - accuracy: 0.6584 - val_loss: 4.2731 - val_categorical_crossentropy: 1.7283 - val_accuracy: 0.4075\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8454 - categorical_crossentropy: -22.7895 - accuracy: 0.6631 - val_loss: 3.7451 - val_categorical_crossentropy: 1.6664 - val_accuracy: 0.4175\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8525 - categorical_crossentropy: -22.6883 - accuracy: 0.6617 - val_loss: 3.6593 - val_categorical_crossentropy: 1.6079 - val_accuracy: 0.4563\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8431 - categorical_crossentropy: -22.8531 - accuracy: 0.6653 - val_loss: 3.6027 - val_categorical_crossentropy: 1.6181 - val_accuracy: 0.4450\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8541 - categorical_crossentropy: -22.7203 - accuracy: 0.6617 - val_loss: 3.6697 - val_categorical_crossentropy: 1.6229 - val_accuracy: 0.4300\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8422 - categorical_crossentropy: -22.7385 - accuracy: 0.6672 - val_loss: 3.5755 - val_categorical_crossentropy: 1.6268 - val_accuracy: 0.4313\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8430 - categorical_crossentropy: -22.8068 - accuracy: 0.6636 - val_loss: 3.8181 - val_categorical_crossentropy: 1.6674 - val_accuracy: 0.4150\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8566 - categorical_crossentropy: -22.7087 - accuracy: 0.6645 - val_loss: 3.5910 - val_categorical_crossentropy: 1.6237 - val_accuracy: 0.4387\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8549 - categorical_crossentropy: -22.7162 - accuracy: 0.6691 - val_loss: 3.4832 - val_categorical_crossentropy: 1.6063 - val_accuracy: 0.4500\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8456 - categorical_crossentropy: -22.7241 - accuracy: 0.6636 - val_loss: 3.4308 - val_categorical_crossentropy: 1.5861 - val_accuracy: 0.4500\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8474 - categorical_crossentropy: -22.7634 - accuracy: 0.6630 - val_loss: 3.6541 - val_categorical_crossentropy: 1.6319 - val_accuracy: 0.4425\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8557 - categorical_crossentropy: -22.7078 - accuracy: 0.6653 - val_loss: 3.6947 - val_categorical_crossentropy: 1.6258 - val_accuracy: 0.4475\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8401 - categorical_crossentropy: -22.8032 - accuracy: 0.6658 - val_loss: 4.1512 - val_categorical_crossentropy: 1.6909 - val_accuracy: 0.4038\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.8512 - categorical_crossentropy: -22.7340 - accuracy: 0.6614 - val_loss: 3.5777 - val_categorical_crossentropy: 1.6407 - val_accuracy: 0.4288\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 12s 59ms/step - loss: 0.8336 - categorical_crossentropy: -22.8379 - accuracy: 0.6636 - val_loss: 3.6729 - val_categorical_crossentropy: 1.6134 - val_accuracy: 0.4487\n",
            "/content/drive/My Drive/DD2424Files/Results/20-05-15 21.28.31/models_cnn_k2c2_3layer_student\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 2)       20        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 2)       8         \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 2)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 48, 351, 2)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 48, 351, 2)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 351, 3)        57        \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 351, 3)        12        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 48, 351, 3)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 87, 3)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 87, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 87, 3)         84        \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 87, 3)         12        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 87, 3)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 17, 3)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 17, 3)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 408)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 3272      \n",
            "=================================================================\n",
            "Total params: 3,849\n",
            "Trainable params: 3,641\n",
            "Non-trainable params: 208\n",
            "_________________________________________________________________\n",
            "shape of y_s_train: (6397, 8) \n",
            "Epoch 1/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 3.1225 - categorical_crossentropy: -9.7287 - accuracy: 0.2825INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.49.27/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 3.1225 - categorical_crossentropy: -9.7287 - accuracy: 0.2825 - val_loss: 1.3728 - val_categorical_crossentropy: 1.9627 - val_accuracy: 0.2450\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.9083 - categorical_crossentropy: -15.9998 - accuracy: 0.4344INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.49.27/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 1.9083 - categorical_crossentropy: -15.9998 - accuracy: 0.4344 - val_loss: 1.9418 - val_categorical_crossentropy: 1.7825 - val_accuracy: 0.3237\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.6225 - categorical_crossentropy: -17.8960 - accuracy: 0.4918INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.49.27/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 1.6225 - categorical_crossentropy: -17.8960 - accuracy: 0.4918 - val_loss: 2.0316 - val_categorical_crossentropy: 1.6270 - val_accuracy: 0.4112\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.4127 - categorical_crossentropy: -19.1346 - accuracy: 0.5359INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.49.27/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 1.4127 - categorical_crossentropy: -19.1346 - accuracy: 0.5359 - val_loss: 1.9813 - val_categorical_crossentropy: 1.5578 - val_accuracy: 0.4387\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3087 - categorical_crossentropy: -20.0368 - accuracy: 0.5543INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.49.27/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 1.3087 - categorical_crossentropy: -20.0368 - accuracy: 0.5543 - val_loss: 2.0569 - val_categorical_crossentropy: 1.5012 - val_accuracy: 0.4875\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 1.2134 - categorical_crossentropy: -20.5351 - accuracy: 0.5800 - val_loss: 2.4036 - val_categorical_crossentropy: 1.5969 - val_accuracy: 0.4550\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 1.1140 - categorical_crossentropy: -21.2920 - accuracy: 0.6050 - val_loss: 2.4710 - val_categorical_crossentropy: 1.4839 - val_accuracy: 0.4863\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.0473 - categorical_crossentropy: -21.7192 - accuracy: 0.6217INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.49.27/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 1.0473 - categorical_crossentropy: -21.7192 - accuracy: 0.6217 - val_loss: 2.1073 - val_categorical_crossentropy: 1.4225 - val_accuracy: 0.5325\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 1.0079 - categorical_crossentropy: -22.0306 - accuracy: 0.6333 - val_loss: 2.4843 - val_categorical_crossentropy: 1.4127 - val_accuracy: 0.5325\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.9112 - categorical_crossentropy: -22.7061 - accuracy: 0.6534 - val_loss: 2.5829 - val_categorical_crossentropy: 1.4226 - val_accuracy: 0.5275\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.8846 - categorical_crossentropy: -22.9471 - accuracy: 0.6648 - val_loss: 2.8383 - val_categorical_crossentropy: 1.4516 - val_accuracy: 0.5138\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.8392 - categorical_crossentropy: -23.3028 - accuracy: 0.6736INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.49.27/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.8392 - categorical_crossentropy: -23.3028 - accuracy: 0.6736 - val_loss: 2.2190 - val_categorical_crossentropy: 1.3480 - val_accuracy: 0.5750\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.7982 - categorical_crossentropy: -23.5219 - accuracy: 0.6897 - val_loss: 2.6470 - val_categorical_crossentropy: 1.3900 - val_accuracy: 0.5375\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.7964 - categorical_crossentropy: -23.5717 - accuracy: 0.6847 - val_loss: 2.5368 - val_categorical_crossentropy: 1.3622 - val_accuracy: 0.5575\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.7627 - categorical_crossentropy: -23.7906 - accuracy: 0.6908 - val_loss: 2.5431 - val_categorical_crossentropy: 1.3825 - val_accuracy: 0.5400\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.7568 - categorical_crossentropy: -23.8655 - accuracy: 0.7035INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.49.27/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.7568 - categorical_crossentropy: -23.8655 - accuracy: 0.7035 - val_loss: 2.4784 - val_categorical_crossentropy: 1.3310 - val_accuracy: 0.5775\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.7288 - categorical_crossentropy: -23.9719 - accuracy: 0.7022 - val_loss: 2.8411 - val_categorical_crossentropy: 1.3803 - val_accuracy: 0.5437\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.7027 - categorical_crossentropy: -24.2082 - accuracy: 0.7058 - val_loss: 2.4160 - val_categorical_crossentropy: 1.3262 - val_accuracy: 0.5738\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.6940 - categorical_crossentropy: -24.3027 - accuracy: 0.7008 - val_loss: 2.6757 - val_categorical_crossentropy: 1.3634 - val_accuracy: 0.5500\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.6727 - categorical_crossentropy: -24.4229 - accuracy: 0.7185 - val_loss: 2.7604 - val_categorical_crossentropy: 1.3615 - val_accuracy: 0.5462\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.6745 - categorical_crossentropy: -24.3929 - accuracy: 0.7108 - val_loss: 2.2764 - val_categorical_crossentropy: 1.3321 - val_accuracy: 0.5688\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.6585 - categorical_crossentropy: -24.5770 - accuracy: 0.7177 - val_loss: 2.3303 - val_categorical_crossentropy: 1.3297 - val_accuracy: 0.5587\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.6440 - categorical_crossentropy: -24.5295 - accuracy: 0.7119 - val_loss: 2.4536 - val_categorical_crossentropy: 1.3291 - val_accuracy: 0.5663\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.6431 - categorical_crossentropy: -24.6446 - accuracy: 0.7175 - val_loss: 2.6241 - val_categorical_crossentropy: 1.3404 - val_accuracy: 0.5663\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.6321 - categorical_crossentropy: -24.6537 - accuracy: 0.7208 - val_loss: 2.4156 - val_categorical_crossentropy: 1.3440 - val_accuracy: 0.5725\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6319 - categorical_crossentropy: -24.6822 - accuracy: 0.7183INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.49.27/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.6319 - categorical_crossentropy: -24.6822 - accuracy: 0.7183 - val_loss: 2.4588 - val_categorical_crossentropy: 1.3207 - val_accuracy: 0.5888\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.6253 - categorical_crossentropy: -24.6972 - accuracy: 0.7216 - val_loss: 2.5770 - val_categorical_crossentropy: 1.3110 - val_accuracy: 0.5813\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6264 - categorical_crossentropy: -24.7481 - accuracy: 0.7163INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.49.27/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.6264 - categorical_crossentropy: -24.7481 - accuracy: 0.7163 - val_loss: 2.6785 - val_categorical_crossentropy: 1.3194 - val_accuracy: 0.5900\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.6055 - categorical_crossentropy: -24.8592 - accuracy: 0.7310 - val_loss: 2.9185 - val_categorical_crossentropy: 1.3288 - val_accuracy: 0.5863\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5945 - categorical_crossentropy: -24.9443 - accuracy: 0.7275INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.49.27/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.5945 - categorical_crossentropy: -24.9443 - accuracy: 0.7275 - val_loss: 2.6336 - val_categorical_crossentropy: 1.3145 - val_accuracy: 0.5987\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.5853 - categorical_crossentropy: -25.0210 - accuracy: 0.7414 - val_loss: 2.6740 - val_categorical_crossentropy: 1.3151 - val_accuracy: 0.5850\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5851 - categorical_crossentropy: -25.0205 - accuracy: 0.7271INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.49.27/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.5851 - categorical_crossentropy: -25.0205 - accuracy: 0.7271 - val_loss: 2.4374 - val_categorical_crossentropy: 1.3122 - val_accuracy: 0.6000\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.5943 - categorical_crossentropy: -24.8801 - accuracy: 0.7330 - val_loss: 2.8468 - val_categorical_crossentropy: 1.3073 - val_accuracy: 0.5813\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.5959 - categorical_crossentropy: -24.9644 - accuracy: 0.7330 - val_loss: 2.8768 - val_categorical_crossentropy: 1.3658 - val_accuracy: 0.5688\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.5795 - categorical_crossentropy: -25.0668 - accuracy: 0.7424 - val_loss: 2.4272 - val_categorical_crossentropy: 1.2995 - val_accuracy: 0.5875\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5669 - categorical_crossentropy: -25.1191 - accuracy: 0.7350INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.49.27/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.5669 - categorical_crossentropy: -25.1191 - accuracy: 0.7350 - val_loss: 2.6888 - val_categorical_crossentropy: 1.3162 - val_accuracy: 0.6012\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.5725 - categorical_crossentropy: -25.0679 - accuracy: 0.7336 - val_loss: 2.6192 - val_categorical_crossentropy: 1.3034 - val_accuracy: 0.5913\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.5792 - categorical_crossentropy: -25.0884 - accuracy: 0.7305 - val_loss: 2.7162 - val_categorical_crossentropy: 1.2963 - val_accuracy: 0.5888\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.5664 - categorical_crossentropy: -25.1363 - accuracy: 0.7332 - val_loss: 2.8843 - val_categorical_crossentropy: 1.3406 - val_accuracy: 0.5825\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.5652 - categorical_crossentropy: -25.1872 - accuracy: 0.7361 - val_loss: 2.5529 - val_categorical_crossentropy: 1.2857 - val_accuracy: 0.5975\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5484 - categorical_crossentropy: -25.2876 - accuracy: 0.7450INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 21.49.27/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.5484 - categorical_crossentropy: -25.2876 - accuracy: 0.7450 - val_loss: 2.5569 - val_categorical_crossentropy: 1.3019 - val_accuracy: 0.6037\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.5593 - categorical_crossentropy: -25.2206 - accuracy: 0.7427 - val_loss: 2.6617 - val_categorical_crossentropy: 1.2830 - val_accuracy: 0.5938\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.5516 - categorical_crossentropy: -25.2662 - accuracy: 0.7463 - val_loss: 2.5859 - val_categorical_crossentropy: 1.3187 - val_accuracy: 0.5775\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.5593 - categorical_crossentropy: -25.1832 - accuracy: 0.7430 - val_loss: 2.8103 - val_categorical_crossentropy: 1.2971 - val_accuracy: 0.5900\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.5300 - categorical_crossentropy: -25.3860 - accuracy: 0.7486 - val_loss: 2.8452 - val_categorical_crossentropy: 1.3553 - val_accuracy: 0.5688\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.5428 - categorical_crossentropy: -25.3426 - accuracy: 0.7449 - val_loss: 2.6915 - val_categorical_crossentropy: 1.2865 - val_accuracy: 0.5987\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.5432 - categorical_crossentropy: -25.3212 - accuracy: 0.7386 - val_loss: 2.8825 - val_categorical_crossentropy: 1.3564 - val_accuracy: 0.5612\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.5436 - categorical_crossentropy: -25.3206 - accuracy: 0.7466 - val_loss: 2.7632 - val_categorical_crossentropy: 1.2977 - val_accuracy: 0.5913\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.5373 - categorical_crossentropy: -25.3848 - accuracy: 0.7510 - val_loss: 2.4807 - val_categorical_crossentropy: 1.2903 - val_accuracy: 0.5875\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.5353 - categorical_crossentropy: -25.3565 - accuracy: 0.7485 - val_loss: 2.9401 - val_categorical_crossentropy: 1.3292 - val_accuracy: 0.5738\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.5372 - categorical_crossentropy: -25.3646 - accuracy: 0.7388 - val_loss: 2.7281 - val_categorical_crossentropy: 1.3038 - val_accuracy: 0.5800\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.5510 - categorical_crossentropy: -25.3035 - accuracy: 0.7469 - val_loss: 2.6418 - val_categorical_crossentropy: 1.2911 - val_accuracy: 0.5838\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.5302 - categorical_crossentropy: -25.4724 - accuracy: 0.7511 - val_loss: 2.7679 - val_categorical_crossentropy: 1.3269 - val_accuracy: 0.5775\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.5316 - categorical_crossentropy: -25.3701 - accuracy: 0.7443 - val_loss: 2.7418 - val_categorical_crossentropy: 1.3030 - val_accuracy: 0.5863\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.5171 - categorical_crossentropy: -25.4622 - accuracy: 0.7497 - val_loss: 3.1530 - val_categorical_crossentropy: 1.3541 - val_accuracy: 0.5675\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.5184 - categorical_crossentropy: -25.5592 - accuracy: 0.7505 - val_loss: 2.8725 - val_categorical_crossentropy: 1.2847 - val_accuracy: 0.5825\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.5201 - categorical_crossentropy: -25.4982 - accuracy: 0.7566 - val_loss: 2.8159 - val_categorical_crossentropy: 1.3323 - val_accuracy: 0.5713\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.5150 - categorical_crossentropy: -25.5757 - accuracy: 0.7615 - val_loss: 2.7701 - val_categorical_crossentropy: 1.3055 - val_accuracy: 0.5775\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.5184 - categorical_crossentropy: -25.4763 - accuracy: 0.7563 - val_loss: 2.8413 - val_categorical_crossentropy: 1.3271 - val_accuracy: 0.5663\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.5124 - categorical_crossentropy: -25.5458 - accuracy: 0.7514 - val_loss: 2.6921 - val_categorical_crossentropy: 1.2833 - val_accuracy: 0.5813\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.5314 - categorical_crossentropy: -25.4552 - accuracy: 0.7461 - val_loss: 3.1210 - val_categorical_crossentropy: 1.3390 - val_accuracy: 0.5763\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.5060 - categorical_crossentropy: -25.6062 - accuracy: 0.7550 - val_loss: 2.8668 - val_categorical_crossentropy: 1.3325 - val_accuracy: 0.5675\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.5102 - categorical_crossentropy: -25.5743 - accuracy: 0.7599 - val_loss: 2.8608 - val_categorical_crossentropy: 1.3123 - val_accuracy: 0.5650\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.5076 - categorical_crossentropy: -25.5339 - accuracy: 0.7568 - val_loss: 2.8367 - val_categorical_crossentropy: 1.2972 - val_accuracy: 0.5725\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.5013 - categorical_crossentropy: -25.6337 - accuracy: 0.7560 - val_loss: 2.9231 - val_categorical_crossentropy: 1.2994 - val_accuracy: 0.5750\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.5002 - categorical_crossentropy: -25.7000 - accuracy: 0.7600 - val_loss: 2.7592 - val_categorical_crossentropy: 1.2915 - val_accuracy: 0.5838\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.4990 - categorical_crossentropy: -25.6215 - accuracy: 0.7593 - val_loss: 2.8274 - val_categorical_crossentropy: 1.2955 - val_accuracy: 0.5838\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.5042 - categorical_crossentropy: -25.6184 - accuracy: 0.7582 - val_loss: 3.1363 - val_categorical_crossentropy: 1.3535 - val_accuracy: 0.5562\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.5109 - categorical_crossentropy: -25.6100 - accuracy: 0.7577 - val_loss: 2.9119 - val_categorical_crossentropy: 1.3113 - val_accuracy: 0.5875\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.5120 - categorical_crossentropy: -25.5042 - accuracy: 0.7569 - val_loss: 2.9448 - val_categorical_crossentropy: 1.3082 - val_accuracy: 0.5800\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.4963 - categorical_crossentropy: -25.6965 - accuracy: 0.7641 - val_loss: 2.7500 - val_categorical_crossentropy: 1.2742 - val_accuracy: 0.5825\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.5027 - categorical_crossentropy: -25.6449 - accuracy: 0.7579 - val_loss: 3.0923 - val_categorical_crossentropy: 1.3165 - val_accuracy: 0.5775\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.5050 - categorical_crossentropy: -25.6116 - accuracy: 0.7580 - val_loss: 3.0266 - val_categorical_crossentropy: 1.3021 - val_accuracy: 0.5875\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.4925 - categorical_crossentropy: -25.7039 - accuracy: 0.7629 - val_loss: 3.0536 - val_categorical_crossentropy: 1.2990 - val_accuracy: 0.5800\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.4980 - categorical_crossentropy: -25.7027 - accuracy: 0.7593 - val_loss: 2.7162 - val_categorical_crossentropy: 1.2959 - val_accuracy: 0.5775\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.4946 - categorical_crossentropy: -25.6757 - accuracy: 0.7643 - val_loss: 2.8721 - val_categorical_crossentropy: 1.2934 - val_accuracy: 0.5763\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.4923 - categorical_crossentropy: -25.6794 - accuracy: 0.7660 - val_loss: 2.9600 - val_categorical_crossentropy: 1.3119 - val_accuracy: 0.5700\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.4798 - categorical_crossentropy: -25.7740 - accuracy: 0.7640 - val_loss: 2.8477 - val_categorical_crossentropy: 1.2908 - val_accuracy: 0.5750\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.4936 - categorical_crossentropy: -25.7273 - accuracy: 0.7585 - val_loss: 3.2613 - val_categorical_crossentropy: 1.3339 - val_accuracy: 0.5713\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.4992 - categorical_crossentropy: -25.6451 - accuracy: 0.7640 - val_loss: 3.0194 - val_categorical_crossentropy: 1.3071 - val_accuracy: 0.5725\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.4906 - categorical_crossentropy: -25.7225 - accuracy: 0.7646 - val_loss: 2.9373 - val_categorical_crossentropy: 1.2862 - val_accuracy: 0.5763\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.4866 - categorical_crossentropy: -25.7423 - accuracy: 0.7636 - val_loss: 2.8203 - val_categorical_crossentropy: 1.2945 - val_accuracy: 0.5688\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.4911 - categorical_crossentropy: -25.6825 - accuracy: 0.7589 - val_loss: 3.1450 - val_categorical_crossentropy: 1.3519 - val_accuracy: 0.5550\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.4879 - categorical_crossentropy: -25.7944 - accuracy: 0.7680 - val_loss: 3.0131 - val_categorical_crossentropy: 1.3521 - val_accuracy: 0.5625\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.4833 - categorical_crossentropy: -25.7402 - accuracy: 0.7625 - val_loss: 3.1824 - val_categorical_crossentropy: 1.3111 - val_accuracy: 0.5675\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.4871 - categorical_crossentropy: -25.7165 - accuracy: 0.7658 - val_loss: 3.1668 - val_categorical_crossentropy: 1.3007 - val_accuracy: 0.5675\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.4878 - categorical_crossentropy: -25.7577 - accuracy: 0.7611 - val_loss: 3.2402 - val_categorical_crossentropy: 1.2827 - val_accuracy: 0.5763\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.4763 - categorical_crossentropy: -25.8279 - accuracy: 0.7583 - val_loss: 3.0914 - val_categorical_crossentropy: 1.3043 - val_accuracy: 0.5700\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.4782 - categorical_crossentropy: -25.7913 - accuracy: 0.7616 - val_loss: 3.1139 - val_categorical_crossentropy: 1.3079 - val_accuracy: 0.5675\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.4895 - categorical_crossentropy: -25.7938 - accuracy: 0.7621 - val_loss: 3.3538 - val_categorical_crossentropy: 1.3629 - val_accuracy: 0.5562\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.4778 - categorical_crossentropy: -25.7628 - accuracy: 0.7641 - val_loss: 3.0201 - val_categorical_crossentropy: 1.3014 - val_accuracy: 0.5713\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.4808 - categorical_crossentropy: -25.8150 - accuracy: 0.7621 - val_loss: 2.9485 - val_categorical_crossentropy: 1.2788 - val_accuracy: 0.5863\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.4793 - categorical_crossentropy: -25.8040 - accuracy: 0.7671 - val_loss: 2.9655 - val_categorical_crossentropy: 1.2782 - val_accuracy: 0.5838\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.4902 - categorical_crossentropy: -25.7469 - accuracy: 0.7616 - val_loss: 3.3531 - val_categorical_crossentropy: 1.3745 - val_accuracy: 0.5550\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.4639 - categorical_crossentropy: -25.9124 - accuracy: 0.7719 - val_loss: 2.8792 - val_categorical_crossentropy: 1.2896 - val_accuracy: 0.5700\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.4783 - categorical_crossentropy: -25.8141 - accuracy: 0.7613 - val_loss: 2.9703 - val_categorical_crossentropy: 1.2758 - val_accuracy: 0.5800\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.4801 - categorical_crossentropy: -25.7849 - accuracy: 0.7674 - val_loss: 3.2915 - val_categorical_crossentropy: 1.3348 - val_accuracy: 0.5738\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.4717 - categorical_crossentropy: -25.8258 - accuracy: 0.7644 - val_loss: 2.9606 - val_categorical_crossentropy: 1.2897 - val_accuracy: 0.5725\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.4769 - categorical_crossentropy: -25.8339 - accuracy: 0.7644 - val_loss: 3.2468 - val_categorical_crossentropy: 1.3511 - val_accuracy: 0.5587\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.4691 - categorical_crossentropy: -25.8835 - accuracy: 0.7682 - val_loss: 3.1179 - val_categorical_crossentropy: 1.3055 - val_accuracy: 0.5738\n",
            "/content/drive/My Drive/DD2424Files/Results/20-05-15 21.49.27/models_cnn_k2c2_3layer_student\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 5)       50        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 5)       20        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 5)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 48, 351, 5)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 48, 351, 5)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 351, 8)        368       \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 351, 8)        32        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 48, 351, 8)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 87, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 87, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 87, 8)         584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 87, 8)         32        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 87, 8)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 17, 8)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 17, 8)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1088)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 8712      \n",
            "=================================================================\n",
            "Total params: 10,182\n",
            "Trainable params: 9,948\n",
            "Non-trainable params: 234\n",
            "_________________________________________________________________\n",
            "shape of y_s_train: (6397, 8) \n",
            "Epoch 1/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 3.3834 - categorical_crossentropy: -11.6910 - accuracy: 0.2989INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 22.15.58/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 29s 146ms/step - loss: 3.3834 - categorical_crossentropy: -11.6910 - accuracy: 0.2989 - val_loss: 1.8362 - val_categorical_crossentropy: 2.1467 - val_accuracy: 0.2350\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.8357 - categorical_crossentropy: -18.8568 - accuracy: 0.4654INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 22.15.58/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 28s 142ms/step - loss: 1.8357 - categorical_crossentropy: -18.8568 - accuracy: 0.4654 - val_loss: 2.3037 - val_categorical_crossentropy: 1.8133 - val_accuracy: 0.3537\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.5120 - categorical_crossentropy: -20.6764 - accuracy: 0.5304INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 22.15.58/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 29s 147ms/step - loss: 1.5120 - categorical_crossentropy: -20.6764 - accuracy: 0.5304 - val_loss: 2.9087 - val_categorical_crossentropy: 1.6161 - val_accuracy: 0.4363\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.2771 - categorical_crossentropy: -21.9271 - accuracy: 0.5715INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 22.15.58/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 29s 144ms/step - loss: 1.2771 - categorical_crossentropy: -21.9271 - accuracy: 0.5715 - val_loss: 3.4387 - val_categorical_crossentropy: 1.5214 - val_accuracy: 0.4925\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.0659 - categorical_crossentropy: -23.0425 - accuracy: 0.6225INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 22.15.58/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 29s 143ms/step - loss: 1.0659 - categorical_crossentropy: -23.0425 - accuracy: 0.6225 - val_loss: 3.2207 - val_categorical_crossentropy: 1.4564 - val_accuracy: 0.5238\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.9808 - categorical_crossentropy: -23.4954 - accuracy: 0.6431 - val_loss: 4.0481 - val_categorical_crossentropy: 1.5164 - val_accuracy: 0.5025\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.8561 - categorical_crossentropy: -24.2123 - accuracy: 0.6727INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 22.15.58/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 29s 143ms/step - loss: 0.8561 - categorical_crossentropy: -24.2123 - accuracy: 0.6727 - val_loss: 2.9784 - val_categorical_crossentropy: 1.3536 - val_accuracy: 0.5437\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.7800 - categorical_crossentropy: -24.5231 - accuracy: 0.6839 - val_loss: 3.8680 - val_categorical_crossentropy: 1.4344 - val_accuracy: 0.5150\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.7253 - categorical_crossentropy: -24.8157 - accuracy: 0.7144INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 22.15.58/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 29s 143ms/step - loss: 0.7253 - categorical_crossentropy: -24.8157 - accuracy: 0.7144 - val_loss: 3.7045 - val_categorical_crossentropy: 1.4058 - val_accuracy: 0.5562\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6870 - categorical_crossentropy: -25.0155 - accuracy: 0.7142INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 22.15.58/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 29s 147ms/step - loss: 0.6870 - categorical_crossentropy: -25.0155 - accuracy: 0.7142 - val_loss: 3.1541 - val_categorical_crossentropy: 1.3092 - val_accuracy: 0.5675\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.7000 - categorical_crossentropy: -24.8717 - accuracy: 0.7114 - val_loss: 3.2139 - val_categorical_crossentropy: 1.3568 - val_accuracy: 0.5500\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.6413 - categorical_crossentropy: -25.1809 - accuracy: 0.7221 - val_loss: 3.1459 - val_categorical_crossentropy: 1.3478 - val_accuracy: 0.5550\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5923 - categorical_crossentropy: -25.4448 - accuracy: 0.7413INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 22.15.58/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 29s 143ms/step - loss: 0.5923 - categorical_crossentropy: -25.4448 - accuracy: 0.7413 - val_loss: 3.2483 - val_categorical_crossentropy: 1.2990 - val_accuracy: 0.5775\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.5916 - categorical_crossentropy: -25.4788 - accuracy: 0.7482 - val_loss: 3.5699 - val_categorical_crossentropy: 1.3656 - val_accuracy: 0.5562\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5577 - categorical_crossentropy: -25.6826 - accuracy: 0.7472INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 22.15.58/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 29s 143ms/step - loss: 0.5577 - categorical_crossentropy: -25.6826 - accuracy: 0.7472 - val_loss: 3.3091 - val_categorical_crossentropy: 1.3424 - val_accuracy: 0.5813\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5644 - categorical_crossentropy: -25.6516 - accuracy: 0.7539INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 22.15.58/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 29s 143ms/step - loss: 0.5644 - categorical_crossentropy: -25.6516 - accuracy: 0.7539 - val_loss: 3.1008 - val_categorical_crossentropy: 1.2629 - val_accuracy: 0.5863\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.5252 - categorical_crossentropy: -25.8128 - accuracy: 0.7619 - val_loss: 2.9688 - val_categorical_crossentropy: 1.3046 - val_accuracy: 0.5763\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.5286 - categorical_crossentropy: -25.8459 - accuracy: 0.7593 - val_loss: 3.1175 - val_categorical_crossentropy: 1.2907 - val_accuracy: 0.5725\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.4898 - categorical_crossentropy: -26.0285 - accuracy: 0.7680 - val_loss: 2.9042 - val_categorical_crossentropy: 1.2744 - val_accuracy: 0.5850\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.4946 - categorical_crossentropy: -26.0554 - accuracy: 0.7641 - val_loss: 3.1560 - val_categorical_crossentropy: 1.2838 - val_accuracy: 0.5788\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.4797 - categorical_crossentropy: -26.1581 - accuracy: 0.7721 - val_loss: 2.9907 - val_categorical_crossentropy: 1.2566 - val_accuracy: 0.5763\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.4676 - categorical_crossentropy: -26.2404 - accuracy: 0.7724 - val_loss: 3.1371 - val_categorical_crossentropy: 1.3093 - val_accuracy: 0.5612\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.4592 - categorical_crossentropy: -26.2265 - accuracy: 0.7715 - val_loss: 3.3552 - val_categorical_crossentropy: 1.3007 - val_accuracy: 0.5800\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.4367 - categorical_crossentropy: -26.4238 - accuracy: 0.7851INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 22.15.58/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 29s 146ms/step - loss: 0.4367 - categorical_crossentropy: -26.4238 - accuracy: 0.7851 - val_loss: 3.4666 - val_categorical_crossentropy: 1.2713 - val_accuracy: 0.6037\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.4638 - categorical_crossentropy: -26.2908 - accuracy: 0.7704 - val_loss: 3.3050 - val_categorical_crossentropy: 1.2808 - val_accuracy: 0.5788\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.4359 - categorical_crossentropy: -26.3832 - accuracy: 0.7815 - val_loss: 3.3246 - val_categorical_crossentropy: 1.2717 - val_accuracy: 0.5838\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.4125 - categorical_crossentropy: -26.5914 - accuracy: 0.7922 - val_loss: 3.1823 - val_categorical_crossentropy: 1.2468 - val_accuracy: 0.5863\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.4381 - categorical_crossentropy: -26.3930 - accuracy: 0.7835 - val_loss: 3.2056 - val_categorical_crossentropy: 1.2436 - val_accuracy: 0.5962\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.4369 - categorical_crossentropy: -26.4295 - accuracy: 0.7815 - val_loss: 3.4655 - val_categorical_crossentropy: 1.3044 - val_accuracy: 0.5750\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.4162 - categorical_crossentropy: -26.5750 - accuracy: 0.7861INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 22.15.58/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 29s 143ms/step - loss: 0.4162 - categorical_crossentropy: -26.5750 - accuracy: 0.7861 - val_loss: 2.9938 - val_categorical_crossentropy: 1.2412 - val_accuracy: 0.6087\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.4017 - categorical_crossentropy: -26.6430 - accuracy: 0.7887 - val_loss: 3.2540 - val_categorical_crossentropy: 1.2647 - val_accuracy: 0.5962\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3935 - categorical_crossentropy: -26.7372 - accuracy: 0.7882 - val_loss: 3.4504 - val_categorical_crossentropy: 1.2802 - val_accuracy: 0.5950\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3908 - categorical_crossentropy: -26.7422 - accuracy: 0.7938 - val_loss: 3.0386 - val_categorical_crossentropy: 1.2302 - val_accuracy: 0.6062\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3863 - categorical_crossentropy: -26.8236 - accuracy: 0.7977 - val_loss: 3.2003 - val_categorical_crossentropy: 1.2326 - val_accuracy: 0.6025\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.3939 - categorical_crossentropy: -26.7241 - accuracy: 0.7907INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 22.15.58/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 28s 142ms/step - loss: 0.3939 - categorical_crossentropy: -26.7241 - accuracy: 0.7907 - val_loss: 3.0525 - val_categorical_crossentropy: 1.2272 - val_accuracy: 0.6125\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3852 - categorical_crossentropy: -26.7528 - accuracy: 0.7908 - val_loss: 3.5506 - val_categorical_crossentropy: 1.2719 - val_accuracy: 0.5838\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3747 - categorical_crossentropy: -26.8681 - accuracy: 0.7988 - val_loss: 3.1946 - val_categorical_crossentropy: 1.2528 - val_accuracy: 0.5925\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.3916 - categorical_crossentropy: -26.7604 - accuracy: 0.7941INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 22.15.58/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 28s 142ms/step - loss: 0.3916 - categorical_crossentropy: -26.7604 - accuracy: 0.7941 - val_loss: 2.9681 - val_categorical_crossentropy: 1.2393 - val_accuracy: 0.6200\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3757 - categorical_crossentropy: -26.8655 - accuracy: 0.8010 - val_loss: 3.3019 - val_categorical_crossentropy: 1.2522 - val_accuracy: 0.6025\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3679 - categorical_crossentropy: -26.8864 - accuracy: 0.8001 - val_loss: 3.3193 - val_categorical_crossentropy: 1.2329 - val_accuracy: 0.6075\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3712 - categorical_crossentropy: -26.9028 - accuracy: 0.8026 - val_loss: 3.4441 - val_categorical_crossentropy: 1.2394 - val_accuracy: 0.6025\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3645 - categorical_crossentropy: -26.9248 - accuracy: 0.8029 - val_loss: 3.1746 - val_categorical_crossentropy: 1.2453 - val_accuracy: 0.6100\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3591 - categorical_crossentropy: -26.9821 - accuracy: 0.8018 - val_loss: 3.1371 - val_categorical_crossentropy: 1.2307 - val_accuracy: 0.6025\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3665 - categorical_crossentropy: -26.9608 - accuracy: 0.8052 - val_loss: 3.3245 - val_categorical_crossentropy: 1.2461 - val_accuracy: 0.5938\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3645 - categorical_crossentropy: -26.9316 - accuracy: 0.8060 - val_loss: 3.2696 - val_categorical_crossentropy: 1.2122 - val_accuracy: 0.6100\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3586 - categorical_crossentropy: -27.0345 - accuracy: 0.8033 - val_loss: 3.3354 - val_categorical_crossentropy: 1.2512 - val_accuracy: 0.6025\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3528 - categorical_crossentropy: -27.0082 - accuracy: 0.8076 - val_loss: 3.4546 - val_categorical_crossentropy: 1.2256 - val_accuracy: 0.6137\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3458 - categorical_crossentropy: -27.0742 - accuracy: 0.8091 - val_loss: 3.4637 - val_categorical_crossentropy: 1.2453 - val_accuracy: 0.6012\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3562 - categorical_crossentropy: -27.0245 - accuracy: 0.8043 - val_loss: 3.2637 - val_categorical_crossentropy: 1.2266 - val_accuracy: 0.6050\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3431 - categorical_crossentropy: -27.0968 - accuracy: 0.8073 - val_loss: 3.1944 - val_categorical_crossentropy: 1.2201 - val_accuracy: 0.6075\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3417 - categorical_crossentropy: -27.1494 - accuracy: 0.8087 - val_loss: 3.0795 - val_categorical_crossentropy: 1.2256 - val_accuracy: 0.5938\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3445 - categorical_crossentropy: -27.0523 - accuracy: 0.8132 - val_loss: 3.1704 - val_categorical_crossentropy: 1.2172 - val_accuracy: 0.6125\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3399 - categorical_crossentropy: -27.1182 - accuracy: 0.8134 - val_loss: 3.6710 - val_categorical_crossentropy: 1.2792 - val_accuracy: 0.5925\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3393 - categorical_crossentropy: -27.1368 - accuracy: 0.8098 - val_loss: 3.2155 - val_categorical_crossentropy: 1.2309 - val_accuracy: 0.6012\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3392 - categorical_crossentropy: -27.0873 - accuracy: 0.8087 - val_loss: 3.6527 - val_categorical_crossentropy: 1.2701 - val_accuracy: 0.5863\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3322 - categorical_crossentropy: -27.2002 - accuracy: 0.8143 - val_loss: 3.3960 - val_categorical_crossentropy: 1.2192 - val_accuracy: 0.6125\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3415 - categorical_crossentropy: -27.1147 - accuracy: 0.8134 - val_loss: 3.3232 - val_categorical_crossentropy: 1.2237 - val_accuracy: 0.6062\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.3341 - categorical_crossentropy: -27.1268 - accuracy: 0.8149INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 22.15.58/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 29s 147ms/step - loss: 0.3341 - categorical_crossentropy: -27.1268 - accuracy: 0.8149 - val_loss: 3.4124 - val_categorical_crossentropy: 1.2246 - val_accuracy: 0.6288\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3308 - categorical_crossentropy: -27.1863 - accuracy: 0.8112 - val_loss: 3.4236 - val_categorical_crossentropy: 1.2332 - val_accuracy: 0.6075\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3426 - categorical_crossentropy: -27.0862 - accuracy: 0.8165 - val_loss: 3.5033 - val_categorical_crossentropy: 1.2477 - val_accuracy: 0.6062\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3300 - categorical_crossentropy: -27.2145 - accuracy: 0.8168 - val_loss: 3.0719 - val_categorical_crossentropy: 1.2171 - val_accuracy: 0.6150\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3257 - categorical_crossentropy: -27.2288 - accuracy: 0.8118 - val_loss: 3.1503 - val_categorical_crossentropy: 1.2279 - val_accuracy: 0.6062\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.3233 - categorical_crossentropy: -27.1943 - accuracy: 0.8234 - val_loss: 3.2342 - val_categorical_crossentropy: 1.2299 - val_accuracy: 0.6112\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3227 - categorical_crossentropy: -27.2015 - accuracy: 0.8182 - val_loss: 3.3025 - val_categorical_crossentropy: 1.2130 - val_accuracy: 0.6175\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3242 - categorical_crossentropy: -27.2655 - accuracy: 0.8196 - val_loss: 3.1292 - val_categorical_crossentropy: 1.2250 - val_accuracy: 0.6075\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3190 - categorical_crossentropy: -27.2562 - accuracy: 0.8235 - val_loss: 3.1459 - val_categorical_crossentropy: 1.2177 - val_accuracy: 0.6100\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3238 - categorical_crossentropy: -27.1887 - accuracy: 0.8191 - val_loss: 3.4191 - val_categorical_crossentropy: 1.2397 - val_accuracy: 0.6075\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3178 - categorical_crossentropy: -27.2691 - accuracy: 0.8146 - val_loss: 3.5076 - val_categorical_crossentropy: 1.2374 - val_accuracy: 0.6075\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3234 - categorical_crossentropy: -27.1791 - accuracy: 0.8213 - val_loss: 3.6536 - val_categorical_crossentropy: 1.2362 - val_accuracy: 0.6050\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3226 - categorical_crossentropy: -27.2267 - accuracy: 0.8141 - val_loss: 3.3354 - val_categorical_crossentropy: 1.2314 - val_accuracy: 0.6100\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3062 - categorical_crossentropy: -27.3337 - accuracy: 0.8199 - val_loss: 3.1995 - val_categorical_crossentropy: 1.2322 - val_accuracy: 0.6100\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3112 - categorical_crossentropy: -27.3045 - accuracy: 0.8166 - val_loss: 3.3089 - val_categorical_crossentropy: 1.2272 - val_accuracy: 0.6075\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3165 - categorical_crossentropy: -27.2466 - accuracy: 0.8155 - val_loss: 3.3357 - val_categorical_crossentropy: 1.2277 - val_accuracy: 0.6125\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3063 - categorical_crossentropy: -27.3160 - accuracy: 0.8244 - val_loss: 3.5327 - val_categorical_crossentropy: 1.2236 - val_accuracy: 0.6137\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3173 - categorical_crossentropy: -27.2728 - accuracy: 0.8218 - val_loss: 3.4274 - val_categorical_crossentropy: 1.2148 - val_accuracy: 0.6100\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3130 - categorical_crossentropy: -27.2823 - accuracy: 0.8155 - val_loss: 3.5146 - val_categorical_crossentropy: 1.2417 - val_accuracy: 0.6012\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3145 - categorical_crossentropy: -27.2539 - accuracy: 0.8229 - val_loss: 3.3185 - val_categorical_crossentropy: 1.2357 - val_accuracy: 0.6175\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3041 - categorical_crossentropy: -27.3206 - accuracy: 0.8179 - val_loss: 3.3738 - val_categorical_crossentropy: 1.2571 - val_accuracy: 0.5938\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3096 - categorical_crossentropy: -27.3190 - accuracy: 0.8284 - val_loss: 3.7844 - val_categorical_crossentropy: 1.2490 - val_accuracy: 0.5962\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3101 - categorical_crossentropy: -27.2752 - accuracy: 0.8160 - val_loss: 3.6162 - val_categorical_crossentropy: 1.2515 - val_accuracy: 0.6087\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3066 - categorical_crossentropy: -27.3268 - accuracy: 0.8188 - val_loss: 3.4284 - val_categorical_crossentropy: 1.2384 - val_accuracy: 0.6037\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3041 - categorical_crossentropy: -27.3276 - accuracy: 0.8148 - val_loss: 3.2661 - val_categorical_crossentropy: 1.2354 - val_accuracy: 0.6187\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3061 - categorical_crossentropy: -27.3239 - accuracy: 0.8221 - val_loss: 3.4132 - val_categorical_crossentropy: 1.2411 - val_accuracy: 0.6125\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.2964 - categorical_crossentropy: -27.3635 - accuracy: 0.8210 - val_loss: 3.5944 - val_categorical_crossentropy: 1.2516 - val_accuracy: 0.6050\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3004 - categorical_crossentropy: -27.3507 - accuracy: 0.8196 - val_loss: 3.3872 - val_categorical_crossentropy: 1.2296 - val_accuracy: 0.6225\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.2942 - categorical_crossentropy: -27.3777 - accuracy: 0.8277 - val_loss: 3.4970 - val_categorical_crossentropy: 1.2259 - val_accuracy: 0.6100\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3016 - categorical_crossentropy: -27.3371 - accuracy: 0.8218 - val_loss: 3.2607 - val_categorical_crossentropy: 1.2514 - val_accuracy: 0.5938\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.2944 - categorical_crossentropy: -27.3709 - accuracy: 0.8266 - val_loss: 3.4090 - val_categorical_crossentropy: 1.2411 - val_accuracy: 0.6062\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3035 - categorical_crossentropy: -27.3488 - accuracy: 0.8210 - val_loss: 3.4638 - val_categorical_crossentropy: 1.2551 - val_accuracy: 0.5987\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.3029 - categorical_crossentropy: -27.3301 - accuracy: 0.8243 - val_loss: 3.1826 - val_categorical_crossentropy: 1.2233 - val_accuracy: 0.6175\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.2914 - categorical_crossentropy: -27.4235 - accuracy: 0.8249 - val_loss: 3.5823 - val_categorical_crossentropy: 1.2498 - val_accuracy: 0.6025\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.2921 - categorical_crossentropy: -27.4105 - accuracy: 0.8266 - val_loss: 3.2204 - val_categorical_crossentropy: 1.2267 - val_accuracy: 0.6187\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.2959 - categorical_crossentropy: -27.3550 - accuracy: 0.8293 - val_loss: 3.3624 - val_categorical_crossentropy: 1.2381 - val_accuracy: 0.6075\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.2885 - categorical_crossentropy: -27.4097 - accuracy: 0.8185 - val_loss: 3.2641 - val_categorical_crossentropy: 1.2315 - val_accuracy: 0.6150\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.2939 - categorical_crossentropy: -27.3926 - accuracy: 0.8254 - val_loss: 3.6460 - val_categorical_crossentropy: 1.2414 - val_accuracy: 0.6037\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.2905 - categorical_crossentropy: -27.4287 - accuracy: 0.8323 - val_loss: 3.5829 - val_categorical_crossentropy: 1.2510 - val_accuracy: 0.6025\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.2874 - categorical_crossentropy: -27.4230 - accuracy: 0.8324 - val_loss: 3.1905 - val_categorical_crossentropy: 1.2349 - val_accuracy: 0.6112\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.2889 - categorical_crossentropy: -27.4348 - accuracy: 0.8244 - val_loss: 3.4940 - val_categorical_crossentropy: 1.2424 - val_accuracy: 0.6075\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.2912 - categorical_crossentropy: -27.4013 - accuracy: 0.8288 - val_loss: 3.5027 - val_categorical_crossentropy: 1.2200 - val_accuracy: 0.6037\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.2920 - categorical_crossentropy: -27.3980 - accuracy: 0.8259 - val_loss: 3.4064 - val_categorical_crossentropy: 1.2311 - val_accuracy: 0.6087\n",
            "/content/drive/My Drive/DD2424Files/Results/20-05-15 22.15.58/models_cnn_k2c2_3layer_student\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 16)      160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 16)      64        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 16)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 48, 351, 16)       0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 48, 351, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 351, 32)       4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 351, 32)       128       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 48, 351, 32)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 87, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 87, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 87, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 87, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 87, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 17, 32)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 17, 32)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4352)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 34824     \n",
            "=================================================================\n",
            "Total params: 49,576\n",
            "Trainable params: 49,224\n",
            "Non-trainable params: 352\n",
            "_________________________________________________________________\n",
            "shape of y_s_train: (6397, 8) \n",
            "Epoch 1/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 4.1541 - categorical_crossentropy: -10.0067 - accuracy: 0.2657INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 23.00.11/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 43s 216ms/step - loss: 4.1541 - categorical_crossentropy: -10.0067 - accuracy: 0.2657 - val_loss: 2.1544 - val_categorical_crossentropy: 2.3744 - val_accuracy: 0.1875\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 2.2095 - categorical_crossentropy: -17.4936 - accuracy: 0.4152INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 23.00.11/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 42s 211ms/step - loss: 2.2095 - categorical_crossentropy: -17.4936 - accuracy: 0.4152 - val_loss: 2.2154 - val_categorical_crossentropy: 1.9954 - val_accuracy: 0.2825\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.7465 - categorical_crossentropy: -20.3778 - accuracy: 0.4993INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 23.00.11/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 42s 212ms/step - loss: 1.7465 - categorical_crossentropy: -20.3778 - accuracy: 0.4993 - val_loss: 3.8187 - val_categorical_crossentropy: 1.8369 - val_accuracy: 0.4212\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.4187 - categorical_crossentropy: -22.0519 - accuracy: 0.5650INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 23.00.11/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 43s 216ms/step - loss: 1.4187 - categorical_crossentropy: -22.0519 - accuracy: 0.5650 - val_loss: 2.6422 - val_categorical_crossentropy: 1.4371 - val_accuracy: 0.5300\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 1.2056 - categorical_crossentropy: -23.1963 - accuracy: 0.6009 - val_loss: 3.6221 - val_categorical_crossentropy: 1.4933 - val_accuracy: 0.4925\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 1.0860 - categorical_crossentropy: -23.6427 - accuracy: 0.6256 - val_loss: 3.4896 - val_categorical_crossentropy: 1.4418 - val_accuracy: 0.5163\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.9598 - categorical_crossentropy: -24.1317 - accuracy: 0.6550 - val_loss: 3.2891 - val_categorical_crossentropy: 1.4306 - val_accuracy: 0.5213\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.8815 - categorical_crossentropy: -24.3899 - accuracy: 0.6675INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 23.00.11/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 42s 212ms/step - loss: 0.8815 - categorical_crossentropy: -24.3899 - accuracy: 0.6675 - val_loss: 3.3924 - val_categorical_crossentropy: 1.3785 - val_accuracy: 0.5475\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.8034 - categorical_crossentropy: -24.8349 - accuracy: 0.6889 - val_loss: 3.6195 - val_categorical_crossentropy: 1.4302 - val_accuracy: 0.5462\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.7522 - categorical_crossentropy: -25.0177 - accuracy: 0.7006 - val_loss: 2.8280 - val_categorical_crossentropy: 1.3346 - val_accuracy: 0.5475\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.7171 - categorical_crossentropy: -25.1201 - accuracy: 0.7078 - val_loss: 3.6885 - val_categorical_crossentropy: 1.3873 - val_accuracy: 0.5350\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6624 - categorical_crossentropy: -25.4445 - accuracy: 0.7177INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 23.00.11/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 42s 212ms/step - loss: 0.6624 - categorical_crossentropy: -25.4445 - accuracy: 0.7177 - val_loss: 3.0275 - val_categorical_crossentropy: 1.3366 - val_accuracy: 0.5600\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6397 - categorical_crossentropy: -25.4683 - accuracy: 0.7194INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 23.00.11/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 42s 212ms/step - loss: 0.6397 - categorical_crossentropy: -25.4683 - accuracy: 0.7194 - val_loss: 3.0822 - val_categorical_crossentropy: 1.3029 - val_accuracy: 0.5800\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.6035 - categorical_crossentropy: -25.6786 - accuracy: 0.7369 - val_loss: 3.3754 - val_categorical_crossentropy: 1.3279 - val_accuracy: 0.5638\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.5893 - categorical_crossentropy: -25.7736 - accuracy: 0.7425 - val_loss: 3.0719 - val_categorical_crossentropy: 1.2826 - val_accuracy: 0.5725\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.5790 - categorical_crossentropy: -25.8185 - accuracy: 0.7396 - val_loss: 3.6809 - val_categorical_crossentropy: 1.3888 - val_accuracy: 0.5350\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.5385 - categorical_crossentropy: -26.0027 - accuracy: 0.7530 - val_loss: 3.5761 - val_categorical_crossentropy: 1.3636 - val_accuracy: 0.5638\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.5586 - categorical_crossentropy: -25.8920 - accuracy: 0.7477 - val_loss: 3.0877 - val_categorical_crossentropy: 1.3018 - val_accuracy: 0.5750\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5151 - categorical_crossentropy: -26.1300 - accuracy: 0.7560INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 23.00.11/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 42s 211ms/step - loss: 0.5151 - categorical_crossentropy: -26.1300 - accuracy: 0.7560 - val_loss: 3.1114 - val_categorical_crossentropy: 1.2696 - val_accuracy: 0.5863\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5067 - categorical_crossentropy: -26.1278 - accuracy: 0.7622INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 23.00.11/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 43s 216ms/step - loss: 0.5067 - categorical_crossentropy: -26.1278 - accuracy: 0.7622 - val_loss: 3.2408 - val_categorical_crossentropy: 1.2530 - val_accuracy: 0.5987\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.4984 - categorical_crossentropy: -26.2894 - accuracy: 0.7618 - val_loss: 3.1985 - val_categorical_crossentropy: 1.2654 - val_accuracy: 0.5863\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.4796 - categorical_crossentropy: -26.3463 - accuracy: 0.7627 - val_loss: 3.1217 - val_categorical_crossentropy: 1.2959 - val_accuracy: 0.5575\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.4584 - categorical_crossentropy: -26.4443 - accuracy: 0.7696 - val_loss: 3.3886 - val_categorical_crossentropy: 1.2705 - val_accuracy: 0.5950\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.4491 - categorical_crossentropy: -26.5190 - accuracy: 0.7746 - val_loss: 3.2996 - val_categorical_crossentropy: 1.2860 - val_accuracy: 0.5738\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.4463 - categorical_crossentropy: -26.5559 - accuracy: 0.7829 - val_loss: 3.3241 - val_categorical_crossentropy: 1.2556 - val_accuracy: 0.5863\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.4323 - categorical_crossentropy: -26.6158 - accuracy: 0.7891 - val_loss: 3.4759 - val_categorical_crossentropy: 1.3044 - val_accuracy: 0.5512\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.4323 - categorical_crossentropy: -26.6238 - accuracy: 0.7863 - val_loss: 3.1492 - val_categorical_crossentropy: 1.2686 - val_accuracy: 0.5800\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.4225 - categorical_crossentropy: -26.7177 - accuracy: 0.7838 - val_loss: 3.2556 - val_categorical_crossentropy: 1.2778 - val_accuracy: 0.5813\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.4095 - categorical_crossentropy: -26.7562 - accuracy: 0.7907 - val_loss: 3.4468 - val_categorical_crossentropy: 1.2615 - val_accuracy: 0.5913\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.3969 - categorical_crossentropy: -26.8907 - accuracy: 0.7866 - val_loss: 3.1790 - val_categorical_crossentropy: 1.2533 - val_accuracy: 0.5850\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.3991 - categorical_crossentropy: -26.8747 - accuracy: 0.7861 - val_loss: 3.5582 - val_categorical_crossentropy: 1.2966 - val_accuracy: 0.5763\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.3914 - categorical_crossentropy: -26.8830 - accuracy: 0.8015 - val_loss: 3.3248 - val_categorical_crossentropy: 1.2590 - val_accuracy: 0.5800\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.3757 - categorical_crossentropy: -27.0431 - accuracy: 0.7990INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 23.00.11/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 42s 212ms/step - loss: 0.3757 - categorical_crossentropy: -27.0431 - accuracy: 0.7990 - val_loss: 3.3720 - val_categorical_crossentropy: 1.2464 - val_accuracy: 0.6025\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.3784 - categorical_crossentropy: -27.0252 - accuracy: 0.8029 - val_loss: 3.3817 - val_categorical_crossentropy: 1.2610 - val_accuracy: 0.5813\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.3754 - categorical_crossentropy: -26.9860 - accuracy: 0.8057INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 23.00.11/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 42s 211ms/step - loss: 0.3754 - categorical_crossentropy: -26.9860 - accuracy: 0.8057 - val_loss: 3.3597 - val_categorical_crossentropy: 1.2496 - val_accuracy: 0.6075\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.3554 - categorical_crossentropy: -27.1174 - accuracy: 0.8101 - val_loss: 3.5133 - val_categorical_crossentropy: 1.2411 - val_accuracy: 0.6062\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.3474 - categorical_crossentropy: -27.1726 - accuracy: 0.8087 - val_loss: 3.1295 - val_categorical_crossentropy: 1.2421 - val_accuracy: 0.5987\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.3458 - categorical_crossentropy: -27.2339 - accuracy: 0.8069INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 23.00.11/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 42s 211ms/step - loss: 0.3458 - categorical_crossentropy: -27.2339 - accuracy: 0.8069 - val_loss: 3.1040 - val_categorical_crossentropy: 1.2106 - val_accuracy: 0.6162\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.3426 - categorical_crossentropy: -27.2457 - accuracy: 0.8104 - val_loss: 3.5350 - val_categorical_crossentropy: 1.2890 - val_accuracy: 0.5725\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.3551 - categorical_crossentropy: -27.1794 - accuracy: 0.8146 - val_loss: 3.4843 - val_categorical_crossentropy: 1.2505 - val_accuracy: 0.6075\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.3255 - categorical_crossentropy: -27.3670 - accuracy: 0.8207 - val_loss: 3.2857 - val_categorical_crossentropy: 1.2455 - val_accuracy: 0.6050\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.3455 - categorical_crossentropy: -27.2386 - accuracy: 0.8141 - val_loss: 3.4493 - val_categorical_crossentropy: 1.2688 - val_accuracy: 0.5888\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.3361 - categorical_crossentropy: -27.3039 - accuracy: 0.8182 - val_loss: 3.3191 - val_categorical_crossentropy: 1.2183 - val_accuracy: 0.5962\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.3205 - categorical_crossentropy: -27.3789 - accuracy: 0.8166 - val_loss: 3.3854 - val_categorical_crossentropy: 1.2288 - val_accuracy: 0.6012\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.3259 - categorical_crossentropy: -27.3639 - accuracy: 0.8202 - val_loss: 3.2484 - val_categorical_crossentropy: 1.2606 - val_accuracy: 0.6000\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.3258 - categorical_crossentropy: -27.3717 - accuracy: 0.8182INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-15 23.00.11/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 43s 215ms/step - loss: 0.3258 - categorical_crossentropy: -27.3717 - accuracy: 0.8182 - val_loss: 3.0360 - val_categorical_crossentropy: 1.2105 - val_accuracy: 0.6175\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.3319 - categorical_crossentropy: -27.3108 - accuracy: 0.8259 - val_loss: 3.3918 - val_categorical_crossentropy: 1.2428 - val_accuracy: 0.5938\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.3196 - categorical_crossentropy: -27.3701 - accuracy: 0.8318 - val_loss: 3.3660 - val_categorical_crossentropy: 1.2189 - val_accuracy: 0.6037\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.3188 - categorical_crossentropy: -27.4638 - accuracy: 0.8213 - val_loss: 3.4461 - val_categorical_crossentropy: 1.2499 - val_accuracy: 0.5900\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2972 - categorical_crossentropy: -27.5061 - accuracy: 0.8259 - val_loss: 3.3459 - val_categorical_crossentropy: 1.2129 - val_accuracy: 0.6087\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.3091 - categorical_crossentropy: -27.4481 - accuracy: 0.8260 - val_loss: 3.6709 - val_categorical_crossentropy: 1.2528 - val_accuracy: 0.5863\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2916 - categorical_crossentropy: -27.5682 - accuracy: 0.8323 - val_loss: 3.1922 - val_categorical_crossentropy: 1.2299 - val_accuracy: 0.6050\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2980 - categorical_crossentropy: -27.5714 - accuracy: 0.8324 - val_loss: 3.1949 - val_categorical_crossentropy: 1.2057 - val_accuracy: 0.6137\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2874 - categorical_crossentropy: -27.5876 - accuracy: 0.8357 - val_loss: 3.1334 - val_categorical_crossentropy: 1.2393 - val_accuracy: 0.6075\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2950 - categorical_crossentropy: -27.5513 - accuracy: 0.8354 - val_loss: 3.2982 - val_categorical_crossentropy: 1.2283 - val_accuracy: 0.6100\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2941 - categorical_crossentropy: -27.5928 - accuracy: 0.8327 - val_loss: 3.3345 - val_categorical_crossentropy: 1.2111 - val_accuracy: 0.6137\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2904 - categorical_crossentropy: -27.5589 - accuracy: 0.8315 - val_loss: 3.4101 - val_categorical_crossentropy: 1.2357 - val_accuracy: 0.6112\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2835 - categorical_crossentropy: -27.6414 - accuracy: 0.8307 - val_loss: 2.9704 - val_categorical_crossentropy: 1.2158 - val_accuracy: 0.6137\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2902 - categorical_crossentropy: -27.5832 - accuracy: 0.8293 - val_loss: 3.2831 - val_categorical_crossentropy: 1.2234 - val_accuracy: 0.5962\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2823 - categorical_crossentropy: -27.6094 - accuracy: 0.8307 - val_loss: 3.2538 - val_categorical_crossentropy: 1.2179 - val_accuracy: 0.6025\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2753 - categorical_crossentropy: -27.6382 - accuracy: 0.8305 - val_loss: 3.5834 - val_categorical_crossentropy: 1.2794 - val_accuracy: 0.5938\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2790 - categorical_crossentropy: -27.6653 - accuracy: 0.8279 - val_loss: 3.3825 - val_categorical_crossentropy: 1.2277 - val_accuracy: 0.6087\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2806 - categorical_crossentropy: -27.6706 - accuracy: 0.8334 - val_loss: 3.3115 - val_categorical_crossentropy: 1.2264 - val_accuracy: 0.5900\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2676 - categorical_crossentropy: -27.7123 - accuracy: 0.8373 - val_loss: 3.4456 - val_categorical_crossentropy: 1.2497 - val_accuracy: 0.5913\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2764 - categorical_crossentropy: -27.7126 - accuracy: 0.8363 - val_loss: 2.9635 - val_categorical_crossentropy: 1.2171 - val_accuracy: 0.5975\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2669 - categorical_crossentropy: -27.6883 - accuracy: 0.8393 - val_loss: 3.2936 - val_categorical_crossentropy: 1.2066 - val_accuracy: 0.6137\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2643 - categorical_crossentropy: -27.7301 - accuracy: 0.8407 - val_loss: 3.3738 - val_categorical_crossentropy: 1.2361 - val_accuracy: 0.5875\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2702 - categorical_crossentropy: -27.6962 - accuracy: 0.8434 - val_loss: 3.4533 - val_categorical_crossentropy: 1.2263 - val_accuracy: 0.6075\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2700 - categorical_crossentropy: -27.6922 - accuracy: 0.8445 - val_loss: 3.4319 - val_categorical_crossentropy: 1.2052 - val_accuracy: 0.6037\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2619 - categorical_crossentropy: -27.7612 - accuracy: 0.8454 - val_loss: 3.3584 - val_categorical_crossentropy: 1.2452 - val_accuracy: 0.5938\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2590 - categorical_crossentropy: -27.7480 - accuracy: 0.8368 - val_loss: 3.4987 - val_categorical_crossentropy: 1.2352 - val_accuracy: 0.5987\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2673 - categorical_crossentropy: -27.7156 - accuracy: 0.8380 - val_loss: 3.4199 - val_categorical_crossentropy: 1.2163 - val_accuracy: 0.6100\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2648 - categorical_crossentropy: -27.6835 - accuracy: 0.8388 - val_loss: 3.5359 - val_categorical_crossentropy: 1.2318 - val_accuracy: 0.6025\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2552 - categorical_crossentropy: -27.7853 - accuracy: 0.8487 - val_loss: 3.4209 - val_categorical_crossentropy: 1.2283 - val_accuracy: 0.6037\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2525 - categorical_crossentropy: -27.7976 - accuracy: 0.8434 - val_loss: 3.3329 - val_categorical_crossentropy: 1.2094 - val_accuracy: 0.6175\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2529 - categorical_crossentropy: -27.7857 - accuracy: 0.8431 - val_loss: 3.4526 - val_categorical_crossentropy: 1.2394 - val_accuracy: 0.5987\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2611 - categorical_crossentropy: -27.7500 - accuracy: 0.8463 - val_loss: 3.4720 - val_categorical_crossentropy: 1.2397 - val_accuracy: 0.6012\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2500 - categorical_crossentropy: -27.7834 - accuracy: 0.8493 - val_loss: 3.6359 - val_categorical_crossentropy: 1.2578 - val_accuracy: 0.5950\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2566 - categorical_crossentropy: -27.7933 - accuracy: 0.8446 - val_loss: 3.3272 - val_categorical_crossentropy: 1.2187 - val_accuracy: 0.6087\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2551 - categorical_crossentropy: -27.7674 - accuracy: 0.8390 - val_loss: 3.5186 - val_categorical_crossentropy: 1.2339 - val_accuracy: 0.6075\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2465 - categorical_crossentropy: -27.8067 - accuracy: 0.8473 - val_loss: 3.3055 - val_categorical_crossentropy: 1.2010 - val_accuracy: 0.6075\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2410 - categorical_crossentropy: -27.8569 - accuracy: 0.8474 - val_loss: 3.3028 - val_categorical_crossentropy: 1.2099 - val_accuracy: 0.6125\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2427 - categorical_crossentropy: -27.8394 - accuracy: 0.8445 - val_loss: 3.2543 - val_categorical_crossentropy: 1.2064 - val_accuracy: 0.6125\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2400 - categorical_crossentropy: -27.8534 - accuracy: 0.8496 - val_loss: 3.2304 - val_categorical_crossentropy: 1.2196 - val_accuracy: 0.6062\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2432 - categorical_crossentropy: -27.8664 - accuracy: 0.8474 - val_loss: 3.4552 - val_categorical_crossentropy: 1.2418 - val_accuracy: 0.5813\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2409 - categorical_crossentropy: -27.8329 - accuracy: 0.8506 - val_loss: 3.2505 - val_categorical_crossentropy: 1.2276 - val_accuracy: 0.6012\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2420 - categorical_crossentropy: -27.8508 - accuracy: 0.8516 - val_loss: 3.2457 - val_categorical_crossentropy: 1.2149 - val_accuracy: 0.6087\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2372 - categorical_crossentropy: -27.8783 - accuracy: 0.8506 - val_loss: 3.2171 - val_categorical_crossentropy: 1.2194 - val_accuracy: 0.6062\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2416 - categorical_crossentropy: -27.8154 - accuracy: 0.8485 - val_loss: 3.5840 - val_categorical_crossentropy: 1.2260 - val_accuracy: 0.6037\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2346 - categorical_crossentropy: -27.8972 - accuracy: 0.8488 - val_loss: 3.2578 - val_categorical_crossentropy: 1.2069 - val_accuracy: 0.6087\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2311 - categorical_crossentropy: -27.9136 - accuracy: 0.8468 - val_loss: 3.1515 - val_categorical_crossentropy: 1.1977 - val_accuracy: 0.6137\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2255 - categorical_crossentropy: -27.9039 - accuracy: 0.8552 - val_loss: 3.6689 - val_categorical_crossentropy: 1.2401 - val_accuracy: 0.6025\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2321 - categorical_crossentropy: -27.9263 - accuracy: 0.8532 - val_loss: 3.2800 - val_categorical_crossentropy: 1.2181 - val_accuracy: 0.6137\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2348 - categorical_crossentropy: -27.8593 - accuracy: 0.8488 - val_loss: 3.4066 - val_categorical_crossentropy: 1.2306 - val_accuracy: 0.6075\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2321 - categorical_crossentropy: -27.9227 - accuracy: 0.8521 - val_loss: 3.1754 - val_categorical_crossentropy: 1.2171 - val_accuracy: 0.6050\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2249 - categorical_crossentropy: -27.9148 - accuracy: 0.8548 - val_loss: 3.1765 - val_categorical_crossentropy: 1.2046 - val_accuracy: 0.6062\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2240 - categorical_crossentropy: -27.9393 - accuracy: 0.8535 - val_loss: 3.3380 - val_categorical_crossentropy: 1.2108 - val_accuracy: 0.6050\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2235 - categorical_crossentropy: -27.9593 - accuracy: 0.8482 - val_loss: 3.1056 - val_categorical_crossentropy: 1.2179 - val_accuracy: 0.6000\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 39s 197ms/step - loss: 0.2304 - categorical_crossentropy: -27.8750 - accuracy: 0.8577 - val_loss: 3.3256 - val_categorical_crossentropy: 1.2182 - val_accuracy: 0.6037\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 39s 196ms/step - loss: 0.2314 - categorical_crossentropy: -27.8805 - accuracy: 0.8506 - val_loss: 3.3175 - val_categorical_crossentropy: 1.2228 - val_accuracy: 0.6125\n",
            "/content/drive/My Drive/DD2424Files/Results/20-05-15 23.00.11/models_cnn_k2c2_3layer_student\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 27)      270       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 27)      108       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 27)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 48, 351, 27)       0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 48, 351, 27)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 351, 54)       13176     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 351, 54)       216       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 48, 351, 54)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 87, 54)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 87, 54)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 87, 54)        26298     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 87, 54)        216       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 87, 54)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 17, 54)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 17, 54)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 7344)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 58760     \n",
            "=================================================================\n",
            "Total params: 99,428\n",
            "Trainable params: 98,966\n",
            "Non-trainable params: 462\n",
            "_________________________________________________________________\n",
            "shape of y_s_train: (6397, 8) \n",
            "Epoch 1/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 8.2805 - categorical_crossentropy: -8.7929 - accuracy: 0.2071INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-16 00.07.14/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 82s 409ms/step - loss: 8.2805 - categorical_crossentropy: -8.7929 - accuracy: 0.2071 - val_loss: 0.7908 - val_categorical_crossentropy: 1.8556 - val_accuracy: 0.3113\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 3.6732 - categorical_crossentropy: -10.8368 - accuracy: 0.2589 - val_loss: 0.8754 - val_categorical_crossentropy: 1.8647 - val_accuracy: 0.3025\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 3.2601 - categorical_crossentropy: -13.8684 - accuracy: 0.3170INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-16 00.07.14/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 80s 399ms/step - loss: 3.2601 - categorical_crossentropy: -13.8684 - accuracy: 0.3170 - val_loss: 1.3402 - val_categorical_crossentropy: 1.7463 - val_accuracy: 0.3462\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 2.4870 - categorical_crossentropy: -18.5271 - accuracy: 0.3980INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-16 00.07.14/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 80s 400ms/step - loss: 2.4870 - categorical_crossentropy: -18.5271 - accuracy: 0.3980 - val_loss: 2.4012 - val_categorical_crossentropy: 1.7449 - val_accuracy: 0.3475\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 2.0961 - categorical_crossentropy: -19.9762 - accuracy: 0.4571INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-16 00.07.14/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 81s 404ms/step - loss: 2.0961 - categorical_crossentropy: -19.9762 - accuracy: 0.4571 - val_loss: 3.0872 - val_categorical_crossentropy: 1.7431 - val_accuracy: 0.3862\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.8381 - categorical_crossentropy: -21.0238 - accuracy: 0.4996INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-16 00.07.14/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 80s 400ms/step - loss: 1.8381 - categorical_crossentropy: -21.0238 - accuracy: 0.4996 - val_loss: 3.4863 - val_categorical_crossentropy: 1.6117 - val_accuracy: 0.4450\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 1.5957 - categorical_crossentropy: -21.7241 - accuracy: 0.5365 - val_loss: 2.9216 - val_categorical_crossentropy: 1.6043 - val_accuracy: 0.4225\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.4501 - categorical_crossentropy: -22.3476 - accuracy: 0.5612INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-16 00.07.14/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 80s 400ms/step - loss: 1.4501 - categorical_crossentropy: -22.3476 - accuracy: 0.5612 - val_loss: 3.2749 - val_categorical_crossentropy: 1.5170 - val_accuracy: 0.4787\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3161 - categorical_crossentropy: -22.7469 - accuracy: 0.5876INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-16 00.07.14/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 80s 400ms/step - loss: 1.3161 - categorical_crossentropy: -22.7469 - accuracy: 0.5876 - val_loss: 3.0005 - val_categorical_crossentropy: 1.4846 - val_accuracy: 0.4963\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 1.1826 - categorical_crossentropy: -23.2218 - accuracy: 0.6111 - val_loss: 3.1492 - val_categorical_crossentropy: 1.5606 - val_accuracy: 0.4613\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 1.0931 - categorical_crossentropy: -23.4832 - accuracy: 0.6326 - val_loss: 3.4289 - val_categorical_crossentropy: 1.5344 - val_accuracy: 0.4737\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.0045 - categorical_crossentropy: -23.9668 - accuracy: 0.6436INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-16 00.07.14/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 80s 400ms/step - loss: 1.0045 - categorical_crossentropy: -23.9668 - accuracy: 0.6436 - val_loss: 2.6918 - val_categorical_crossentropy: 1.4104 - val_accuracy: 0.5337\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.9653 - categorical_crossentropy: -24.1200 - accuracy: 0.6522 - val_loss: 3.5200 - val_categorical_crossentropy: 1.4456 - val_accuracy: 0.5288\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.8800 - categorical_crossentropy: -24.4509 - accuracy: 0.6722INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-16 00.07.14/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 81s 404ms/step - loss: 0.8800 - categorical_crossentropy: -24.4509 - accuracy: 0.6722 - val_loss: 2.8883 - val_categorical_crossentropy: 1.3827 - val_accuracy: 0.5537\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.8435 - categorical_crossentropy: -24.6604 - accuracy: 0.6849 - val_loss: 3.9135 - val_categorical_crossentropy: 1.5426 - val_accuracy: 0.4863\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 77s 384ms/step - loss: 0.8168 - categorical_crossentropy: -24.7120 - accuracy: 0.6888 - val_loss: 3.0869 - val_categorical_crossentropy: 1.3512 - val_accuracy: 0.5487\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 77s 384ms/step - loss: 0.7665 - categorical_crossentropy: -24.9249 - accuracy: 0.6989 - val_loss: 3.4055 - val_categorical_crossentropy: 1.4107 - val_accuracy: 0.5387\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.7221 - categorical_crossentropy: -25.1597 - accuracy: 0.7117 - val_loss: 3.4528 - val_categorical_crossentropy: 1.3735 - val_accuracy: 0.5487\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.7269 - categorical_crossentropy: -25.1668 - accuracy: 0.7133INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-16 00.07.14/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 80s 400ms/step - loss: 0.7269 - categorical_crossentropy: -25.1668 - accuracy: 0.7133 - val_loss: 3.3385 - val_categorical_crossentropy: 1.3661 - val_accuracy: 0.5638\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.6867 - categorical_crossentropy: -25.3474 - accuracy: 0.7244 - val_loss: 3.1209 - val_categorical_crossentropy: 1.3518 - val_accuracy: 0.5638\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6288 - categorical_crossentropy: -25.5072 - accuracy: 0.7255INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-16 00.07.14/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 80s 400ms/step - loss: 0.6288 - categorical_crossentropy: -25.5072 - accuracy: 0.7255 - val_loss: 3.3312 - val_categorical_crossentropy: 1.3483 - val_accuracy: 0.5700\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.6140 - categorical_crossentropy: -25.7667 - accuracy: 0.7428 - val_loss: 3.1351 - val_categorical_crossentropy: 1.3149 - val_accuracy: 0.5663\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6103 - categorical_crossentropy: -25.6651 - accuracy: 0.7468INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-16 00.07.14/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 80s 400ms/step - loss: 0.6103 - categorical_crossentropy: -25.6651 - accuracy: 0.7468 - val_loss: 3.0185 - val_categorical_crossentropy: 1.3619 - val_accuracy: 0.5725\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6039 - categorical_crossentropy: -25.7574 - accuracy: 0.7397INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-16 00.07.14/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 81s 404ms/step - loss: 0.6039 - categorical_crossentropy: -25.7574 - accuracy: 0.7397 - val_loss: 2.9762 - val_categorical_crossentropy: 1.3414 - val_accuracy: 0.5775\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.5691 - categorical_crossentropy: -25.9028 - accuracy: 0.7539 - val_loss: 3.1101 - val_categorical_crossentropy: 1.3075 - val_accuracy: 0.5587\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.5787 - categorical_crossentropy: -25.8629 - accuracy: 0.7513 - val_loss: 3.1734 - val_categorical_crossentropy: 1.3229 - val_accuracy: 0.5638\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.5556 - categorical_crossentropy: -26.0301 - accuracy: 0.7582 - val_loss: 3.1894 - val_categorical_crossentropy: 1.3153 - val_accuracy: 0.5688\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.5478 - categorical_crossentropy: -26.0867 - accuracy: 0.7508 - val_loss: 3.1635 - val_categorical_crossentropy: 1.2824 - val_accuracy: 0.5688\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5426 - categorical_crossentropy: -26.0737 - accuracy: 0.7618INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-16 00.07.14/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 80s 400ms/step - loss: 0.5426 - categorical_crossentropy: -26.0737 - accuracy: 0.7618 - val_loss: 2.8159 - val_categorical_crossentropy: 1.2635 - val_accuracy: 0.5813\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.5288 - categorical_crossentropy: -26.1917 - accuracy: 0.7558 - val_loss: 3.3556 - val_categorical_crossentropy: 1.3000 - val_accuracy: 0.5663\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5156 - categorical_crossentropy: -26.2715 - accuracy: 0.7574INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-16 00.07.14/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 80s 401ms/step - loss: 0.5156 - categorical_crossentropy: -26.2715 - accuracy: 0.7574 - val_loss: 3.3659 - val_categorical_crossentropy: 1.2652 - val_accuracy: 0.6000\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5038 - categorical_crossentropy: -26.3745 - accuracy: 0.7643INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-16 00.07.14/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 80s 400ms/step - loss: 0.5038 - categorical_crossentropy: -26.3745 - accuracy: 0.7643 - val_loss: 2.8079 - val_categorical_crossentropy: 1.2109 - val_accuracy: 0.6025\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.5011 - categorical_crossentropy: -26.3817 - accuracy: 0.7691 - val_loss: 3.3946 - val_categorical_crossentropy: 1.2738 - val_accuracy: 0.5775\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.4529 - categorical_crossentropy: -26.5547 - accuracy: 0.7707 - val_loss: 3.5134 - val_categorical_crossentropy: 1.2897 - val_accuracy: 0.5750\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.4533 - categorical_crossentropy: -26.6278 - accuracy: 0.7780INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-16 00.07.14/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 80s 400ms/step - loss: 0.4533 - categorical_crossentropy: -26.6278 - accuracy: 0.7780 - val_loss: 3.0293 - val_categorical_crossentropy: 1.2126 - val_accuracy: 0.6137\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.4759 - categorical_crossentropy: -26.4908 - accuracy: 0.7724 - val_loss: 3.2559 - val_categorical_crossentropy: 1.2257 - val_accuracy: 0.5925\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.4557 - categorical_crossentropy: -26.5791 - accuracy: 0.7843 - val_loss: 3.2826 - val_categorical_crossentropy: 1.2100 - val_accuracy: 0.5975\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.4494 - categorical_crossentropy: -26.6119 - accuracy: 0.7865 - val_loss: 3.1941 - val_categorical_crossentropy: 1.2080 - val_accuracy: 0.5925\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 77s 384ms/step - loss: 0.4147 - categorical_crossentropy: -26.8389 - accuracy: 0.7912 - val_loss: 3.3172 - val_categorical_crossentropy: 1.2471 - val_accuracy: 0.5950\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.4434 - categorical_crossentropy: -26.6992 - accuracy: 0.7836 - val_loss: 3.4205 - val_categorical_crossentropy: 1.2565 - val_accuracy: 0.5938\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 77s 384ms/step - loss: 0.4055 - categorical_crossentropy: -26.8613 - accuracy: 0.7946 - val_loss: 3.2682 - val_categorical_crossentropy: 1.2476 - val_accuracy: 0.5913\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.4221 - categorical_crossentropy: -26.7992 - accuracy: 0.7937 - val_loss: 3.4472 - val_categorical_crossentropy: 1.2500 - val_accuracy: 0.5888\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.4009 - categorical_crossentropy: -26.9045 - accuracy: 0.7941 - val_loss: 3.3269 - val_categorical_crossentropy: 1.2449 - val_accuracy: 0.6050\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.3945 - categorical_crossentropy: -26.9525 - accuracy: 0.8010 - val_loss: 3.2555 - val_categorical_crossentropy: 1.2278 - val_accuracy: 0.6112\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.3934 - categorical_crossentropy: -26.9532 - accuracy: 0.7982 - val_loss: 2.8752 - val_categorical_crossentropy: 1.2340 - val_accuracy: 0.5975\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.3884 - categorical_crossentropy: -26.9471 - accuracy: 0.8013 - val_loss: 3.7746 - val_categorical_crossentropy: 1.3113 - val_accuracy: 0.5600\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.3839 - categorical_crossentropy: -26.9858 - accuracy: 0.7980 - val_loss: 2.9840 - val_categorical_crossentropy: 1.2422 - val_accuracy: 0.6112\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.3658 - categorical_crossentropy: -27.1412 - accuracy: 0.8044 - val_loss: 3.3563 - val_categorical_crossentropy: 1.2384 - val_accuracy: 0.6025\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.3734 - categorical_crossentropy: -27.0573 - accuracy: 0.8082 - val_loss: 3.5436 - val_categorical_crossentropy: 1.2656 - val_accuracy: 0.5913\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.3702 - categorical_crossentropy: -27.0918 - accuracy: 0.8069 - val_loss: 3.0719 - val_categorical_crossentropy: 1.2050 - val_accuracy: 0.6075\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.3696 - categorical_crossentropy: -27.0956 - accuracy: 0.8113 - val_loss: 3.2854 - val_categorical_crossentropy: 1.2215 - val_accuracy: 0.6050\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.3598 - categorical_crossentropy: -27.1597 - accuracy: 0.8112 - val_loss: 3.0661 - val_categorical_crossentropy: 1.2203 - val_accuracy: 0.6075\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.3599 - categorical_crossentropy: -27.1385 - accuracy: 0.8105 - val_loss: 3.3973 - val_categorical_crossentropy: 1.2120 - val_accuracy: 0.6037\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.3478 - categorical_crossentropy: -27.2168 - accuracy: 0.8116 - val_loss: 3.3593 - val_categorical_crossentropy: 1.1975 - val_accuracy: 0.6037\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.3485 - categorical_crossentropy: -27.2239 - accuracy: 0.8107 - val_loss: 3.1225 - val_categorical_crossentropy: 1.2227 - val_accuracy: 0.6112\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.3607 - categorical_crossentropy: -27.1308 - accuracy: 0.8101INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-16 00.07.14/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 81s 404ms/step - loss: 0.3607 - categorical_crossentropy: -27.1308 - accuracy: 0.8101 - val_loss: 3.3047 - val_categorical_crossentropy: 1.2037 - val_accuracy: 0.6150\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.3446 - categorical_crossentropy: -27.2417 - accuracy: 0.8112 - val_loss: 3.3456 - val_categorical_crossentropy: 1.2073 - val_accuracy: 0.6025\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.3398 - categorical_crossentropy: -27.3247 - accuracy: 0.8155 - val_loss: 3.2838 - val_categorical_crossentropy: 1.2320 - val_accuracy: 0.6137\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.3531 - categorical_crossentropy: -27.1667 - accuracy: 0.8116 - val_loss: 3.3431 - val_categorical_crossentropy: 1.2289 - val_accuracy: 0.6087\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.3300 - categorical_crossentropy: -27.3247 - accuracy: 0.8182 - val_loss: 3.1126 - val_categorical_crossentropy: 1.2105 - val_accuracy: 0.6125\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.3305 - categorical_crossentropy: -27.3336 - accuracy: 0.8205 - val_loss: 3.2389 - val_categorical_crossentropy: 1.2157 - val_accuracy: 0.6000\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.3353 - categorical_crossentropy: -27.2831 - accuracy: 0.8149 - val_loss: 3.4490 - val_categorical_crossentropy: 1.2094 - val_accuracy: 0.6087\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.3253 - categorical_crossentropy: -27.2893 - accuracy: 0.8226 - val_loss: 3.7054 - val_categorical_crossentropy: 1.2351 - val_accuracy: 0.5888\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.3330 - categorical_crossentropy: -27.3360 - accuracy: 0.8194 - val_loss: 3.0349 - val_categorical_crossentropy: 1.2167 - val_accuracy: 0.6012\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.3221 - categorical_crossentropy: -27.3769 - accuracy: 0.8240 - val_loss: 3.1858 - val_categorical_crossentropy: 1.2136 - val_accuracy: 0.6050\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.3240 - categorical_crossentropy: -27.3101 - accuracy: 0.8177 - val_loss: 3.1712 - val_categorical_crossentropy: 1.2430 - val_accuracy: 0.5900\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.3094 - categorical_crossentropy: -27.4248 - accuracy: 0.8288 - val_loss: 3.4630 - val_categorical_crossentropy: 1.2102 - val_accuracy: 0.5987\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.3157 - categorical_crossentropy: -27.3557 - accuracy: 0.8246 - val_loss: 3.5129 - val_categorical_crossentropy: 1.2157 - val_accuracy: 0.6025\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.3115 - categorical_crossentropy: -27.4364 - accuracy: 0.8248 - val_loss: 3.4257 - val_categorical_crossentropy: 1.2150 - val_accuracy: 0.6000\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.3059 - categorical_crossentropy: -27.4684 - accuracy: 0.8249 - val_loss: 3.0464 - val_categorical_crossentropy: 1.2007 - val_accuracy: 0.6087\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.3107 - categorical_crossentropy: -27.3883 - accuracy: 0.8246 - val_loss: 3.0510 - val_categorical_crossentropy: 1.2019 - val_accuracy: 0.6150\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.3027 - categorical_crossentropy: -27.4795 - accuracy: 0.8246 - val_loss: 3.3667 - val_categorical_crossentropy: 1.2325 - val_accuracy: 0.6100\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.3054 - categorical_crossentropy: -27.4117 - accuracy: 0.8280 - val_loss: 3.2946 - val_categorical_crossentropy: 1.2089 - val_accuracy: 0.6037\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.3036 - categorical_crossentropy: -27.4774 - accuracy: 0.8273 - val_loss: 3.3403 - val_categorical_crossentropy: 1.2025 - val_accuracy: 0.6112\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.2958 - categorical_crossentropy: -27.5082 - accuracy: 0.8302 - val_loss: 3.1837 - val_categorical_crossentropy: 1.2057 - val_accuracy: 0.6012\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.2894 - categorical_crossentropy: -27.5166 - accuracy: 0.8335 - val_loss: 3.4912 - val_categorical_crossentropy: 1.2162 - val_accuracy: 0.6025\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.2973 - categorical_crossentropy: -27.4665 - accuracy: 0.8290 - val_loss: 3.4214 - val_categorical_crossentropy: 1.2169 - val_accuracy: 0.5938\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.2931 - categorical_crossentropy: -27.5026 - accuracy: 0.8351 - val_loss: 3.2244 - val_categorical_crossentropy: 1.1996 - val_accuracy: 0.6062\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.2981 - categorical_crossentropy: -27.5026 - accuracy: 0.8354INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-16 00.07.14/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 80s 401ms/step - loss: 0.2981 - categorical_crossentropy: -27.5026 - accuracy: 0.8354 - val_loss: 3.2465 - val_categorical_crossentropy: 1.1999 - val_accuracy: 0.6162\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.2836 - categorical_crossentropy: -27.5432 - accuracy: 0.8343 - val_loss: 3.5592 - val_categorical_crossentropy: 1.2167 - val_accuracy: 0.5975\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.2921 - categorical_crossentropy: -27.5197 - accuracy: 0.8270 - val_loss: 3.1926 - val_categorical_crossentropy: 1.1894 - val_accuracy: 0.6037\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.2883 - categorical_crossentropy: -27.5116 - accuracy: 0.8352 - val_loss: 3.3797 - val_categorical_crossentropy: 1.1930 - val_accuracy: 0.6100\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.2827 - categorical_crossentropy: -27.5910 - accuracy: 0.8348 - val_loss: 3.3163 - val_categorical_crossentropy: 1.2267 - val_accuracy: 0.6050\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.2844 - categorical_crossentropy: -27.5433 - accuracy: 0.8288 - val_loss: 3.2632 - val_categorical_crossentropy: 1.2052 - val_accuracy: 0.6037\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.2945 - categorical_crossentropy: -27.4833 - accuracy: 0.8307 - val_loss: 3.1156 - val_categorical_crossentropy: 1.1844 - val_accuracy: 0.6112\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.2893 - categorical_crossentropy: -27.5559 - accuracy: 0.8410INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-16 00.07.14/models_cnn_k2c2_3layer_student/assets\n",
            "200/200 [==============================] - 80s 401ms/step - loss: 0.2893 - categorical_crossentropy: -27.5559 - accuracy: 0.8410 - val_loss: 3.2077 - val_categorical_crossentropy: 1.1917 - val_accuracy: 0.6175\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.2816 - categorical_crossentropy: -27.5886 - accuracy: 0.8355 - val_loss: 3.0632 - val_categorical_crossentropy: 1.2003 - val_accuracy: 0.6075\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.2741 - categorical_crossentropy: -27.5714 - accuracy: 0.8380 - val_loss: 3.3581 - val_categorical_crossentropy: 1.1914 - val_accuracy: 0.6050\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.2754 - categorical_crossentropy: -27.6256 - accuracy: 0.8370 - val_loss: 3.4441 - val_categorical_crossentropy: 1.2143 - val_accuracy: 0.5987\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.2680 - categorical_crossentropy: -27.6485 - accuracy: 0.8320 - val_loss: 3.2911 - val_categorical_crossentropy: 1.2033 - val_accuracy: 0.6075\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.2719 - categorical_crossentropy: -27.6264 - accuracy: 0.8401 - val_loss: 3.0330 - val_categorical_crossentropy: 1.1881 - val_accuracy: 0.6112\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.2710 - categorical_crossentropy: -27.5785 - accuracy: 0.8370 - val_loss: 3.2214 - val_categorical_crossentropy: 1.1840 - val_accuracy: 0.6162\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.2718 - categorical_crossentropy: -27.6407 - accuracy: 0.8363 - val_loss: 3.1521 - val_categorical_crossentropy: 1.2004 - val_accuracy: 0.6087\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.2728 - categorical_crossentropy: -27.5700 - accuracy: 0.8371 - val_loss: 3.3452 - val_categorical_crossentropy: 1.1969 - val_accuracy: 0.6075\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.2649 - categorical_crossentropy: -27.6492 - accuracy: 0.8420 - val_loss: 3.3780 - val_categorical_crossentropy: 1.1900 - val_accuracy: 0.6025\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.2689 - categorical_crossentropy: -27.6183 - accuracy: 0.8376 - val_loss: 3.4372 - val_categorical_crossentropy: 1.2319 - val_accuracy: 0.5950\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.2632 - categorical_crossentropy: -27.6933 - accuracy: 0.8377 - val_loss: 3.2431 - val_categorical_crossentropy: 1.1846 - val_accuracy: 0.6075\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 77s 385ms/step - loss: 0.2640 - categorical_crossentropy: -27.6602 - accuracy: 0.8432 - val_loss: 3.1859 - val_categorical_crossentropy: 1.1941 - val_accuracy: 0.6162\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.2632 - categorical_crossentropy: -27.6383 - accuracy: 0.8412 - val_loss: 3.2536 - val_categorical_crossentropy: 1.1830 - val_accuracy: 0.6062\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 77s 386ms/step - loss: 0.2602 - categorical_crossentropy: -27.6956 - accuracy: 0.8363 - val_loss: 3.4060 - val_categorical_crossentropy: 1.2068 - val_accuracy: 0.6100\n",
            "/content/drive/My Drive/DD2424Files/Results/20-05-16 00.07.14/models_cnn_k2c2_3layer_student\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 51)      510       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 51)      204       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 51)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 48, 351, 51)       0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 48, 351, 51)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 351, 101)      46460     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 351, 101)      404       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 48, 351, 101)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 87, 101)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 87, 101)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 87, 101)       91910     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 87, 101)       404       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 87, 101)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 17, 101)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 17, 101)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 13736)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 109896    \n",
            "=================================================================\n",
            "Total params: 250,172\n",
            "Trainable params: 249,474\n",
            "Non-trainable params: 698\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9hgxJ07T6Hh",
        "colab_type": "text"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elKyRtkctwqW",
        "colab_type": "code",
        "outputId": "6e7372a2-83b1-4fb5-bc21-5cbf3c352bb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "# Experiment 1\n",
        "\n",
        "hyperparams = {\"number_filters_1\" : 15,\n",
        "               \"kernel_size_1\" : (1, 4),\n",
        "               \"epsilon\": 0.01, \n",
        "               \"learning_rate\": 0.01, \n",
        "               \"batch_size\": 32, \n",
        "               \"epochs\": 2}\n",
        "\n",
        "model_string = \"cnn15-fc8\"\n",
        "model = cnn1_model(hyperparams)\n",
        "\n",
        "history = run_experiment(model, model_string, hyperparams)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n",
            "(1, 4)\n",
            "Epoch 1/2\n",
            "199/200 [============================>.] - ETA: 0s - loss: 19208.5430 - accuracy: 0.1454INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-11 22.41.10/models_cnn15-fc8/assets\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 19124.6992 - accuracy: 0.1458 - val_loss: 729.0200 - val_accuracy: 0.1737\n",
            "Epoch 2/2\n",
            "199/200 [============================>.] - ETA: 0s - loss: 314.3699 - accuracy: 0.4488INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-11 22.41.10/models_cnn15-fc8/assets\n",
            "200/200 [==============================] - 11s 54ms/step - loss: 314.0475 - accuracy: 0.4491 - val_loss: 607.1850 - val_accuracy: 0.1825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL99OFR973kZ",
        "colab_type": "code",
        "outputId": "813e5471-f0e4-4e26-fb10-846502a0857d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Experiment 2\n",
        "\n",
        "hyperparams = {\"number_filters\" : [15, 15, 30, 30],\n",
        "               \"kernel_size\" : [(1, 4), (1,4), (1,4), (1,4)],\n",
        "               \"pooling_size\" : [(1,4), (1,5), (1,8), (1,8)],\n",
        "               \"hidden_layers\": [30,30],\n",
        "               \"epsilon\": 0.01, \n",
        "               \"learning_rate\": 0.01, \n",
        "               \"batch_size\": 32, \n",
        "               \"epochs\": 100,\n",
        "               \"dropout\" : 0.4,\n",
        "               \"drop_out_hidden\" : 0\n",
        "               }\n",
        "\n",
        "model_string = \"cnn_k1c2\"\n",
        "model = cnn_k1c2_model(hyperparams)\n",
        "\n",
        "history = run_experiment(model, model_string, hyperparams)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 3.6970 - accuracy: 0.2795WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 09.06.11/models_cnn_k1c2/assets\n",
            "200/200 [==============================] - 34s 171ms/step - loss: 3.6970 - accuracy: 0.2795 - val_loss: 1.7947 - val_accuracy: 0.3475\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.7553 - accuracy: 0.3620 - val_loss: 1.7976 - val_accuracy: 0.3450\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - 30s 148ms/step - loss: 1.7365 - accuracy: 0.3661 - val_loss: 1.7836 - val_accuracy: 0.3475\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - 30s 148ms/step - loss: 1.6979 - accuracy: 0.3858 - val_loss: 1.9631 - val_accuracy: 0.3013\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.6431 - accuracy: 0.4058INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 09.06.11/models_cnn_k1c2/assets\n",
            "200/200 [==============================] - 33s 167ms/step - loss: 1.6431 - accuracy: 0.4058 - val_loss: 1.7341 - val_accuracy: 0.3638\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.5547 - accuracy: 0.4416INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 09.06.11/models_cnn_k1c2/assets\n",
            "200/200 [==============================] - 34s 168ms/step - loss: 1.5547 - accuracy: 0.4416 - val_loss: 1.5684 - val_accuracy: 0.4250\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.4940 - accuracy: 0.4646 - val_loss: 1.7661 - val_accuracy: 0.3750\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - 30s 148ms/step - loss: 1.4520 - accuracy: 0.4846 - val_loss: 1.7488 - val_accuracy: 0.3587\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.4175 - accuracy: 0.5015INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 09.06.11/models_cnn_k1c2/assets\n",
            "200/200 [==============================] - 34s 168ms/step - loss: 1.4175 - accuracy: 0.5015 - val_loss: 1.5663 - val_accuracy: 0.4263\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.4063 - accuracy: 0.5040 - val_loss: 1.7619 - val_accuracy: 0.3700\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3658 - accuracy: 0.5151INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 09.06.11/models_cnn_k1c2/assets\n",
            "200/200 [==============================] - 34s 168ms/step - loss: 1.3658 - accuracy: 0.5151 - val_loss: 1.5526 - val_accuracy: 0.4500\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.3669 - accuracy: 0.5252 - val_loss: 1.6336 - val_accuracy: 0.4250\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 30s 148ms/step - loss: 1.3436 - accuracy: 0.5304 - val_loss: 1.5333 - val_accuracy: 0.4462\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3466 - accuracy: 0.5285INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 09.06.11/models_cnn_k1c2/assets\n",
            "200/200 [==============================] - 34s 168ms/step - loss: 1.3466 - accuracy: 0.5285 - val_loss: 1.5389 - val_accuracy: 0.4613\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3332 - accuracy: 0.5388INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 09.06.11/models_cnn_k1c2/assets\n",
            "200/200 [==============================] - 34s 169ms/step - loss: 1.3332 - accuracy: 0.5388 - val_loss: 1.4759 - val_accuracy: 0.5025\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 30s 148ms/step - loss: 1.3421 - accuracy: 0.5343 - val_loss: 1.7871 - val_accuracy: 0.3800\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 30s 148ms/step - loss: 1.3239 - accuracy: 0.5354 - val_loss: 1.5921 - val_accuracy: 0.4400\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3017 - accuracy: 0.5443INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 09.06.11/models_cnn_k1c2/assets\n",
            "200/200 [==============================] - 34s 169ms/step - loss: 1.3017 - accuracy: 0.5443 - val_loss: 1.4276 - val_accuracy: 0.5100\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.3147 - accuracy: 0.5434 - val_loss: 1.4749 - val_accuracy: 0.4825\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.2949 - accuracy: 0.5424INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 09.06.11/models_cnn_k1c2/assets\n",
            "200/200 [==============================] - 34s 169ms/step - loss: 1.2949 - accuracy: 0.5424 - val_loss: 1.4557 - val_accuracy: 0.5113\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.3045 - accuracy: 0.5413 - val_loss: 1.5369 - val_accuracy: 0.4563\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.3070 - accuracy: 0.5428 - val_loss: 1.5273 - val_accuracy: 0.4975\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.2841 - accuracy: 0.5485 - val_loss: 1.5354 - val_accuracy: 0.4900\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.2860 - accuracy: 0.5548 - val_loss: 1.4574 - val_accuracy: 0.4975\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.2703 - accuracy: 0.5524 - val_loss: 1.5822 - val_accuracy: 0.4475\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.2683 - accuracy: 0.5562 - val_loss: 1.5256 - val_accuracy: 0.4775\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.2727 - accuracy: 0.5571 - val_loss: 1.4562 - val_accuracy: 0.5050\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.2585 - accuracy: 0.5535 - val_loss: 1.6048 - val_accuracy: 0.4125\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.2506 - accuracy: 0.5635 - val_loss: 1.5182 - val_accuracy: 0.4900\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.2650 - accuracy: 0.5625 - val_loss: 1.4669 - val_accuracy: 0.4850\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.2497 - accuracy: 0.5673 - val_loss: 1.4621 - val_accuracy: 0.4888\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.2451 - accuracy: 0.5635 - val_loss: 1.5851 - val_accuracy: 0.4425\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 30s 150ms/step - loss: 1.2554 - accuracy: 0.5687 - val_loss: 1.5593 - val_accuracy: 0.4462\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.2355 - accuracy: 0.5721 - val_loss: 1.5510 - val_accuracy: 0.4675\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.2404 - accuracy: 0.5642INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 09.06.11/models_cnn_k1c2/assets\n",
            "200/200 [==============================] - 34s 168ms/step - loss: 1.2404 - accuracy: 0.5642 - val_loss: 1.4725 - val_accuracy: 0.5175\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.2200 - accuracy: 0.5764 - val_loss: 1.5691 - val_accuracy: 0.4725\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.2156 - accuracy: 0.5696INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 09.06.11/models_cnn_k1c2/assets\n",
            "200/200 [==============================] - 34s 169ms/step - loss: 1.2156 - accuracy: 0.5696 - val_loss: 1.4101 - val_accuracy: 0.5350\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.2182 - accuracy: 0.5779 - val_loss: 1.5409 - val_accuracy: 0.5125\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.2293 - accuracy: 0.5737 - val_loss: 1.5003 - val_accuracy: 0.4812\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.2131 - accuracy: 0.5811 - val_loss: 1.5155 - val_accuracy: 0.4812\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.2157 - accuracy: 0.5750 - val_loss: 1.6895 - val_accuracy: 0.4238\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.2035 - accuracy: 0.5725 - val_loss: 1.4702 - val_accuracy: 0.4925\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.2031 - accuracy: 0.5828 - val_loss: 1.5547 - val_accuracy: 0.4650\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.2038 - accuracy: 0.5792 - val_loss: 1.5607 - val_accuracy: 0.4900\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.2062 - accuracy: 0.5832 - val_loss: 1.4068 - val_accuracy: 0.5238\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1890 - accuracy: 0.5861 - val_loss: 1.6207 - val_accuracy: 0.4688\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1969 - accuracy: 0.5754 - val_loss: 1.5285 - val_accuracy: 0.4888\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1919 - accuracy: 0.5850 - val_loss: 1.5290 - val_accuracy: 0.4462\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1977 - accuracy: 0.5861 - val_loss: 1.6137 - val_accuracy: 0.4975\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1982 - accuracy: 0.5834 - val_loss: 1.5112 - val_accuracy: 0.4650\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1839 - accuracy: 0.5804 - val_loss: 1.4304 - val_accuracy: 0.5175\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1836 - accuracy: 0.5845 - val_loss: 1.5209 - val_accuracy: 0.4762\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1855 - accuracy: 0.5864 - val_loss: 1.5353 - val_accuracy: 0.4837\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1599 - accuracy: 0.5953 - val_loss: 1.5427 - val_accuracy: 0.4625\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1701 - accuracy: 0.5909 - val_loss: 1.4506 - val_accuracy: 0.4925\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1948 - accuracy: 0.5809 - val_loss: 1.5485 - val_accuracy: 0.4737\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1636 - accuracy: 0.5940 - val_loss: 1.4895 - val_accuracy: 0.5100\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1778 - accuracy: 0.5903 - val_loss: 1.5288 - val_accuracy: 0.4525\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1607 - accuracy: 0.5954 - val_loss: 1.4979 - val_accuracy: 0.4638\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1609 - accuracy: 0.6015 - val_loss: 1.5838 - val_accuracy: 0.4825\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 30s 150ms/step - loss: 1.1640 - accuracy: 0.5940 - val_loss: 1.4862 - val_accuracy: 0.4888\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1633 - accuracy: 0.5953 - val_loss: 1.4838 - val_accuracy: 0.4963\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1451 - accuracy: 0.5990 - val_loss: 1.5005 - val_accuracy: 0.5075\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 30s 148ms/step - loss: 1.1690 - accuracy: 0.5957 - val_loss: 1.5256 - val_accuracy: 0.4787\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 30s 148ms/step - loss: 1.1575 - accuracy: 0.5947 - val_loss: 1.4412 - val_accuracy: 0.5025\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1549 - accuracy: 0.5950 - val_loss: 1.5011 - val_accuracy: 0.5000\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1575 - accuracy: 0.5973 - val_loss: 1.4341 - val_accuracy: 0.5163\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1404 - accuracy: 0.6053 - val_loss: 1.5070 - val_accuracy: 0.4700\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1472 - accuracy: 0.5972 - val_loss: 1.5076 - val_accuracy: 0.4825\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1566 - accuracy: 0.5936 - val_loss: 1.4960 - val_accuracy: 0.4688\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1649 - accuracy: 0.5956 - val_loss: 1.4740 - val_accuracy: 0.4975\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1553 - accuracy: 0.6008 - val_loss: 1.5248 - val_accuracy: 0.4762\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1482 - accuracy: 0.6001 - val_loss: 1.6124 - val_accuracy: 0.4712\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1473 - accuracy: 0.6000 - val_loss: 1.5348 - val_accuracy: 0.4875\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1414 - accuracy: 0.6018 - val_loss: 1.5840 - val_accuracy: 0.4850\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1317 - accuracy: 0.6058 - val_loss: 1.4746 - val_accuracy: 0.4975\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 30s 148ms/step - loss: 1.1365 - accuracy: 0.6018 - val_loss: 1.4810 - val_accuracy: 0.5013\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 30s 148ms/step - loss: 1.1308 - accuracy: 0.6109 - val_loss: 1.4839 - val_accuracy: 0.4938\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 30s 148ms/step - loss: 1.1305 - accuracy: 0.6064 - val_loss: 1.4552 - val_accuracy: 0.5100\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1285 - accuracy: 0.6039 - val_loss: 1.5658 - val_accuracy: 0.4825\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1360 - accuracy: 0.6039 - val_loss: 1.5068 - val_accuracy: 0.4925\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1320 - accuracy: 0.6061 - val_loss: 1.4475 - val_accuracy: 0.4875\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1329 - accuracy: 0.6064 - val_loss: 1.5276 - val_accuracy: 0.5000\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1086 - accuracy: 0.6150 - val_loss: 1.5331 - val_accuracy: 0.4800\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 30s 150ms/step - loss: 1.1345 - accuracy: 0.5975 - val_loss: 1.4351 - val_accuracy: 0.5250\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1163 - accuracy: 0.6103 - val_loss: 1.5660 - val_accuracy: 0.4638\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1199 - accuracy: 0.6067 - val_loss: 1.4427 - val_accuracy: 0.5125\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 30s 150ms/step - loss: 1.1311 - accuracy: 0.6048 - val_loss: 1.5055 - val_accuracy: 0.4837\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1097 - accuracy: 0.6120 - val_loss: 1.5241 - val_accuracy: 0.4812\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1101 - accuracy: 0.6161 - val_loss: 1.4975 - val_accuracy: 0.4900\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1191 - accuracy: 0.6106 - val_loss: 1.4527 - val_accuracy: 0.4938\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1206 - accuracy: 0.6025 - val_loss: 1.5250 - val_accuracy: 0.4975\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1041 - accuracy: 0.6172 - val_loss: 1.4456 - val_accuracy: 0.5325\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1118 - accuracy: 0.6170 - val_loss: 1.4942 - val_accuracy: 0.4750\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1164 - accuracy: 0.6112 - val_loss: 1.4217 - val_accuracy: 0.5163\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 30s 150ms/step - loss: 1.1187 - accuracy: 0.6100 - val_loss: 1.3777 - val_accuracy: 0.5250\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 30s 150ms/step - loss: 1.1051 - accuracy: 0.6145 - val_loss: 1.5662 - val_accuracy: 0.4350\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 30s 150ms/step - loss: 1.1027 - accuracy: 0.6125 - val_loss: 1.4451 - val_accuracy: 0.5113\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 30s 150ms/step - loss: 1.1144 - accuracy: 0.6151 - val_loss: 1.5042 - val_accuracy: 0.4800\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 30s 149ms/step - loss: 1.1123 - accuracy: 0.6161 - val_loss: 1.4893 - val_accuracy: 0.5000\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 15)      75        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 15)      60        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 15)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 96, 351, 15)       0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 96, 351, 15)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 96, 351, 15)       915       \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 96, 351, 15)       60        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 96, 351, 15)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 96, 70, 15)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 96, 70, 15)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 96, 70, 30)        1830      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 96, 70, 30)        120       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 96, 70, 30)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 96, 8, 30)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 96, 8, 30)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 96, 8, 30)         3630      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 96, 8, 30)         120       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 96, 8, 30)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 96, 1, 30)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 96, 1, 30)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2880)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 30)                86430     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 30)                930       \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 248       \n",
            "=================================================================\n",
            "Total params: 94,802\n",
            "Trainable params: 94,430\n",
            "Non-trainable params: 372\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDM1GAk2KVBr",
        "colab_type": "code",
        "outputId": "a341730b-2ec7-4605-d771-43c2064f0902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        }
      },
      "source": [
        "# Experiment 3\n",
        "# Shallow k2c1\n",
        "\n",
        "hyperparams = {\"number_filters\" : [43],\n",
        "               \"kernel_size\" : [(96, 4)],\n",
        "               \"pooling_size\" : [(96,4)],\n",
        "               \"hidden_layers\": [12],\n",
        "               \"epsilon\": 0.01, \n",
        "               \"learning_rate\": 0.01, \n",
        "               \"batch_size\": 32, \n",
        "               \"epochs\": 100,\n",
        "               \"dropout\" : 0.0,\n",
        "               \"drop_out_hidden\" : 0\n",
        "               }\n",
        "\n",
        "\n",
        "model_string = \"Shallow_k2c1\"\n",
        "model = cnn_k1c2_model(hyperparams)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "#history = run_experiment(model, model_string, hyperparams)\n",
        "#model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_12 (Batc (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 96, 1405, 43)      16555     \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 96, 1405, 43)      172       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 96, 1405, 43)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 1, 351, 43)        0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 1, 351, 43)        0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 15093)             0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 12)                181128    \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 8)                 104       \n",
            "=================================================================\n",
            "Total params: 198,343\n",
            "Trainable params: 198,065\n",
            "Non-trainable params: 278\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLZD-TdVQK6H",
        "colab_type": "code",
        "outputId": "09210cc2-0e6f-4e1b-bab7-ac00d2dc2ebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Experiment 4\n",
        "# Deep k2c1\n",
        "\n",
        "hyperparams = {\"number_filters\" : [43, 43, 87, 87],\n",
        "               \"kernel_size\" : [(96, 4), (1,4), (1,4), (1,4)],\n",
        "               \"pooling_size\" : [(96,4), (1,4), (1,5), (1,4)],\n",
        "               \"hidden_layers\": [70, 70],\n",
        "               \"epsilon\": 0.01, \n",
        "               \"learning_rate\": 0.01, \n",
        "               \"batch_size\": 32, \n",
        "               \"epochs\": 30,\n",
        "               \"dropout\" : 0,\n",
        "               \"drop_out_hidden\" : 0\n",
        "               }\n",
        "\n",
        "\n",
        "model_string = \"cnn_k1c2_deep\"\n",
        "model = cnn_k1c2_model(hyperparams)\n",
        "\n",
        "\n",
        "history = run_experiment(model, model_string, hyperparams)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.8835 - accuracy: 0.3158INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 11.01.32/models_cnn_k1c2_deep/assets\n",
            "200/200 [==============================] - 148s 742ms/step - loss: 1.8835 - accuracy: 0.3158 - val_loss: 2.0002 - val_accuracy: 0.2550\n",
            "Epoch 2/30\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.6625 - accuracy: 0.4014INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 11.01.32/models_cnn_k1c2_deep/assets\n",
            "200/200 [==============================] - 149s 744ms/step - loss: 1.6625 - accuracy: 0.4014 - val_loss: 2.0063 - val_accuracy: 0.3250\n",
            "Epoch 3/30\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.5720 - accuracy: 0.4438INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 11.01.32/models_cnn_k1c2_deep/assets\n",
            "200/200 [==============================] - 149s 744ms/step - loss: 1.5720 - accuracy: 0.4438 - val_loss: 1.8658 - val_accuracy: 0.3587\n",
            "Epoch 4/30\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.4852 - accuracy: 0.4741INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 11.01.32/models_cnn_k1c2_deep/assets\n",
            "200/200 [==============================] - 149s 743ms/step - loss: 1.4852 - accuracy: 0.4741 - val_loss: 2.0809 - val_accuracy: 0.3775\n",
            "Epoch 5/30\n",
            "200/200 [==============================] - 145s 723ms/step - loss: 1.4290 - accuracy: 0.4971 - val_loss: 2.2624 - val_accuracy: 0.2912\n",
            "Epoch 6/30\n",
            "200/200 [==============================] - 144s 722ms/step - loss: 1.4015 - accuracy: 0.5093 - val_loss: 2.0922 - val_accuracy: 0.3113\n",
            "Epoch 7/30\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3568 - accuracy: 0.5287INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 11.01.32/models_cnn_k1c2_deep/assets\n",
            "200/200 [==============================] - 148s 742ms/step - loss: 1.3568 - accuracy: 0.5287 - val_loss: 1.7623 - val_accuracy: 0.4638\n",
            "Epoch 8/30\n",
            "200/200 [==============================] - 144s 722ms/step - loss: 1.3245 - accuracy: 0.5359 - val_loss: 2.0263 - val_accuracy: 0.3800\n",
            "Epoch 9/30\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.2771 - accuracy: 0.5462INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 11.01.32/models_cnn_k1c2_deep/assets\n",
            "200/200 [==============================] - 148s 742ms/step - loss: 1.2771 - accuracy: 0.5462 - val_loss: 1.5618 - val_accuracy: 0.5050\n",
            "Epoch 10/30\n",
            "200/200 [==============================] - 145s 723ms/step - loss: 1.2553 - accuracy: 0.5621 - val_loss: 2.1303 - val_accuracy: 0.3725\n",
            "Epoch 11/30\n",
            "200/200 [==============================] - 145s 723ms/step - loss: 1.2234 - accuracy: 0.5731 - val_loss: 1.8844 - val_accuracy: 0.3975\n",
            "Epoch 12/30\n",
            "200/200 [==============================] - 145s 723ms/step - loss: 1.1933 - accuracy: 0.5842 - val_loss: 2.4042 - val_accuracy: 0.3537\n",
            "Epoch 13/30\n",
            "200/200 [==============================] - 145s 724ms/step - loss: 1.1304 - accuracy: 0.6070 - val_loss: 2.2124 - val_accuracy: 0.3713\n",
            "Epoch 14/30\n",
            "200/200 [==============================] - 145s 723ms/step - loss: 1.0805 - accuracy: 0.6236 - val_loss: 1.8802 - val_accuracy: 0.4288\n",
            "Epoch 15/30\n",
            "200/200 [==============================] - 145s 724ms/step - loss: 1.0410 - accuracy: 0.6350 - val_loss: 1.8366 - val_accuracy: 0.4812\n",
            "Epoch 16/30\n",
            "200/200 [==============================] - 145s 723ms/step - loss: 1.0038 - accuracy: 0.6498 - val_loss: 1.9034 - val_accuracy: 0.4688\n",
            "Epoch 17/30\n",
            "200/200 [==============================] - 145s 723ms/step - loss: 0.9400 - accuracy: 0.6728 - val_loss: 1.9589 - val_accuracy: 0.4350\n",
            "Epoch 18/30\n",
            "200/200 [==============================] - 145s 724ms/step - loss: 0.9098 - accuracy: 0.6775 - val_loss: 1.9619 - val_accuracy: 0.4250\n",
            "Epoch 19/30\n",
            "200/200 [==============================] - 145s 724ms/step - loss: 0.8123 - accuracy: 0.7110 - val_loss: 2.6758 - val_accuracy: 0.3650\n",
            "Epoch 20/30\n",
            "200/200 [==============================] - 145s 724ms/step - loss: 0.7858 - accuracy: 0.7235 - val_loss: 2.2482 - val_accuracy: 0.4038\n",
            "Epoch 21/30\n",
            "200/200 [==============================] - 145s 724ms/step - loss: 0.7346 - accuracy: 0.7418 - val_loss: 2.6046 - val_accuracy: 0.3825\n",
            "Epoch 22/30\n",
            "200/200 [==============================] - 144s 722ms/step - loss: 0.6872 - accuracy: 0.7564 - val_loss: 2.5552 - val_accuracy: 0.3725\n",
            "Epoch 23/30\n",
            "200/200 [==============================] - 145s 723ms/step - loss: 0.6069 - accuracy: 0.7810 - val_loss: 2.7508 - val_accuracy: 0.3725\n",
            "Epoch 24/30\n",
            "200/200 [==============================] - 145s 723ms/step - loss: 0.5665 - accuracy: 0.7957 - val_loss: 2.5128 - val_accuracy: 0.4162\n",
            "Epoch 25/30\n",
            "200/200 [==============================] - 145s 723ms/step - loss: 0.5194 - accuracy: 0.8113 - val_loss: 2.5473 - val_accuracy: 0.4288\n",
            "Epoch 26/30\n",
            "200/200 [==============================] - 144s 722ms/step - loss: 0.4646 - accuracy: 0.8354 - val_loss: 2.6536 - val_accuracy: 0.4313\n",
            "Epoch 27/30\n",
            "200/200 [==============================] - 145s 723ms/step - loss: 0.4506 - accuracy: 0.8426 - val_loss: 2.9396 - val_accuracy: 0.3800\n",
            "Epoch 28/30\n",
            "200/200 [==============================] - 145s 723ms/step - loss: 0.4433 - accuracy: 0.8424 - val_loss: 2.7904 - val_accuracy: 0.4238\n",
            "Epoch 29/30\n",
            "200/200 [==============================] - 144s 721ms/step - loss: 0.3545 - accuracy: 0.8820 - val_loss: 3.2647 - val_accuracy: 0.4100\n",
            "Epoch 30/30\n",
            "200/200 [==============================] - 144s 722ms/step - loss: 0.3496 - accuracy: 0.8776 - val_loss: 4.2396 - val_accuracy: 0.2800\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 43)      16555     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 43)      172       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 43)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 1, 351, 43)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1, 351, 43)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 1, 351, 43)        7439      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 1, 351, 43)        172       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1, 351, 43)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 1, 87, 43)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1, 87, 43)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 1, 87, 87)         15051     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 1, 87, 87)         348       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1, 87, 87)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 17, 87)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1, 17, 87)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 1, 17, 87)         30363     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 1, 17, 87)         348       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 1, 17, 87)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 1, 4, 87)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1, 4, 87)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 348)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 70)                24430     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 70)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 70)                4970      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 70)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 568       \n",
            "=================================================================\n",
            "Total params: 100,800\n",
            "Trainable params: 100,088\n",
            "Non-trainable params: 712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty0Re0J1rDGZ",
        "colab_type": "code",
        "outputId": "8e70d470-79e0-4628-9e92-8aff431e2b5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Experiment 5\n",
        "# Deep k2c2\n",
        "\n",
        "params = {2000: [3,5,5, 8, 10],\n",
        "          4000: [4, 8, 8, 12, 16],\n",
        "          10000:[8, 12, 12, 20, 24],\n",
        "    50000:[15, 30, 30, 45, 60],\n",
        "          100000: [20, 41, 41, 62, 83],\n",
        "                    250000: [33, 66, 66, 100, 133]}\n",
        "\n",
        "num = 2000\n",
        "\n",
        "hyperparams = {\"number_filters\" : params[num],\n",
        "               \"number_params\" : num,\n",
        "               \"kernel_size\" : [(3, 3), (3,3), (3,3), (3,3),(3,3)],\n",
        "               \"pooling_size\" : [(2,4), (2,4), (2,4), (3,5), (4,4)],\n",
        "               \"hidden_layers\": [],\n",
        "               \"epsilon\": 0.01, \n",
        "               \"learning_rate\": 0.01, \n",
        "               \"batch_size\": 32, \n",
        "               \"epochs\": 300,\n",
        "               \"dropout\" : 0.1,\n",
        "               \"drop_out_hidden\" : 0\n",
        "               }\n",
        "\n",
        "\n",
        "model_string = \"cnn_k2c2_5layer\"\n",
        "model = cnn_k1c2_model(hyperparams)\n",
        "\n",
        "\n",
        "history = run_experiment(model, model_string, hyperparams)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "200/200 [==============================] - ETA: 0s - loss: 2.0193 - accuracy: 0.2360INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 05.03.02/models_cnn_k2c2_5layer/assets\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 2.0193 - accuracy: 0.2360 - val_loss: 1.8687 - val_accuracy: 0.3375\n",
            "Epoch 2/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.7514 - accuracy: 0.3492 - val_loss: 1.8305 - val_accuracy: 0.2988\n",
            "Epoch 3/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.6617 - accuracy: 0.3891 - val_loss: 1.8727 - val_accuracy: 0.3313\n",
            "Epoch 4/300\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.6168 - accuracy: 0.4088INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 05.03.02/models_cnn_k2c2_5layer/assets\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 1.6164 - accuracy: 0.4091 - val_loss: 1.6945 - val_accuracy: 0.4075\n",
            "Epoch 5/300\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.5774 - accuracy: 0.4317INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 05.03.02/models_cnn_k2c2_5layer/assets\n",
            "200/200 [==============================] - 11s 54ms/step - loss: 1.5779 - accuracy: 0.4321 - val_loss: 1.5760 - val_accuracy: 0.4375\n",
            "Epoch 6/300\n",
            "200/200 [==============================] - 8s 39ms/step - loss: 1.5680 - accuracy: 0.4283 - val_loss: 1.5722 - val_accuracy: 0.4325\n",
            "Epoch 7/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.5382 - accuracy: 0.4449 - val_loss: 1.5512 - val_accuracy: 0.4313\n",
            "Epoch 8/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.5301 - accuracy: 0.4508 - val_loss: 1.6749 - val_accuracy: 0.4000\n",
            "Epoch 9/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.5296 - accuracy: 0.4508 - val_loss: 1.9806 - val_accuracy: 0.3363\n",
            "Epoch 10/300\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.5157 - accuracy: 0.4512INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 05.03.02/models_cnn_k2c2_5layer/assets\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 1.5154 - accuracy: 0.4508 - val_loss: 1.5424 - val_accuracy: 0.4437\n",
            "Epoch 11/300\n",
            "200/200 [==============================] - 8s 39ms/step - loss: 1.5152 - accuracy: 0.4604 - val_loss: 1.9240 - val_accuracy: 0.3088\n",
            "Epoch 12/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.4994 - accuracy: 0.4558 - val_loss: 1.6255 - val_accuracy: 0.4313\n",
            "Epoch 13/300\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.4913 - accuracy: 0.4611INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 05.03.02/models_cnn_k2c2_5layer/assets\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 1.4915 - accuracy: 0.4610 - val_loss: 1.5395 - val_accuracy: 0.4725\n",
            "Epoch 14/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.4817 - accuracy: 0.4691 - val_loss: 1.5243 - val_accuracy: 0.4613\n",
            "Epoch 15/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.4806 - accuracy: 0.4726 - val_loss: 1.5741 - val_accuracy: 0.4338\n",
            "Epoch 16/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.4652 - accuracy: 0.4743 - val_loss: 1.5935 - val_accuracy: 0.4187\n",
            "Epoch 17/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.4822 - accuracy: 0.4726 - val_loss: 1.6107 - val_accuracy: 0.4275\n",
            "Epoch 18/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.4608 - accuracy: 0.4782 - val_loss: 1.5758 - val_accuracy: 0.4487\n",
            "Epoch 19/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.4621 - accuracy: 0.4818 - val_loss: 1.5740 - val_accuracy: 0.4688\n",
            "Epoch 20/300\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.4466 - accuracy: 0.4802INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 05.03.02/models_cnn_k2c2_5layer/assets\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 1.4473 - accuracy: 0.4798 - val_loss: 1.5141 - val_accuracy: 0.4787\n",
            "Epoch 21/300\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.4499 - accuracy: 0.4829INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 05.03.02/models_cnn_k2c2_5layer/assets\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 1.4493 - accuracy: 0.4830 - val_loss: 1.5207 - val_accuracy: 0.4825\n",
            "Epoch 22/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.4486 - accuracy: 0.4851 - val_loss: 1.5454 - val_accuracy: 0.4450\n",
            "Epoch 23/300\n",
            "200/200 [==============================] - 8s 39ms/step - loss: 1.4489 - accuracy: 0.4901 - val_loss: 1.5282 - val_accuracy: 0.4663\n",
            "Epoch 24/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.4497 - accuracy: 0.4879 - val_loss: 1.7002 - val_accuracy: 0.4087\n",
            "Epoch 25/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.4317 - accuracy: 0.4970 - val_loss: 1.5749 - val_accuracy: 0.4512\n",
            "Epoch 26/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.4372 - accuracy: 0.4859 - val_loss: 1.5015 - val_accuracy: 0.4750\n",
            "Epoch 27/300\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.4243 - accuracy: 0.4964INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 05.03.02/models_cnn_k2c2_5layer/assets\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 1.4232 - accuracy: 0.4968 - val_loss: 1.5347 - val_accuracy: 0.4938\n",
            "Epoch 28/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.4261 - accuracy: 0.4930 - val_loss: 1.5705 - val_accuracy: 0.4525\n",
            "Epoch 29/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.4315 - accuracy: 0.4938 - val_loss: 1.4770 - val_accuracy: 0.4925\n",
            "Epoch 30/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.4149 - accuracy: 0.4952 - val_loss: 1.5118 - val_accuracy: 0.4888\n",
            "Epoch 31/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.4198 - accuracy: 0.5030 - val_loss: 1.5739 - val_accuracy: 0.4712\n",
            "Epoch 32/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.4121 - accuracy: 0.5043 - val_loss: 1.6391 - val_accuracy: 0.4437\n",
            "Epoch 33/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.4060 - accuracy: 0.5013 - val_loss: 1.5210 - val_accuracy: 0.4850\n",
            "Epoch 34/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.4079 - accuracy: 0.5074 - val_loss: 1.5515 - val_accuracy: 0.4575\n",
            "Epoch 35/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.4174 - accuracy: 0.5018 - val_loss: 1.6336 - val_accuracy: 0.4338\n",
            "Epoch 36/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.4117 - accuracy: 0.5132 - val_loss: 1.6070 - val_accuracy: 0.4688\n",
            "Epoch 37/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.4006 - accuracy: 0.5040 - val_loss: 1.5958 - val_accuracy: 0.4425\n",
            "Epoch 38/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3953 - accuracy: 0.5134 - val_loss: 1.6448 - val_accuracy: 0.4437\n",
            "Epoch 39/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3937 - accuracy: 0.5127 - val_loss: 1.6461 - val_accuracy: 0.4200\n",
            "Epoch 40/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3918 - accuracy: 0.5165 - val_loss: 1.5549 - val_accuracy: 0.4812\n",
            "Epoch 41/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3737 - accuracy: 0.5209 - val_loss: 1.7841 - val_accuracy: 0.4075\n",
            "Epoch 42/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3932 - accuracy: 0.5082 - val_loss: 1.6398 - val_accuracy: 0.4538\n",
            "Epoch 43/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3862 - accuracy: 0.5185 - val_loss: 1.7198 - val_accuracy: 0.4025\n",
            "Epoch 44/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3894 - accuracy: 0.5132 - val_loss: 1.5985 - val_accuracy: 0.4613\n",
            "Epoch 45/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3771 - accuracy: 0.5195 - val_loss: 1.5106 - val_accuracy: 0.4925\n",
            "Epoch 46/300\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.3818 - accuracy: 0.5157INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 05.03.02/models_cnn_k2c2_5layer/assets\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 1.3817 - accuracy: 0.5163 - val_loss: 1.5223 - val_accuracy: 0.4950\n",
            "Epoch 47/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3827 - accuracy: 0.5093 - val_loss: 1.4893 - val_accuracy: 0.4938\n",
            "Epoch 48/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3783 - accuracy: 0.5171 - val_loss: 1.6315 - val_accuracy: 0.4425\n",
            "Epoch 49/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3621 - accuracy: 0.5238 - val_loss: 1.6860 - val_accuracy: 0.4288\n",
            "Epoch 50/300\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.3634 - accuracy: 0.5278INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 05.03.02/models_cnn_k2c2_5layer/assets\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 1.3645 - accuracy: 0.5276 - val_loss: 1.4659 - val_accuracy: 0.5063\n",
            "Epoch 51/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3761 - accuracy: 0.5174 - val_loss: 1.5193 - val_accuracy: 0.4863\n",
            "Epoch 52/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3666 - accuracy: 0.5262 - val_loss: 1.5949 - val_accuracy: 0.4500\n",
            "Epoch 53/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3524 - accuracy: 0.5276 - val_loss: 1.5579 - val_accuracy: 0.4787\n",
            "Epoch 54/300\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.3754 - accuracy: 0.5179INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 05.03.02/models_cnn_k2c2_5layer/assets\n",
            "200/200 [==============================] - 11s 54ms/step - loss: 1.3768 - accuracy: 0.5176 - val_loss: 1.4650 - val_accuracy: 0.5125\n",
            "Epoch 55/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3689 - accuracy: 0.5185 - val_loss: 1.4237 - val_accuracy: 0.5050\n",
            "Epoch 56/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3576 - accuracy: 0.5299 - val_loss: 1.5463 - val_accuracy: 0.4750\n",
            "Epoch 57/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3523 - accuracy: 0.5353 - val_loss: 1.4690 - val_accuracy: 0.5125\n",
            "Epoch 58/300\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.3639 - accuracy: 0.5339INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 05.03.02/models_cnn_k2c2_5layer/assets\n",
            "200/200 [==============================] - 11s 54ms/step - loss: 1.3652 - accuracy: 0.5338 - val_loss: 1.4553 - val_accuracy: 0.5213\n",
            "Epoch 59/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3581 - accuracy: 0.5206 - val_loss: 1.4970 - val_accuracy: 0.5050\n",
            "Epoch 60/300\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.3615 - accuracy: 0.5212INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 05.03.02/models_cnn_k2c2_5layer/assets\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 1.3601 - accuracy: 0.5223 - val_loss: 1.4155 - val_accuracy: 0.5325\n",
            "Epoch 61/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3524 - accuracy: 0.5252 - val_loss: 1.8277 - val_accuracy: 0.3850\n",
            "Epoch 62/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3516 - accuracy: 0.5309 - val_loss: 1.5308 - val_accuracy: 0.4913\n",
            "Epoch 63/300\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.3622 - accuracy: 0.5232INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 05.03.02/models_cnn_k2c2_5layer/assets\n",
            "200/200 [==============================] - 11s 54ms/step - loss: 1.3611 - accuracy: 0.5240 - val_loss: 1.4008 - val_accuracy: 0.5387\n",
            "Epoch 64/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3527 - accuracy: 0.5229 - val_loss: 1.4714 - val_accuracy: 0.5188\n",
            "Epoch 65/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3393 - accuracy: 0.5335 - val_loss: 1.4673 - val_accuracy: 0.5088\n",
            "Epoch 66/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3424 - accuracy: 0.5287 - val_loss: 1.4727 - val_accuracy: 0.4963\n",
            "Epoch 67/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3436 - accuracy: 0.5295 - val_loss: 1.3801 - val_accuracy: 0.5175\n",
            "Epoch 68/300\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.3539 - accuracy: 0.5192INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 05.03.02/models_cnn_k2c2_5layer/assets\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 1.3527 - accuracy: 0.5195 - val_loss: 1.3793 - val_accuracy: 0.5400\n",
            "Epoch 69/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3449 - accuracy: 0.5340 - val_loss: 1.5539 - val_accuracy: 0.4737\n",
            "Epoch 70/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3363 - accuracy: 0.5307 - val_loss: 1.5343 - val_accuracy: 0.4737\n",
            "Epoch 71/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3525 - accuracy: 0.5317 - val_loss: 1.4815 - val_accuracy: 0.5125\n",
            "Epoch 72/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3351 - accuracy: 0.5381 - val_loss: 1.3997 - val_accuracy: 0.5275\n",
            "Epoch 73/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3383 - accuracy: 0.5363 - val_loss: 1.5031 - val_accuracy: 0.5038\n",
            "Epoch 74/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3368 - accuracy: 0.5327 - val_loss: 1.4759 - val_accuracy: 0.4950\n",
            "Epoch 75/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3279 - accuracy: 0.5424 - val_loss: 1.4969 - val_accuracy: 0.5113\n",
            "Epoch 76/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3379 - accuracy: 0.5312 - val_loss: 1.6862 - val_accuracy: 0.4437\n",
            "Epoch 77/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3233 - accuracy: 0.5418 - val_loss: 1.4791 - val_accuracy: 0.5238\n",
            "Epoch 78/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3246 - accuracy: 0.5453 - val_loss: 1.4490 - val_accuracy: 0.5188\n",
            "Epoch 79/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3408 - accuracy: 0.5345 - val_loss: 1.4499 - val_accuracy: 0.5150\n",
            "Epoch 80/300\n",
            "200/200 [==============================] - 8s 39ms/step - loss: 1.3368 - accuracy: 0.5335 - val_loss: 1.4066 - val_accuracy: 0.5375\n",
            "Epoch 81/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3301 - accuracy: 0.5365 - val_loss: 1.4326 - val_accuracy: 0.5125\n",
            "Epoch 82/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3321 - accuracy: 0.5374 - val_loss: 1.4022 - val_accuracy: 0.5288\n",
            "Epoch 83/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3264 - accuracy: 0.5367 - val_loss: 1.4652 - val_accuracy: 0.5138\n",
            "Epoch 84/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3362 - accuracy: 0.5359 - val_loss: 1.5686 - val_accuracy: 0.4737\n",
            "Epoch 85/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3222 - accuracy: 0.5396 - val_loss: 1.3965 - val_accuracy: 0.5375\n",
            "Epoch 86/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3320 - accuracy: 0.5338 - val_loss: 1.6630 - val_accuracy: 0.4375\n",
            "Epoch 87/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3176 - accuracy: 0.5379 - val_loss: 1.4367 - val_accuracy: 0.5362\n",
            "Epoch 88/300\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.3417 - accuracy: 0.5349INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 05.03.02/models_cnn_k2c2_5layer/assets\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 1.3424 - accuracy: 0.5345 - val_loss: 1.3630 - val_accuracy: 0.5525\n",
            "Epoch 89/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3308 - accuracy: 0.5337 - val_loss: 1.5213 - val_accuracy: 0.4975\n",
            "Epoch 90/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3378 - accuracy: 0.5309 - val_loss: 1.4939 - val_accuracy: 0.4938\n",
            "Epoch 91/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3234 - accuracy: 0.5395 - val_loss: 1.4211 - val_accuracy: 0.5362\n",
            "Epoch 92/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3383 - accuracy: 0.5337 - val_loss: 1.4423 - val_accuracy: 0.5250\n",
            "Epoch 93/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3156 - accuracy: 0.5467 - val_loss: 1.3873 - val_accuracy: 0.5250\n",
            "Epoch 94/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3151 - accuracy: 0.5421 - val_loss: 1.4606 - val_accuracy: 0.5150\n",
            "Epoch 95/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3271 - accuracy: 0.5370 - val_loss: 1.5022 - val_accuracy: 0.4688\n",
            "Epoch 96/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3224 - accuracy: 0.5385 - val_loss: 1.4591 - val_accuracy: 0.4950\n",
            "Epoch 97/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3200 - accuracy: 0.5379 - val_loss: 1.3840 - val_accuracy: 0.5312\n",
            "Epoch 98/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3082 - accuracy: 0.5468 - val_loss: 1.3677 - val_accuracy: 0.5437\n",
            "Epoch 99/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3292 - accuracy: 0.5415 - val_loss: 1.4960 - val_accuracy: 0.5088\n",
            "Epoch 100/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3200 - accuracy: 0.5385 - val_loss: 1.6727 - val_accuracy: 0.4425\n",
            "Epoch 101/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3137 - accuracy: 0.5495 - val_loss: 1.4678 - val_accuracy: 0.5100\n",
            "Epoch 102/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3184 - accuracy: 0.5423 - val_loss: 1.4470 - val_accuracy: 0.5350\n",
            "Epoch 103/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3174 - accuracy: 0.5434 - val_loss: 1.5247 - val_accuracy: 0.5075\n",
            "Epoch 104/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3265 - accuracy: 0.5420 - val_loss: 1.4218 - val_accuracy: 0.5200\n",
            "Epoch 105/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3217 - accuracy: 0.5415 - val_loss: 1.4217 - val_accuracy: 0.5275\n",
            "Epoch 106/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3244 - accuracy: 0.5393 - val_loss: 1.6153 - val_accuracy: 0.4663\n",
            "Epoch 107/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3160 - accuracy: 0.5399 - val_loss: 1.4543 - val_accuracy: 0.5238\n",
            "Epoch 108/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3201 - accuracy: 0.5365 - val_loss: 1.4317 - val_accuracy: 0.5250\n",
            "Epoch 109/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3187 - accuracy: 0.5392 - val_loss: 1.3995 - val_accuracy: 0.5437\n",
            "Epoch 110/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3254 - accuracy: 0.5524 - val_loss: 1.4891 - val_accuracy: 0.5113\n",
            "Epoch 111/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3157 - accuracy: 0.5410 - val_loss: 1.6021 - val_accuracy: 0.4538\n",
            "Epoch 112/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3221 - accuracy: 0.5417 - val_loss: 1.4838 - val_accuracy: 0.5113\n",
            "Epoch 113/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3155 - accuracy: 0.5446 - val_loss: 1.5022 - val_accuracy: 0.4938\n",
            "Epoch 114/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3153 - accuracy: 0.5392 - val_loss: 1.5021 - val_accuracy: 0.5100\n",
            "Epoch 115/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3175 - accuracy: 0.5378 - val_loss: 1.5288 - val_accuracy: 0.4925\n",
            "Epoch 116/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3173 - accuracy: 0.5392 - val_loss: 1.4154 - val_accuracy: 0.5200\n",
            "Epoch 117/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2989 - accuracy: 0.5487 - val_loss: 1.4534 - val_accuracy: 0.5138\n",
            "Epoch 118/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3173 - accuracy: 0.5432 - val_loss: 1.4162 - val_accuracy: 0.5288\n",
            "Epoch 119/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3145 - accuracy: 0.5378 - val_loss: 1.5035 - val_accuracy: 0.4950\n",
            "Epoch 120/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3134 - accuracy: 0.5399 - val_loss: 1.6242 - val_accuracy: 0.4638\n",
            "Epoch 121/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3099 - accuracy: 0.5442 - val_loss: 1.4382 - val_accuracy: 0.5100\n",
            "Epoch 122/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3071 - accuracy: 0.5451 - val_loss: 1.5048 - val_accuracy: 0.4988\n",
            "Epoch 123/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3158 - accuracy: 0.5368 - val_loss: 1.4511 - val_accuracy: 0.5425\n",
            "Epoch 124/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3163 - accuracy: 0.5459 - val_loss: 1.4059 - val_accuracy: 0.5400\n",
            "Epoch 125/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3082 - accuracy: 0.5493 - val_loss: 1.4771 - val_accuracy: 0.4913\n",
            "Epoch 126/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3024 - accuracy: 0.5401 - val_loss: 1.5650 - val_accuracy: 0.4988\n",
            "Epoch 127/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3115 - accuracy: 0.5413 - val_loss: 1.4877 - val_accuracy: 0.5225\n",
            "Epoch 128/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3038 - accuracy: 0.5470 - val_loss: 1.5605 - val_accuracy: 0.5038\n",
            "Epoch 129/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3175 - accuracy: 0.5432 - val_loss: 1.3656 - val_accuracy: 0.5450\n",
            "Epoch 130/300\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.3025 - accuracy: 0.5413INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 05.03.02/models_cnn_k2c2_5layer/assets\n",
            "200/200 [==============================] - 11s 55ms/step - loss: 1.3028 - accuracy: 0.5412 - val_loss: 1.3589 - val_accuracy: 0.5587\n",
            "Epoch 131/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2952 - accuracy: 0.5517 - val_loss: 1.5719 - val_accuracy: 0.4737\n",
            "Epoch 132/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3072 - accuracy: 0.5424 - val_loss: 1.5076 - val_accuracy: 0.4988\n",
            "Epoch 133/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3012 - accuracy: 0.5460 - val_loss: 1.4234 - val_accuracy: 0.5437\n",
            "Epoch 134/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2966 - accuracy: 0.5421 - val_loss: 1.4658 - val_accuracy: 0.5150\n",
            "Epoch 135/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3060 - accuracy: 0.5474 - val_loss: 1.4146 - val_accuracy: 0.5288\n",
            "Epoch 136/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3071 - accuracy: 0.5492 - val_loss: 1.4606 - val_accuracy: 0.4825\n",
            "Epoch 137/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3160 - accuracy: 0.5426 - val_loss: 1.4793 - val_accuracy: 0.5213\n",
            "Epoch 138/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3083 - accuracy: 0.5457 - val_loss: 1.4637 - val_accuracy: 0.5113\n",
            "Epoch 139/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3008 - accuracy: 0.5463 - val_loss: 1.5434 - val_accuracy: 0.4863\n",
            "Epoch 140/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2994 - accuracy: 0.5421 - val_loss: 1.4549 - val_accuracy: 0.5063\n",
            "Epoch 141/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3110 - accuracy: 0.5463 - val_loss: 1.4770 - val_accuracy: 0.5250\n",
            "Epoch 142/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2977 - accuracy: 0.5560 - val_loss: 1.4869 - val_accuracy: 0.4963\n",
            "Epoch 143/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3149 - accuracy: 0.5365 - val_loss: 1.3623 - val_accuracy: 0.5537\n",
            "Epoch 144/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3164 - accuracy: 0.5423 - val_loss: 1.4445 - val_accuracy: 0.5038\n",
            "Epoch 145/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2975 - accuracy: 0.5463 - val_loss: 1.4429 - val_accuracy: 0.5263\n",
            "Epoch 146/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2924 - accuracy: 0.5499 - val_loss: 1.3929 - val_accuracy: 0.5525\n",
            "Epoch 147/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2933 - accuracy: 0.5532 - val_loss: 1.3805 - val_accuracy: 0.5425\n",
            "Epoch 148/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3099 - accuracy: 0.5424 - val_loss: 1.4158 - val_accuracy: 0.5500\n",
            "Epoch 149/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2987 - accuracy: 0.5498 - val_loss: 1.5665 - val_accuracy: 0.4650\n",
            "Epoch 150/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2838 - accuracy: 0.5512 - val_loss: 1.4101 - val_accuracy: 0.5400\n",
            "Epoch 151/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3067 - accuracy: 0.5446 - val_loss: 1.5116 - val_accuracy: 0.4963\n",
            "Epoch 152/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3018 - accuracy: 0.5426 - val_loss: 1.5605 - val_accuracy: 0.4850\n",
            "Epoch 153/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3006 - accuracy: 0.5409 - val_loss: 1.4569 - val_accuracy: 0.5150\n",
            "Epoch 154/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3048 - accuracy: 0.5471 - val_loss: 1.4786 - val_accuracy: 0.4963\n",
            "Epoch 155/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3053 - accuracy: 0.5432 - val_loss: 1.5455 - val_accuracy: 0.4787\n",
            "Epoch 156/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3022 - accuracy: 0.5453 - val_loss: 1.3984 - val_accuracy: 0.5512\n",
            "Epoch 157/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2972 - accuracy: 0.5517 - val_loss: 1.4066 - val_accuracy: 0.5375\n",
            "Epoch 158/300\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.3015 - accuracy: 0.5455INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 05.03.02/models_cnn_k2c2_5layer/assets\n",
            "200/200 [==============================] - 11s 54ms/step - loss: 1.3030 - accuracy: 0.5446 - val_loss: 1.3537 - val_accuracy: 0.5688\n",
            "Epoch 159/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2950 - accuracy: 0.5492 - val_loss: 1.4062 - val_accuracy: 0.5375\n",
            "Epoch 160/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3007 - accuracy: 0.5421 - val_loss: 1.3366 - val_accuracy: 0.5575\n",
            "Epoch 161/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2976 - accuracy: 0.5451 - val_loss: 1.3409 - val_accuracy: 0.5550\n",
            "Epoch 162/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2887 - accuracy: 0.5467 - val_loss: 1.4340 - val_accuracy: 0.5163\n",
            "Epoch 163/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2901 - accuracy: 0.5551 - val_loss: 1.4306 - val_accuracy: 0.5263\n",
            "Epoch 164/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2856 - accuracy: 0.5504 - val_loss: 1.5463 - val_accuracy: 0.5013\n",
            "Epoch 165/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2957 - accuracy: 0.5517 - val_loss: 1.3512 - val_accuracy: 0.5562\n",
            "Epoch 166/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3030 - accuracy: 0.5445 - val_loss: 1.3885 - val_accuracy: 0.5387\n",
            "Epoch 167/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2933 - accuracy: 0.5465 - val_loss: 1.3591 - val_accuracy: 0.5412\n",
            "Epoch 168/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2936 - accuracy: 0.5470 - val_loss: 1.5376 - val_accuracy: 0.4613\n",
            "Epoch 169/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2837 - accuracy: 0.5457 - val_loss: 1.3568 - val_accuracy: 0.5462\n",
            "Epoch 170/300\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.2988 - accuracy: 0.5432INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 05.03.02/models_cnn_k2c2_5layer/assets\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 1.2977 - accuracy: 0.5440 - val_loss: 1.3275 - val_accuracy: 0.5713\n",
            "Epoch 171/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2839 - accuracy: 0.5515 - val_loss: 1.4293 - val_accuracy: 0.5350\n",
            "Epoch 172/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2829 - accuracy: 0.5596 - val_loss: 1.5329 - val_accuracy: 0.5000\n",
            "Epoch 173/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2937 - accuracy: 0.5490 - val_loss: 1.4283 - val_accuracy: 0.5312\n",
            "Epoch 174/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2834 - accuracy: 0.5529 - val_loss: 1.3778 - val_accuracy: 0.5412\n",
            "Epoch 175/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2932 - accuracy: 0.5492 - val_loss: 1.4928 - val_accuracy: 0.4950\n",
            "Epoch 176/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2958 - accuracy: 0.5484 - val_loss: 1.3960 - val_accuracy: 0.5412\n",
            "Epoch 177/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2772 - accuracy: 0.5449 - val_loss: 1.4701 - val_accuracy: 0.5188\n",
            "Epoch 178/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2815 - accuracy: 0.5485 - val_loss: 1.3790 - val_accuracy: 0.5437\n",
            "Epoch 179/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2889 - accuracy: 0.5510 - val_loss: 1.4996 - val_accuracy: 0.5100\n",
            "Epoch 180/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2961 - accuracy: 0.5410 - val_loss: 1.3726 - val_accuracy: 0.5312\n",
            "Epoch 181/300\n",
            "200/200 [==============================] - 8s 39ms/step - loss: 1.2859 - accuracy: 0.5493 - val_loss: 1.3663 - val_accuracy: 0.5500\n",
            "Epoch 182/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2821 - accuracy: 0.5582 - val_loss: 1.5516 - val_accuracy: 0.5025\n",
            "Epoch 183/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2802 - accuracy: 0.5531 - val_loss: 1.3981 - val_accuracy: 0.5500\n",
            "Epoch 184/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3053 - accuracy: 0.5412 - val_loss: 1.5220 - val_accuracy: 0.4762\n",
            "Epoch 185/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2868 - accuracy: 0.5576 - val_loss: 1.4540 - val_accuracy: 0.5275\n",
            "Epoch 186/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2774 - accuracy: 0.5517 - val_loss: 1.5777 - val_accuracy: 0.4812\n",
            "Epoch 187/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.3045 - accuracy: 0.5443 - val_loss: 1.4631 - val_accuracy: 0.5213\n",
            "Epoch 188/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2816 - accuracy: 0.5518 - val_loss: 1.5382 - val_accuracy: 0.4950\n",
            "Epoch 189/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2832 - accuracy: 0.5529 - val_loss: 1.3844 - val_accuracy: 0.5587\n",
            "Epoch 190/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2866 - accuracy: 0.5506 - val_loss: 1.3798 - val_accuracy: 0.5487\n",
            "Epoch 191/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2944 - accuracy: 0.5509 - val_loss: 1.3965 - val_accuracy: 0.5475\n",
            "Epoch 192/300\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.2769 - accuracy: 0.5581INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-17 05.03.02/models_cnn_k2c2_5layer/assets\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 1.2762 - accuracy: 0.5581 - val_loss: 1.3276 - val_accuracy: 0.5725\n",
            "Epoch 193/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2888 - accuracy: 0.5590 - val_loss: 1.5246 - val_accuracy: 0.4875\n",
            "Epoch 194/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2775 - accuracy: 0.5506 - val_loss: 1.3945 - val_accuracy: 0.5362\n",
            "Epoch 195/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2754 - accuracy: 0.5479 - val_loss: 1.5697 - val_accuracy: 0.4863\n",
            "Epoch 196/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2761 - accuracy: 0.5523 - val_loss: 1.4210 - val_accuracy: 0.5437\n",
            "Epoch 197/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2839 - accuracy: 0.5529 - val_loss: 1.4910 - val_accuracy: 0.5113\n",
            "Epoch 198/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2871 - accuracy: 0.5540 - val_loss: 1.5910 - val_accuracy: 0.4850\n",
            "Epoch 199/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2884 - accuracy: 0.5517 - val_loss: 1.4037 - val_accuracy: 0.5350\n",
            "Epoch 200/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2788 - accuracy: 0.5542 - val_loss: 1.4714 - val_accuracy: 0.5100\n",
            "Epoch 201/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2800 - accuracy: 0.5549 - val_loss: 1.4233 - val_accuracy: 0.5250\n",
            "Epoch 202/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2893 - accuracy: 0.5446 - val_loss: 1.4104 - val_accuracy: 0.5275\n",
            "Epoch 203/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2805 - accuracy: 0.5518 - val_loss: 1.4871 - val_accuracy: 0.5163\n",
            "Epoch 204/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2847 - accuracy: 0.5590 - val_loss: 1.4358 - val_accuracy: 0.5263\n",
            "Epoch 205/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2663 - accuracy: 0.5615 - val_loss: 1.3761 - val_accuracy: 0.5475\n",
            "Epoch 206/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2801 - accuracy: 0.5476 - val_loss: 1.4623 - val_accuracy: 0.5175\n",
            "Epoch 207/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2907 - accuracy: 0.5529 - val_loss: 1.4224 - val_accuracy: 0.5450\n",
            "Epoch 208/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2848 - accuracy: 0.5554 - val_loss: 1.3455 - val_accuracy: 0.5575\n",
            "Epoch 209/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2751 - accuracy: 0.5495 - val_loss: 1.4868 - val_accuracy: 0.5100\n",
            "Epoch 210/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2745 - accuracy: 0.5604 - val_loss: 1.4763 - val_accuracy: 0.5138\n",
            "Epoch 211/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2778 - accuracy: 0.5498 - val_loss: 1.3462 - val_accuracy: 0.5725\n",
            "Epoch 212/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2889 - accuracy: 0.5506 - val_loss: 1.5678 - val_accuracy: 0.4863\n",
            "Epoch 213/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2822 - accuracy: 0.5503 - val_loss: 1.4800 - val_accuracy: 0.5063\n",
            "Epoch 214/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2820 - accuracy: 0.5529 - val_loss: 1.4762 - val_accuracy: 0.5300\n",
            "Epoch 215/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2680 - accuracy: 0.5601 - val_loss: 1.3639 - val_accuracy: 0.5587\n",
            "Epoch 216/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2862 - accuracy: 0.5537 - val_loss: 1.4143 - val_accuracy: 0.5437\n",
            "Epoch 217/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2874 - accuracy: 0.5537 - val_loss: 1.4802 - val_accuracy: 0.5113\n",
            "Epoch 218/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2706 - accuracy: 0.5587 - val_loss: 1.3686 - val_accuracy: 0.5600\n",
            "Epoch 219/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2734 - accuracy: 0.5584 - val_loss: 1.3770 - val_accuracy: 0.5375\n",
            "Epoch 220/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2897 - accuracy: 0.5526 - val_loss: 1.4244 - val_accuracy: 0.5437\n",
            "Epoch 221/300\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 1.2828 - accuracy: 0.5540 - val_loss: 1.3755 - val_accuracy: 0.5475\n",
            "Epoch 222/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2835 - accuracy: 0.5548 - val_loss: 1.4428 - val_accuracy: 0.5400\n",
            "Epoch 223/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2819 - accuracy: 0.5515 - val_loss: 1.3762 - val_accuracy: 0.5562\n",
            "Epoch 224/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2782 - accuracy: 0.5526 - val_loss: 1.5024 - val_accuracy: 0.5063\n",
            "Epoch 225/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2752 - accuracy: 0.5574 - val_loss: 1.4068 - val_accuracy: 0.5550\n",
            "Epoch 226/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2791 - accuracy: 0.5492 - val_loss: 1.5499 - val_accuracy: 0.4875\n",
            "Epoch 227/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2791 - accuracy: 0.5507 - val_loss: 1.4695 - val_accuracy: 0.5288\n",
            "Epoch 228/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2742 - accuracy: 0.5560 - val_loss: 1.4765 - val_accuracy: 0.5225\n",
            "Epoch 229/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2890 - accuracy: 0.5462 - val_loss: 1.4294 - val_accuracy: 0.5300\n",
            "Epoch 230/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2862 - accuracy: 0.5567 - val_loss: 1.5059 - val_accuracy: 0.5038\n",
            "Epoch 231/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2814 - accuracy: 0.5506 - val_loss: 1.4099 - val_accuracy: 0.5225\n",
            "Epoch 232/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2756 - accuracy: 0.5584 - val_loss: 1.5369 - val_accuracy: 0.5050\n",
            "Epoch 233/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2878 - accuracy: 0.5523 - val_loss: 1.4941 - val_accuracy: 0.5163\n",
            "Epoch 234/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2860 - accuracy: 0.5520 - val_loss: 1.3712 - val_accuracy: 0.5487\n",
            "Epoch 235/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2652 - accuracy: 0.5535 - val_loss: 1.4550 - val_accuracy: 0.5300\n",
            "Epoch 236/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2753 - accuracy: 0.5562 - val_loss: 1.3847 - val_accuracy: 0.5500\n",
            "Epoch 237/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2789 - accuracy: 0.5553 - val_loss: 1.4421 - val_accuracy: 0.5238\n",
            "Epoch 238/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2808 - accuracy: 0.5482 - val_loss: 1.4035 - val_accuracy: 0.5487\n",
            "Epoch 239/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2799 - accuracy: 0.5523 - val_loss: 1.5007 - val_accuracy: 0.5163\n",
            "Epoch 240/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2768 - accuracy: 0.5564 - val_loss: 1.4725 - val_accuracy: 0.5175\n",
            "Epoch 241/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2723 - accuracy: 0.5592 - val_loss: 1.4134 - val_accuracy: 0.5275\n",
            "Epoch 242/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2726 - accuracy: 0.5564 - val_loss: 1.4845 - val_accuracy: 0.5125\n",
            "Epoch 243/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2808 - accuracy: 0.5557 - val_loss: 1.4909 - val_accuracy: 0.5100\n",
            "Epoch 244/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2771 - accuracy: 0.5581 - val_loss: 1.3720 - val_accuracy: 0.5650\n",
            "Epoch 245/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2884 - accuracy: 0.5484 - val_loss: 1.4361 - val_accuracy: 0.5263\n",
            "Epoch 246/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2735 - accuracy: 0.5485 - val_loss: 1.3826 - val_accuracy: 0.5462\n",
            "Epoch 247/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2617 - accuracy: 0.5589 - val_loss: 1.4035 - val_accuracy: 0.5500\n",
            "Epoch 248/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2652 - accuracy: 0.5576 - val_loss: 1.5863 - val_accuracy: 0.4850\n",
            "Epoch 249/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2708 - accuracy: 0.5567 - val_loss: 1.3608 - val_accuracy: 0.5512\n",
            "Epoch 250/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2889 - accuracy: 0.5506 - val_loss: 1.4195 - val_accuracy: 0.5512\n",
            "Epoch 251/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2755 - accuracy: 0.5540 - val_loss: 1.3663 - val_accuracy: 0.5512\n",
            "Epoch 252/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2754 - accuracy: 0.5599 - val_loss: 1.4613 - val_accuracy: 0.5150\n",
            "Epoch 253/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2687 - accuracy: 0.5549 - val_loss: 1.3684 - val_accuracy: 0.5663\n",
            "Epoch 254/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2640 - accuracy: 0.5612 - val_loss: 1.3566 - val_accuracy: 0.5562\n",
            "Epoch 255/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2731 - accuracy: 0.5593 - val_loss: 1.5310 - val_accuracy: 0.5050\n",
            "Epoch 256/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2817 - accuracy: 0.5543 - val_loss: 1.4789 - val_accuracy: 0.5100\n",
            "Epoch 257/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2598 - accuracy: 0.5596 - val_loss: 1.3931 - val_accuracy: 0.5625\n",
            "Epoch 258/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2629 - accuracy: 0.5601 - val_loss: 1.4400 - val_accuracy: 0.5200\n",
            "Epoch 259/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2733 - accuracy: 0.5524 - val_loss: 1.3511 - val_accuracy: 0.5500\n",
            "Epoch 260/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2678 - accuracy: 0.5609 - val_loss: 1.3825 - val_accuracy: 0.5512\n",
            "Epoch 261/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2783 - accuracy: 0.5493 - val_loss: 1.4464 - val_accuracy: 0.5225\n",
            "Epoch 262/300\n",
            "200/200 [==============================] - 8s 39ms/step - loss: 1.2843 - accuracy: 0.5462 - val_loss: 1.4302 - val_accuracy: 0.5250\n",
            "Epoch 263/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2757 - accuracy: 0.5560 - val_loss: 1.3852 - val_accuracy: 0.5375\n",
            "Epoch 264/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2719 - accuracy: 0.5606 - val_loss: 1.3623 - val_accuracy: 0.5375\n",
            "Epoch 265/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2739 - accuracy: 0.5539 - val_loss: 1.7300 - val_accuracy: 0.4300\n",
            "Epoch 266/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2676 - accuracy: 0.5601 - val_loss: 1.5175 - val_accuracy: 0.5013\n",
            "Epoch 267/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2829 - accuracy: 0.5548 - val_loss: 1.4301 - val_accuracy: 0.5275\n",
            "Epoch 268/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2854 - accuracy: 0.5493 - val_loss: 1.4999 - val_accuracy: 0.4963\n",
            "Epoch 269/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2740 - accuracy: 0.5625 - val_loss: 1.4461 - val_accuracy: 0.5263\n",
            "Epoch 270/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2691 - accuracy: 0.5582 - val_loss: 1.3732 - val_accuracy: 0.5562\n",
            "Epoch 271/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2866 - accuracy: 0.5521 - val_loss: 1.4121 - val_accuracy: 0.5238\n",
            "Epoch 272/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2868 - accuracy: 0.5490 - val_loss: 1.4925 - val_accuracy: 0.5063\n",
            "Epoch 273/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2625 - accuracy: 0.5546 - val_loss: 1.3821 - val_accuracy: 0.5650\n",
            "Epoch 274/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2676 - accuracy: 0.5557 - val_loss: 1.5011 - val_accuracy: 0.5125\n",
            "Epoch 275/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2600 - accuracy: 0.5665 - val_loss: 1.5724 - val_accuracy: 0.5063\n",
            "Epoch 276/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2735 - accuracy: 0.5559 - val_loss: 1.4205 - val_accuracy: 0.5325\n",
            "Epoch 277/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2783 - accuracy: 0.5564 - val_loss: 1.4304 - val_accuracy: 0.5025\n",
            "Epoch 278/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2717 - accuracy: 0.5562 - val_loss: 1.4094 - val_accuracy: 0.5263\n",
            "Epoch 279/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2713 - accuracy: 0.5615 - val_loss: 1.3335 - val_accuracy: 0.5700\n",
            "Epoch 280/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2875 - accuracy: 0.5524 - val_loss: 1.3862 - val_accuracy: 0.5425\n",
            "Epoch 281/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2638 - accuracy: 0.5612 - val_loss: 1.6118 - val_accuracy: 0.4875\n",
            "Epoch 282/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2705 - accuracy: 0.5534 - val_loss: 1.4098 - val_accuracy: 0.5512\n",
            "Epoch 283/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2707 - accuracy: 0.5546 - val_loss: 1.3962 - val_accuracy: 0.5575\n",
            "Epoch 284/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2747 - accuracy: 0.5542 - val_loss: 1.3975 - val_accuracy: 0.5337\n",
            "Epoch 285/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2763 - accuracy: 0.5518 - val_loss: 1.4275 - val_accuracy: 0.5312\n",
            "Epoch 286/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2765 - accuracy: 0.5565 - val_loss: 1.3639 - val_accuracy: 0.5487\n",
            "Epoch 287/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2645 - accuracy: 0.5612 - val_loss: 1.4224 - val_accuracy: 0.5587\n",
            "Epoch 288/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2717 - accuracy: 0.5559 - val_loss: 1.5648 - val_accuracy: 0.5000\n",
            "Epoch 289/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2736 - accuracy: 0.5584 - val_loss: 1.4647 - val_accuracy: 0.5312\n",
            "Epoch 290/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2815 - accuracy: 0.5542 - val_loss: 1.6079 - val_accuracy: 0.4750\n",
            "Epoch 291/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2726 - accuracy: 0.5570 - val_loss: 1.4577 - val_accuracy: 0.5275\n",
            "Epoch 292/300\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 1.2759 - accuracy: 0.5598 - val_loss: 1.6730 - val_accuracy: 0.4588\n",
            "Epoch 293/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2737 - accuracy: 0.5540 - val_loss: 1.5493 - val_accuracy: 0.4837\n",
            "Epoch 294/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2699 - accuracy: 0.5623 - val_loss: 1.5506 - val_accuracy: 0.4963\n",
            "Epoch 295/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2665 - accuracy: 0.5606 - val_loss: 1.5623 - val_accuracy: 0.5075\n",
            "Epoch 296/300\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 1.2692 - accuracy: 0.5579 - val_loss: 1.4319 - val_accuracy: 0.5412\n",
            "Epoch 297/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2580 - accuracy: 0.5614 - val_loss: 1.5387 - val_accuracy: 0.5000\n",
            "Epoch 298/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2719 - accuracy: 0.5557 - val_loss: 1.4335 - val_accuracy: 0.5450\n",
            "Epoch 299/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2559 - accuracy: 0.5632 - val_loss: 1.5198 - val_accuracy: 0.5038\n",
            "Epoch 300/300\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 1.2581 - accuracy: 0.5654 - val_loss: 1.5078 - val_accuracy: 0.5150\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 3)       30        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 3)       12        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 3)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 48, 351, 3)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 48, 351, 3)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 351, 5)        140       \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 351, 5)        20        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 48, 351, 5)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 87, 5)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 87, 5)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 87, 5)         230       \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 87, 5)         20        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 87, 5)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 21, 5)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 12, 21, 5)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 12, 21, 8)         368       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 12, 21, 8)         32        \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 12, 21, 8)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 8)           0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4, 4, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 4, 4, 10)          730       \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 4, 4, 10)          40        \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 4, 4, 10)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 88        \n",
            "=================================================================\n",
            "Total params: 2,094\n",
            "Trainable params: 1,840\n",
            "Non-trainable params: 254\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meUYHSOHs1FM",
        "colab_type": "text"
      },
      "source": [
        "## Training 4-layer fully convolutional neural networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs-_zD_ss7Ub",
        "colab_type": "code",
        "outputId": "acad08fa-f378-4190-d219-7d2a20c01cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Experiment 6\n",
        "# Deep k2c2\n",
        "\n",
        "params = {2000: [4,6,6,9],\n",
        "          4000: [6, 10, 10, 14],\n",
        "          10000:[10, 16, 16, 28],\n",
        "    50000:[20, 41, 41, 63],\n",
        "          100000: [29, 59, 59, 90],\n",
        "                    250000: [48, 95, 95, 142]}\n",
        "\n",
        "num = 10000\n",
        "#dropouts = [0.1, 0.1, 0.1, 0.2, 0.2, 0.4]\n",
        "#dropouts = [0.2, 0.4]\n",
        "dropouts = [0.4]\n",
        "\n",
        "\n",
        "for i, num in enumerate([250000]):\n",
        "\n",
        "  hyperparams = {\"number_filters\" : params[num],\n",
        "                \"number_params\" : num,\n",
        "                \"kernel_size\" : [(3, 3), (3,3), (3,3), (3,3)],\n",
        "                \"pooling_size\" : [(2,4), (2,4), (3,5), (3,5)],\n",
        "                \"hidden_layers\": [],\n",
        "                \"epsilon\": 0.01, \n",
        "                \"learning_rate\": 0.01, \n",
        "                \"batch_size\": 32, \n",
        "                \"epochs\": 50,\n",
        "                \"dropout\" : dropouts[i],\n",
        "                \"drop_out_hidden\" : 0\n",
        "                }\n",
        "\n",
        "\n",
        "  model_string = \"cnn_k2c2_4layer\"\n",
        "  model = cnn_k1c2_model(hyperparams)\n",
        "\n",
        "\n",
        "  history = run_experiment(model, model_string, hyperparams)\n",
        "  model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 2.5825 - accuracy: 0.2262INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 15.40.46/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 80s 399ms/step - loss: 2.5825 - accuracy: 0.2262 - val_loss: 2.1571 - val_accuracy: 0.2688\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.8614 - accuracy: 0.3428INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 15.40.46/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 80s 398ms/step - loss: 1.8614 - accuracy: 0.3428 - val_loss: 1.9216 - val_accuracy: 0.3350\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.6220 - accuracy: 0.4219INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 15.40.46/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 80s 398ms/step - loss: 1.6220 - accuracy: 0.4219 - val_loss: 1.7800 - val_accuracy: 0.3738\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 1.5485 - accuracy: 0.4486 - val_loss: 1.9648 - val_accuracy: 0.2950\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.4773 - accuracy: 0.4830INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 15.40.46/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 80s 398ms/step - loss: 1.4773 - accuracy: 0.4830 - val_loss: 1.5081 - val_accuracy: 0.4650\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.4364 - accuracy: 0.4965INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 15.40.46/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 79s 397ms/step - loss: 1.4364 - accuracy: 0.4965 - val_loss: 1.5240 - val_accuracy: 0.4688\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.4070 - accuracy: 0.4980INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 15.40.46/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 80s 399ms/step - loss: 1.4070 - accuracy: 0.4980 - val_loss: 1.4647 - val_accuracy: 0.4900\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3925 - accuracy: 0.5179INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 15.40.46/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 80s 399ms/step - loss: 1.3925 - accuracy: 0.5179 - val_loss: 1.4268 - val_accuracy: 0.5200\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 1.3632 - accuracy: 0.5259 - val_loss: 1.4636 - val_accuracy: 0.5113\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 76s 380ms/step - loss: 1.3304 - accuracy: 0.5412 - val_loss: 1.4170 - val_accuracy: 0.5088\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3172 - accuracy: 0.5359INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 15.40.46/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 79s 396ms/step - loss: 1.3172 - accuracy: 0.5359 - val_loss: 1.3867 - val_accuracy: 0.5275\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 1.2894 - accuracy: 0.5565 - val_loss: 1.4610 - val_accuracy: 0.5025\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 1.2676 - accuracy: 0.5567 - val_loss: 1.5219 - val_accuracy: 0.4875\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 76s 378ms/step - loss: 1.2509 - accuracy: 0.5598 - val_loss: 1.4369 - val_accuracy: 0.5163\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.2576 - accuracy: 0.5592INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 15.40.46/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 80s 398ms/step - loss: 1.2576 - accuracy: 0.5592 - val_loss: 1.3637 - val_accuracy: 0.5375\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 1.2191 - accuracy: 0.5750 - val_loss: 1.4567 - val_accuracy: 0.5225\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.2125 - accuracy: 0.5829INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 15.40.46/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 79s 397ms/step - loss: 1.2125 - accuracy: 0.5829 - val_loss: 1.4648 - val_accuracy: 0.5475\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 1.2016 - accuracy: 0.5782 - val_loss: 1.4294 - val_accuracy: 0.5200\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 1.1827 - accuracy: 0.5886 - val_loss: 1.4434 - val_accuracy: 0.5350\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 1.1810 - accuracy: 0.5953 - val_loss: 1.3520 - val_accuracy: 0.5362\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 1.1697 - accuracy: 0.5950 - val_loss: 1.4149 - val_accuracy: 0.5350\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 76s 380ms/step - loss: 1.1546 - accuracy: 0.5982 - val_loss: 1.4705 - val_accuracy: 0.5337\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 1.1336 - accuracy: 0.6054 - val_loss: 1.3311 - val_accuracy: 0.5475\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 1.1312 - accuracy: 0.6098 - val_loss: 1.6305 - val_accuracy: 0.4775\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.1165 - accuracy: 0.6008INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 15.40.46/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 80s 399ms/step - loss: 1.1165 - accuracy: 0.6008 - val_loss: 1.3911 - val_accuracy: 0.5725\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.1086 - accuracy: 0.6151INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 15.40.46/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 80s 399ms/step - loss: 1.1086 - accuracy: 0.6151 - val_loss: 1.3501 - val_accuracy: 0.5838\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 76s 380ms/step - loss: 1.0852 - accuracy: 0.6226 - val_loss: 1.3482 - val_accuracy: 0.5525\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 1.0797 - accuracy: 0.6233 - val_loss: 1.6399 - val_accuracy: 0.5025\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 1.0662 - accuracy: 0.6244 - val_loss: 1.4516 - val_accuracy: 0.5587\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.0502 - accuracy: 0.6292INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 15.40.46/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 80s 398ms/step - loss: 1.0502 - accuracy: 0.6292 - val_loss: 1.2912 - val_accuracy: 0.5913\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 1.0597 - accuracy: 0.6306 - val_loss: 1.3270 - val_accuracy: 0.5625\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 76s 380ms/step - loss: 1.0408 - accuracy: 0.6373 - val_loss: 1.4615 - val_accuracy: 0.5225\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 1.0244 - accuracy: 0.6469 - val_loss: 1.6324 - val_accuracy: 0.4663\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 76s 380ms/step - loss: 1.0154 - accuracy: 0.6473 - val_loss: 1.3645 - val_accuracy: 0.5575\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 0.9995 - accuracy: 0.6570 - val_loss: 1.3594 - val_accuracy: 0.5625\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 76s 380ms/step - loss: 0.9896 - accuracy: 0.6516 - val_loss: 1.3718 - val_accuracy: 0.5600\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 0.9687 - accuracy: 0.6589 - val_loss: 1.4254 - val_accuracy: 0.5663\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 0.9814 - accuracy: 0.6553 - val_loss: 1.3649 - val_accuracy: 0.5788\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 0.9492 - accuracy: 0.6678 - val_loss: 1.3737 - val_accuracy: 0.5625\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 0.9681 - accuracy: 0.6641 - val_loss: 1.4325 - val_accuracy: 0.5562\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 0.9463 - accuracy: 0.6653 - val_loss: 1.5678 - val_accuracy: 0.5125\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 0.9479 - accuracy: 0.6706 - val_loss: 1.5407 - val_accuracy: 0.5163\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 0.9433 - accuracy: 0.6705 - val_loss: 1.4219 - val_accuracy: 0.5562\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 76s 380ms/step - loss: 0.9115 - accuracy: 0.6855 - val_loss: 1.5299 - val_accuracy: 0.5425\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 76s 380ms/step - loss: 0.9119 - accuracy: 0.6783 - val_loss: 1.3836 - val_accuracy: 0.5663\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.8985 - accuracy: 0.6856INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 15.40.46/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 80s 399ms/step - loss: 0.8985 - accuracy: 0.6856 - val_loss: 1.3886 - val_accuracy: 0.5975\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 0.8968 - accuracy: 0.6856 - val_loss: 1.4336 - val_accuracy: 0.5587\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 76s 380ms/step - loss: 0.8663 - accuracy: 0.6978 - val_loss: 1.4347 - val_accuracy: 0.5725\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 0.8811 - accuracy: 0.6925 - val_loss: 1.4516 - val_accuracy: 0.5788\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 76s 379ms/step - loss: 0.8627 - accuracy: 0.7010 - val_loss: 1.6529 - val_accuracy: 0.5075\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 48)      480       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 48)      192       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 48)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 48, 351, 48)       0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 48, 351, 48)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 351, 95)       41135     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 351, 95)       380       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 48, 351, 95)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 87, 95)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 87, 95)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 87, 95)        81320     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 87, 95)        380       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 87, 95)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 17, 95)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 17, 95)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 17, 142)        121552    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 17, 142)        568       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 8, 17, 142)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 3, 142)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2, 3, 142)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 852)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 6824      \n",
            "=================================================================\n",
            "Total params: 253,215\n",
            "Trainable params: 252,263\n",
            "Non-trainable params: 952\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5sMX9xCM-xu",
        "colab_type": "text"
      },
      "source": [
        "## Training 3-layer fully convolutional neural networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-SjNRKj-M5O",
        "colab_type": "code",
        "outputId": "d4eacbe6-09c0-4684-b0bd-850333b72065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Experiment 7\n",
        "# Deep k2c2\n",
        "\n",
        "params = {2000: [1,1,2],\n",
        "          4000: [2, 3, 3],\n",
        "          10000:[5, 8, 8],\n",
        "    50000:[16, 32, 32],\n",
        "          100000: [27, 54, 54],\n",
        "                    250000: [51, 101, 101]}\n",
        "\n",
        "num = 10000\n",
        "dropouts = [0.1, 0.1, 0.1, 0.2, 0.2, 0.4]\n",
        "\n",
        "for i, num in enumerate([2000, 4000, 10000, 50000, 100000, 250000]):\n",
        "\n",
        "  hyperparams = {\"number_filters\" : params[num],\n",
        "                \"number_params\" : num,\n",
        "                \"kernel_size\" : [(3, 3), (3,3), (3,3)],\n",
        "                \"pooling_size\" : [(2,4), (2,4), (3,5)],\n",
        "                \"hidden_layers\": [],\n",
        "                \"epsilon\": 0.01, \n",
        "                \"learning_rate\": 0.01, \n",
        "                \"batch_size\": 32, \n",
        "                \"epochs\": 100,\n",
        "                \"dropout\" : dropouts[i],\n",
        "                \"drop_out_hidden\" : 0\n",
        "                }\n",
        "\n",
        "\n",
        "  model_string = \"cnn_k2c2_4layer\"\n",
        "  model = cnn_k1c2_model(hyperparams)\n",
        "\n",
        "\n",
        "  history = run_experiment(model, model_string, hyperparams)\n",
        "  model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.9896 - accuracy: 0.2537INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-12 23.43.45/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.9896 - accuracy: 0.2537 - val_loss: 1.9552 - val_accuracy: 0.2875\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.8521 - accuracy: 0.3105INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-12 23.43.45/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 1.8521 - accuracy: 0.3105 - val_loss: 1.9072 - val_accuracy: 0.3150\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - 12s 58ms/step - loss: 1.8042 - accuracy: 0.3356 - val_loss: 2.0227 - val_accuracy: 0.2212\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.7811 - accuracy: 0.3433INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-12 23.43.45/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 1.7811 - accuracy: 0.3433 - val_loss: 1.8190 - val_accuracy: 0.3388\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - 12s 58ms/step - loss: 1.7617 - accuracy: 0.3530 - val_loss: 1.8208 - val_accuracy: 0.3363\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 12s 58ms/step - loss: 1.7276 - accuracy: 0.3692 - val_loss: 1.8294 - val_accuracy: 0.3212\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.6911 - accuracy: 0.3839INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-12 23.43.45/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 1.6911 - accuracy: 0.3839 - val_loss: 1.7093 - val_accuracy: 0.3675\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - 12s 59ms/step - loss: 1.6562 - accuracy: 0.4007 - val_loss: 1.9132 - val_accuracy: 0.2837\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 12s 59ms/step - loss: 1.6354 - accuracy: 0.4147 - val_loss: 1.7843 - val_accuracy: 0.3162\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.6142 - accuracy: 0.4221INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-12 23.43.45/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 1.6142 - accuracy: 0.4221 - val_loss: 1.6700 - val_accuracy: 0.3762\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 12s 59ms/step - loss: 1.5870 - accuracy: 0.4268 - val_loss: 2.0338 - val_accuracy: 0.2788\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.5700 - accuracy: 0.4325INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-12 23.43.45/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 1.5700 - accuracy: 0.4325 - val_loss: 1.6191 - val_accuracy: 0.4013\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 1.5580 - accuracy: 0.4407 - val_loss: 1.6364 - val_accuracy: 0.3925\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.5529 - accuracy: 0.4419 - val_loss: 1.9984 - val_accuracy: 0.2550\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.5303 - accuracy: 0.4513INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-12 23.43.45/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.5303 - accuracy: 0.4513 - val_loss: 1.6196 - val_accuracy: 0.4137\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.5346 - accuracy: 0.4426 - val_loss: 1.6550 - val_accuracy: 0.3988\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.5190 - accuracy: 0.4562INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-12 23.43.45/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.5190 - accuracy: 0.4562 - val_loss: 1.5990 - val_accuracy: 0.4212\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 1.5102 - accuracy: 0.4590 - val_loss: 1.6705 - val_accuracy: 0.4000\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 12s 62ms/step - loss: 1.4923 - accuracy: 0.4646 - val_loss: 1.6449 - val_accuracy: 0.4062\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 1.5031 - accuracy: 0.4526 - val_loss: 1.7268 - val_accuracy: 0.3688\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.5067 - accuracy: 0.4619 - val_loss: 1.6061 - val_accuracy: 0.4100\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 1.4936 - accuracy: 0.4652 - val_loss: 1.6789 - val_accuracy: 0.3688\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4995 - accuracy: 0.4660 - val_loss: 1.9016 - val_accuracy: 0.2875\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 1.4886 - accuracy: 0.4696 - val_loss: 1.5774 - val_accuracy: 0.4187\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 1.4864 - accuracy: 0.4705 - val_loss: 1.7357 - val_accuracy: 0.3413\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4905 - accuracy: 0.4638 - val_loss: 1.6480 - val_accuracy: 0.3975\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4811 - accuracy: 0.4749 - val_loss: 1.6581 - val_accuracy: 0.4087\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4793 - accuracy: 0.4726 - val_loss: 1.7006 - val_accuracy: 0.3738\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4737 - accuracy: 0.4724 - val_loss: 1.7914 - val_accuracy: 0.3400\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4692 - accuracy: 0.4843 - val_loss: 1.7531 - val_accuracy: 0.3475\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.4777 - accuracy: 0.4768INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-12 23.43.45/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 1.4777 - accuracy: 0.4768 - val_loss: 1.6214 - val_accuracy: 0.4350\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4660 - accuracy: 0.4774 - val_loss: 1.6253 - val_accuracy: 0.4000\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4691 - accuracy: 0.4810 - val_loss: 1.5787 - val_accuracy: 0.4175\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4611 - accuracy: 0.4823 - val_loss: 1.6343 - val_accuracy: 0.3775\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4578 - accuracy: 0.4880 - val_loss: 1.5962 - val_accuracy: 0.4112\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4660 - accuracy: 0.4815 - val_loss: 1.5825 - val_accuracy: 0.4112\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4620 - accuracy: 0.4794 - val_loss: 1.7722 - val_accuracy: 0.3750\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4584 - accuracy: 0.4819 - val_loss: 1.5856 - val_accuracy: 0.4125\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 1.4660 - accuracy: 0.4851 - val_loss: 1.6222 - val_accuracy: 0.4187\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4547 - accuracy: 0.4871 - val_loss: 1.6959 - val_accuracy: 0.3812\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4562 - accuracy: 0.4810 - val_loss: 1.7152 - val_accuracy: 0.3663\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4476 - accuracy: 0.4921 - val_loss: 1.5893 - val_accuracy: 0.4125\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4596 - accuracy: 0.4834 - val_loss: 1.5664 - val_accuracy: 0.4300\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 1.4486 - accuracy: 0.4840 - val_loss: 1.6306 - val_accuracy: 0.4238\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4550 - accuracy: 0.4824 - val_loss: 1.6012 - val_accuracy: 0.4225\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4581 - accuracy: 0.4840 - val_loss: 1.5698 - val_accuracy: 0.4212\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 1.4491 - accuracy: 0.4884 - val_loss: 1.5862 - val_accuracy: 0.4187\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4501 - accuracy: 0.4855 - val_loss: 1.5950 - val_accuracy: 0.4112\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4364 - accuracy: 0.4887 - val_loss: 1.5715 - val_accuracy: 0.4200\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 1.4580 - accuracy: 0.4815 - val_loss: 1.7418 - val_accuracy: 0.3425\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4499 - accuracy: 0.4935 - val_loss: 1.5732 - val_accuracy: 0.4225\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4541 - accuracy: 0.4812 - val_loss: 1.6059 - val_accuracy: 0.4187\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4426 - accuracy: 0.4869 - val_loss: 1.6281 - val_accuracy: 0.3938\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4402 - accuracy: 0.4930 - val_loss: 1.6167 - val_accuracy: 0.4288\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4397 - accuracy: 0.4909 - val_loss: 1.5863 - val_accuracy: 0.4250\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4315 - accuracy: 0.4863 - val_loss: 1.6279 - val_accuracy: 0.4263\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4531 - accuracy: 0.4837 - val_loss: 1.5949 - val_accuracy: 0.4175\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4439 - accuracy: 0.4869 - val_loss: 1.5856 - val_accuracy: 0.4263\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4423 - accuracy: 0.4866 - val_loss: 1.6622 - val_accuracy: 0.4200\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4459 - accuracy: 0.4848 - val_loss: 1.7272 - val_accuracy: 0.3638\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4449 - accuracy: 0.4894 - val_loss: 1.6041 - val_accuracy: 0.4300\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4418 - accuracy: 0.4880 - val_loss: 1.5692 - val_accuracy: 0.4187\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4384 - accuracy: 0.4960 - val_loss: 1.6052 - val_accuracy: 0.4137\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4372 - accuracy: 0.4924 - val_loss: 1.5954 - val_accuracy: 0.4313\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4358 - accuracy: 0.4918 - val_loss: 1.5987 - val_accuracy: 0.4175\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4391 - accuracy: 0.4937 - val_loss: 1.5653 - val_accuracy: 0.4062\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4310 - accuracy: 0.4882 - val_loss: 1.6417 - val_accuracy: 0.4075\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4325 - accuracy: 0.4940 - val_loss: 1.5966 - val_accuracy: 0.4175\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 1.4300 - accuracy: 0.4940 - val_loss: 1.6496 - val_accuracy: 0.4238\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 1.4368 - accuracy: 0.4929 - val_loss: 1.6020 - val_accuracy: 0.3975\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 1.4393 - accuracy: 0.4857 - val_loss: 1.5951 - val_accuracy: 0.4112\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4288 - accuracy: 0.4827 - val_loss: 1.7005 - val_accuracy: 0.3738\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4356 - accuracy: 0.4905 - val_loss: 1.6051 - val_accuracy: 0.4125\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4233 - accuracy: 0.4979 - val_loss: 1.6411 - val_accuracy: 0.4112\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4330 - accuracy: 0.4915 - val_loss: 1.6213 - val_accuracy: 0.4325\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4385 - accuracy: 0.4926 - val_loss: 1.6185 - val_accuracy: 0.4263\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4259 - accuracy: 0.4991 - val_loss: 1.6794 - val_accuracy: 0.3913\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4260 - accuracy: 0.4913 - val_loss: 1.6258 - val_accuracy: 0.4075\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4251 - accuracy: 0.4938 - val_loss: 1.7670 - val_accuracy: 0.3512\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 1.4306 - accuracy: 0.4957 - val_loss: 1.7295 - val_accuracy: 0.3638\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4382 - accuracy: 0.4893 - val_loss: 1.6501 - val_accuracy: 0.4125\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4321 - accuracy: 0.4935 - val_loss: 1.5867 - val_accuracy: 0.4225\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4194 - accuracy: 0.5035 - val_loss: 1.6977 - val_accuracy: 0.3812\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4288 - accuracy: 0.4965 - val_loss: 1.6325 - val_accuracy: 0.4050\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4416 - accuracy: 0.4902 - val_loss: 1.7607 - val_accuracy: 0.3325\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4349 - accuracy: 0.4948 - val_loss: 1.6150 - val_accuracy: 0.4150\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4311 - accuracy: 0.4902 - val_loss: 1.5863 - val_accuracy: 0.4125\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4305 - accuracy: 0.4945 - val_loss: 1.6604 - val_accuracy: 0.4013\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4271 - accuracy: 0.4968 - val_loss: 1.6590 - val_accuracy: 0.4100\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4318 - accuracy: 0.4869 - val_loss: 1.7411 - val_accuracy: 0.3550\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4252 - accuracy: 0.4882 - val_loss: 1.6990 - val_accuracy: 0.3800\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4249 - accuracy: 0.4924 - val_loss: 1.6107 - val_accuracy: 0.3988\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4278 - accuracy: 0.4973 - val_loss: 1.7171 - val_accuracy: 0.3675\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4279 - accuracy: 0.4973 - val_loss: 1.5924 - val_accuracy: 0.4250\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4326 - accuracy: 0.4938 - val_loss: 1.6229 - val_accuracy: 0.4187\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4120 - accuracy: 0.4985 - val_loss: 1.5968 - val_accuracy: 0.4062\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 12s 59ms/step - loss: 1.4205 - accuracy: 0.4976 - val_loss: 1.5879 - val_accuracy: 0.4238\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4244 - accuracy: 0.5034 - val_loss: 1.6069 - val_accuracy: 0.3988\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.4281 - accuracy: 0.4957 - val_loss: 1.5959 - val_accuracy: 0.4125\n",
            "Epoch 100/100\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.4116 - accuracy: 0.5017INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-12 23.43.45/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.4115 - accuracy: 0.5016 - val_loss: 1.5687 - val_accuracy: 0.4400\n",
            "Model: \"sequential_92\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_368 (Bat (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d_276 (Conv2D)          (None, 96, 1405, 1)       10        \n",
            "_________________________________________________________________\n",
            "batch_normalization_369 (Bat (None, 96, 1405, 1)       4         \n",
            "_________________________________________________________________\n",
            "activation_276 (Activation)  (None, 96, 1405, 1)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_276 (MaxPoolin (None, 48, 351, 1)        0         \n",
            "_________________________________________________________________\n",
            "dropout_276 (Dropout)        (None, 48, 351, 1)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_277 (Conv2D)          (None, 48, 351, 1)        10        \n",
            "_________________________________________________________________\n",
            "batch_normalization_370 (Bat (None, 48, 351, 1)        4         \n",
            "_________________________________________________________________\n",
            "activation_277 (Activation)  (None, 48, 351, 1)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_277 (MaxPoolin (None, 24, 87, 1)         0         \n",
            "_________________________________________________________________\n",
            "dropout_277 (Dropout)        (None, 24, 87, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_278 (Conv2D)          (None, 24, 87, 2)         20        \n",
            "_________________________________________________________________\n",
            "batch_normalization_371 (Bat (None, 24, 87, 2)         8         \n",
            "_________________________________________________________________\n",
            "activation_278 (Activation)  (None, 24, 87, 2)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_278 (MaxPoolin (None, 8, 17, 2)          0         \n",
            "_________________________________________________________________\n",
            "dropout_278 (Dropout)        (None, 8, 17, 2)          0         \n",
            "_________________________________________________________________\n",
            "flatten_92 (Flatten)         (None, 272)               0         \n",
            "_________________________________________________________________\n",
            "dense_92 (Dense)             (None, 8)                 2184      \n",
            "=================================================================\n",
            "Total params: 2,624\n",
            "Trainable params: 2,424\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 2.0052 - accuracy: 0.2609INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.04.28/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 2.0052 - accuracy: 0.2609 - val_loss: 2.0154 - val_accuracy: 0.2688\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.7273 - accuracy: 0.3739INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.04.28/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 1.7273 - accuracy: 0.3739 - val_loss: 1.7078 - val_accuracy: 0.3800\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.6139 - accuracy: 0.4244 - val_loss: 1.6973 - val_accuracy: 0.3725\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.5412 - accuracy: 0.4502 - val_loss: 1.7412 - val_accuracy: 0.3725\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.5112 - accuracy: 0.4707INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.04.28/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 17s 85ms/step - loss: 1.5112 - accuracy: 0.4707 - val_loss: 1.6329 - val_accuracy: 0.3825\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.4770 - accuracy: 0.4841INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.04.28/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 1.4770 - accuracy: 0.4841 - val_loss: 1.6395 - val_accuracy: 0.4075\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.4614 - accuracy: 0.4837INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.04.28/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 1.4614 - accuracy: 0.4837 - val_loss: 1.6092 - val_accuracy: 0.4225\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.4318 - accuracy: 0.4968INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.04.28/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 1.4318 - accuracy: 0.4968 - val_loss: 1.5881 - val_accuracy: 0.4350\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.4201 - accuracy: 0.4927 - val_loss: 1.6146 - val_accuracy: 0.4175\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 13s 63ms/step - loss: 1.4177 - accuracy: 0.4959 - val_loss: 1.6327 - val_accuracy: 0.4013\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.4019 - accuracy: 0.5116 - val_loss: 1.5772 - val_accuracy: 0.4338\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.4011 - accuracy: 0.5079 - val_loss: 1.6693 - val_accuracy: 0.4162\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3818 - accuracy: 0.5143 - val_loss: 1.6529 - val_accuracy: 0.3925\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3701 - accuracy: 0.5138INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.04.28/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 1.3701 - accuracy: 0.5138 - val_loss: 1.6055 - val_accuracy: 0.4425\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3706 - accuracy: 0.5162 - val_loss: 1.6505 - val_accuracy: 0.4200\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3784 - accuracy: 0.5174INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.04.28/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 17s 86ms/step - loss: 1.3784 - accuracy: 0.5174 - val_loss: 1.6002 - val_accuracy: 0.4475\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3556 - accuracy: 0.5282INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.04.28/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 1.3556 - accuracy: 0.5282 - val_loss: 1.5877 - val_accuracy: 0.4588\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3651 - accuracy: 0.5207 - val_loss: 1.6430 - val_accuracy: 0.4212\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.3617 - accuracy: 0.5174 - val_loss: 1.5986 - val_accuracy: 0.4175\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3496 - accuracy: 0.5235 - val_loss: 1.5956 - val_accuracy: 0.4412\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3558 - accuracy: 0.5221 - val_loss: 1.6197 - val_accuracy: 0.4212\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3394 - accuracy: 0.5302 - val_loss: 1.6360 - val_accuracy: 0.4200\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3499 - accuracy: 0.5209 - val_loss: 1.6361 - val_accuracy: 0.4338\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3385 - accuracy: 0.5273 - val_loss: 1.5606 - val_accuracy: 0.4512\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3449 - accuracy: 0.5234 - val_loss: 1.6432 - val_accuracy: 0.4162\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3397 - accuracy: 0.5296 - val_loss: 1.6102 - val_accuracy: 0.4363\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3293 - accuracy: 0.5281 - val_loss: 1.5954 - val_accuracy: 0.4588\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3237 - accuracy: 0.5382 - val_loss: 1.6578 - val_accuracy: 0.4175\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3291 - accuracy: 0.5327 - val_loss: 1.6394 - val_accuracy: 0.4187\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3247 - accuracy: 0.5318 - val_loss: 1.5722 - val_accuracy: 0.4563\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3371 - accuracy: 0.5287 - val_loss: 1.5924 - val_accuracy: 0.4375\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3212 - accuracy: 0.5304 - val_loss: 1.7663 - val_accuracy: 0.4112\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3231 - accuracy: 0.5279 - val_loss: 1.6701 - val_accuracy: 0.4325\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3245 - accuracy: 0.5345 - val_loss: 1.7152 - val_accuracy: 0.3913\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3108 - accuracy: 0.5442 - val_loss: 1.6824 - val_accuracy: 0.4350\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3017 - accuracy: 0.5506 - val_loss: 1.6772 - val_accuracy: 0.4238\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3200 - accuracy: 0.5363INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.04.28/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 1.3200 - accuracy: 0.5363 - val_loss: 1.5418 - val_accuracy: 0.4613\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.3195 - accuracy: 0.5338 - val_loss: 1.6026 - val_accuracy: 0.4475\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3199 - accuracy: 0.5354INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.04.28/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 1.3199 - accuracy: 0.5354 - val_loss: 1.5769 - val_accuracy: 0.4688\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.3152 - accuracy: 0.5396 - val_loss: 1.5986 - val_accuracy: 0.4538\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.3076 - accuracy: 0.5374 - val_loss: 1.6147 - val_accuracy: 0.4437\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3020 - accuracy: 0.5376 - val_loss: 1.6462 - val_accuracy: 0.4363\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3159 - accuracy: 0.5354INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.04.28/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 1.3159 - accuracy: 0.5354 - val_loss: 1.5984 - val_accuracy: 0.4762\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.3034 - accuracy: 0.5393 - val_loss: 1.6026 - val_accuracy: 0.4525\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3041 - accuracy: 0.5462 - val_loss: 1.5728 - val_accuracy: 0.4613\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 13s 63ms/step - loss: 1.2957 - accuracy: 0.5401 - val_loss: 1.5465 - val_accuracy: 0.4450\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 13s 63ms/step - loss: 1.3069 - accuracy: 0.5368 - val_loss: 1.6142 - val_accuracy: 0.4387\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 13s 63ms/step - loss: 1.3083 - accuracy: 0.5385 - val_loss: 1.6824 - val_accuracy: 0.4325\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3091 - accuracy: 0.5379 - val_loss: 1.6011 - val_accuracy: 0.4525\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 13s 63ms/step - loss: 1.2970 - accuracy: 0.5459 - val_loss: 1.6168 - val_accuracy: 0.4387\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3089 - accuracy: 0.5370INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.04.28/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 17s 85ms/step - loss: 1.3089 - accuracy: 0.5370 - val_loss: 1.6058 - val_accuracy: 0.4775\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 13s 63ms/step - loss: 1.3004 - accuracy: 0.5409 - val_loss: 1.5738 - val_accuracy: 0.4775\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2944 - accuracy: 0.5420 - val_loss: 1.6548 - val_accuracy: 0.4350\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2956 - accuracy: 0.5501 - val_loss: 1.5625 - val_accuracy: 0.4625\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 1.3017 - accuracy: 0.5412 - val_loss: 1.6306 - val_accuracy: 0.4313\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 1.3065 - accuracy: 0.5428 - val_loss: 1.6561 - val_accuracy: 0.4288\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2955 - accuracy: 0.5398 - val_loss: 1.6044 - val_accuracy: 0.4300\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2865 - accuracy: 0.5501 - val_loss: 1.6417 - val_accuracy: 0.4288\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2873 - accuracy: 0.5473 - val_loss: 1.5892 - val_accuracy: 0.4450\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2976 - accuracy: 0.5403 - val_loss: 1.6432 - val_accuracy: 0.4250\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2955 - accuracy: 0.5407 - val_loss: 1.5923 - val_accuracy: 0.4600\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2938 - accuracy: 0.5463 - val_loss: 1.6679 - val_accuracy: 0.4062\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 1.2757 - accuracy: 0.5534 - val_loss: 1.6171 - val_accuracy: 0.4400\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2977 - accuracy: 0.5484 - val_loss: 1.6362 - val_accuracy: 0.4150\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 13s 63ms/step - loss: 1.2854 - accuracy: 0.5470 - val_loss: 1.5775 - val_accuracy: 0.4550\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.2740 - accuracy: 0.5542 - val_loss: 1.6627 - val_accuracy: 0.4363\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.2786 - accuracy: 0.5496 - val_loss: 1.6460 - val_accuracy: 0.4400\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.2912 - accuracy: 0.5465 - val_loss: 1.6654 - val_accuracy: 0.4288\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.2863 - accuracy: 0.5376 - val_loss: 1.6884 - val_accuracy: 0.4250\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.2791 - accuracy: 0.5531 - val_loss: 1.6228 - val_accuracy: 0.4538\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 13s 63ms/step - loss: 1.2918 - accuracy: 0.5406 - val_loss: 1.6929 - val_accuracy: 0.4137\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 13s 63ms/step - loss: 1.2892 - accuracy: 0.5478 - val_loss: 1.6015 - val_accuracy: 0.4225\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2723 - accuracy: 0.5504 - val_loss: 1.6101 - val_accuracy: 0.4350\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2781 - accuracy: 0.5482 - val_loss: 1.6396 - val_accuracy: 0.4325\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2688 - accuracy: 0.5479 - val_loss: 1.6596 - val_accuracy: 0.4238\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2869 - accuracy: 0.5489 - val_loss: 1.5650 - val_accuracy: 0.4563\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 1.2800 - accuracy: 0.5484 - val_loss: 1.7365 - val_accuracy: 0.4087\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2822 - accuracy: 0.5438 - val_loss: 1.6218 - val_accuracy: 0.4437\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 1.2658 - accuracy: 0.5526 - val_loss: 1.6404 - val_accuracy: 0.4425\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2780 - accuracy: 0.5487 - val_loss: 1.6278 - val_accuracy: 0.4363\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2709 - accuracy: 0.5524 - val_loss: 1.6100 - val_accuracy: 0.4525\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 1.2698 - accuracy: 0.5523 - val_loss: 1.5988 - val_accuracy: 0.4512\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.2769 - accuracy: 0.5553 - val_loss: 1.6263 - val_accuracy: 0.4313\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 13s 63ms/step - loss: 1.2641 - accuracy: 0.5557 - val_loss: 1.5786 - val_accuracy: 0.4450\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.2787 - accuracy: 0.5539 - val_loss: 1.7517 - val_accuracy: 0.3938\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.3045 - accuracy: 0.5373 - val_loss: 1.6077 - val_accuracy: 0.4375\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 13s 63ms/step - loss: 1.2773 - accuracy: 0.5524 - val_loss: 1.6492 - val_accuracy: 0.4400\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2801 - accuracy: 0.5467 - val_loss: 1.5816 - val_accuracy: 0.4512\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 1.2700 - accuracy: 0.5540 - val_loss: 1.6274 - val_accuracy: 0.4387\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 1.2789 - accuracy: 0.5498 - val_loss: 1.6617 - val_accuracy: 0.4275\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2753 - accuracy: 0.5506 - val_loss: 1.5788 - val_accuracy: 0.4412\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2566 - accuracy: 0.5579 - val_loss: 1.6031 - val_accuracy: 0.4363\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2673 - accuracy: 0.5524 - val_loss: 1.6705 - val_accuracy: 0.4425\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2697 - accuracy: 0.5503 - val_loss: 1.5853 - val_accuracy: 0.4475\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2737 - accuracy: 0.5492 - val_loss: 1.6866 - val_accuracy: 0.4137\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 1.2616 - accuracy: 0.5517 - val_loss: 1.7953 - val_accuracy: 0.3963\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2749 - accuracy: 0.5503 - val_loss: 1.6797 - val_accuracy: 0.4250\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2790 - accuracy: 0.5496 - val_loss: 1.5902 - val_accuracy: 0.4437\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2634 - accuracy: 0.5523 - val_loss: 1.7686 - val_accuracy: 0.4200\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.2751 - accuracy: 0.5517 - val_loss: 1.6681 - val_accuracy: 0.4112\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 2)       20        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 2)       8         \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 2)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 48, 351, 2)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 48, 351, 2)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 351, 3)        57        \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 351, 3)        12        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 48, 351, 3)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 87, 3)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 87, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 87, 3)         84        \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 87, 3)         12        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 87, 3)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 17, 3)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 17, 3)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 408)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 3272      \n",
            "=================================================================\n",
            "Total params: 3,849\n",
            "Trainable params: 3,641\n",
            "Non-trainable params: 208\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 2.1787 - accuracy: 0.2892INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.26.51/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 20s 98ms/step - loss: 2.1787 - accuracy: 0.2892 - val_loss: 2.0556 - val_accuracy: 0.2800\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.6251 - accuracy: 0.4268INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.26.51/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 1.6251 - accuracy: 0.4268 - val_loss: 1.9266 - val_accuracy: 0.3487\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.5236 - accuracy: 0.4646INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.26.51/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 1.5236 - accuracy: 0.4646 - val_loss: 1.7018 - val_accuracy: 0.3938\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.4371 - accuracy: 0.4932INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.26.51/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 20s 102ms/step - loss: 1.4371 - accuracy: 0.4932 - val_loss: 1.7467 - val_accuracy: 0.4437\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3896 - accuracy: 0.5123INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.26.51/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 1.3896 - accuracy: 0.5123 - val_loss: 1.5903 - val_accuracy: 0.4462\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3613 - accuracy: 0.5277INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.26.51/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 1.3613 - accuracy: 0.5277 - val_loss: 1.6421 - val_accuracy: 0.4538\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 1.3152 - accuracy: 0.5498 - val_loss: 1.5479 - val_accuracy: 0.4437\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.2944 - accuracy: 0.5485INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.26.51/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 1.2944 - accuracy: 0.5485 - val_loss: 1.6099 - val_accuracy: 0.4575\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 1.2582 - accuracy: 0.5690 - val_loss: 1.6837 - val_accuracy: 0.4288\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 1.2295 - accuracy: 0.5789 - val_loss: 1.7237 - val_accuracy: 0.4338\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.2347 - accuracy: 0.5743INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.26.51/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 1.2347 - accuracy: 0.5743 - val_loss: 1.5730 - val_accuracy: 0.4725\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 1.1945 - accuracy: 0.5829 - val_loss: 1.6080 - val_accuracy: 0.4450\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 1.1947 - accuracy: 0.5862 - val_loss: 1.6165 - val_accuracy: 0.4512\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 1.1855 - accuracy: 0.5897 - val_loss: 1.8490 - val_accuracy: 0.3975\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 1.1466 - accuracy: 0.6081 - val_loss: 1.5994 - val_accuracy: 0.4575\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.1337 - accuracy: 0.6219INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.26.51/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 20s 102ms/step - loss: 1.1337 - accuracy: 0.6219 - val_loss: 1.5181 - val_accuracy: 0.4787\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 1.1279 - accuracy: 0.6031 - val_loss: 1.7038 - val_accuracy: 0.4238\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 1.1280 - accuracy: 0.6087 - val_loss: 1.6217 - val_accuracy: 0.4475\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 1.1130 - accuracy: 0.6120 - val_loss: 1.5443 - val_accuracy: 0.4638\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.1079 - accuracy: 0.6120INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.26.51/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 1.1079 - accuracy: 0.6120 - val_loss: 1.6195 - val_accuracy: 0.4812\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 1.0905 - accuracy: 0.6179 - val_loss: 1.6419 - val_accuracy: 0.4688\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 1.0766 - accuracy: 0.6265 - val_loss: 1.6409 - val_accuracy: 0.4500\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 1.0748 - accuracy: 0.6233 - val_loss: 1.6571 - val_accuracy: 0.4538\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 1.0747 - accuracy: 0.6251 - val_loss: 1.6253 - val_accuracy: 0.4613\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.0674 - accuracy: 0.6284INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.26.51/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 1.0674 - accuracy: 0.6284 - val_loss: 1.6286 - val_accuracy: 0.4863\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.0619 - accuracy: 0.6322INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.26.51/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 1.0619 - accuracy: 0.6322 - val_loss: 1.5338 - val_accuracy: 0.4913\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 1.0559 - accuracy: 0.6275 - val_loss: 1.6179 - val_accuracy: 0.4888\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 1.0445 - accuracy: 0.6330 - val_loss: 1.6553 - val_accuracy: 0.4650\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 1.0532 - accuracy: 0.6298 - val_loss: 1.6407 - val_accuracy: 0.4663\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 1.0298 - accuracy: 0.6408 - val_loss: 1.6794 - val_accuracy: 0.4487\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 1.0404 - accuracy: 0.6336 - val_loss: 1.6396 - val_accuracy: 0.4613\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 1.0343 - accuracy: 0.6372 - val_loss: 1.6742 - val_accuracy: 0.4850\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 1.0274 - accuracy: 0.6322 - val_loss: 1.6180 - val_accuracy: 0.4775\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 1.0246 - accuracy: 0.6397 - val_loss: 1.6333 - val_accuracy: 0.4613\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 1.0209 - accuracy: 0.6448 - val_loss: 1.6409 - val_accuracy: 0.4725\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 1.0011 - accuracy: 0.6414 - val_loss: 1.6537 - val_accuracy: 0.4625\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 1.0169 - accuracy: 0.6478 - val_loss: 1.6587 - val_accuracy: 0.4725\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 1.0034 - accuracy: 0.6461 - val_loss: 1.6890 - val_accuracy: 0.4725\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9813 - accuracy: 0.6509 - val_loss: 1.7108 - val_accuracy: 0.4837\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.9909 - accuracy: 0.6451INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.26.51/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 20s 101ms/step - loss: 0.9909 - accuracy: 0.6451 - val_loss: 1.6119 - val_accuracy: 0.5050\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.9944 - accuracy: 0.6514 - val_loss: 1.6719 - val_accuracy: 0.4825\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9880 - accuracy: 0.6464 - val_loss: 1.6345 - val_accuracy: 0.4750\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9819 - accuracy: 0.6553 - val_loss: 1.7093 - val_accuracy: 0.4712\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 1.0058 - accuracy: 0.6495 - val_loss: 1.6876 - val_accuracy: 0.4613\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9849 - accuracy: 0.6537 - val_loss: 1.6564 - val_accuracy: 0.4700\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9803 - accuracy: 0.6600 - val_loss: 1.6831 - val_accuracy: 0.4588\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9669 - accuracy: 0.6603 - val_loss: 1.6572 - val_accuracy: 0.4900\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9792 - accuracy: 0.6570 - val_loss: 1.6815 - val_accuracy: 0.4613\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9728 - accuracy: 0.6587 - val_loss: 1.7207 - val_accuracy: 0.4625\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.9652 - accuracy: 0.6631 - val_loss: 1.7421 - val_accuracy: 0.4650\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.9828 - accuracy: 0.6586 - val_loss: 1.7618 - val_accuracy: 0.4812\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9604 - accuracy: 0.6587 - val_loss: 1.6567 - val_accuracy: 0.4800\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9682 - accuracy: 0.6577 - val_loss: 1.7754 - val_accuracy: 0.4325\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9579 - accuracy: 0.6625 - val_loss: 1.6773 - val_accuracy: 0.4725\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.9691 - accuracy: 0.6584 - val_loss: 1.7470 - val_accuracy: 0.4487\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.9562 - accuracy: 0.6652 - val_loss: 1.7612 - val_accuracy: 0.4563\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9644 - accuracy: 0.6609 - val_loss: 1.7299 - val_accuracy: 0.4750\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9558 - accuracy: 0.6652 - val_loss: 1.7122 - val_accuracy: 0.4725\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9513 - accuracy: 0.6603 - val_loss: 1.6861 - val_accuracy: 0.4588\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9602 - accuracy: 0.6625 - val_loss: 1.7074 - val_accuracy: 0.4638\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9712 - accuracy: 0.6545 - val_loss: 1.7012 - val_accuracy: 0.4500\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9675 - accuracy: 0.6552 - val_loss: 1.7053 - val_accuracy: 0.4900\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9435 - accuracy: 0.6688 - val_loss: 1.7056 - val_accuracy: 0.4613\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9517 - accuracy: 0.6642 - val_loss: 1.6873 - val_accuracy: 0.4638\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9399 - accuracy: 0.6730 - val_loss: 1.7387 - val_accuracy: 0.4712\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9350 - accuracy: 0.6713 - val_loss: 1.7070 - val_accuracy: 0.4625\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9351 - accuracy: 0.6744 - val_loss: 1.7300 - val_accuracy: 0.4688\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9390 - accuracy: 0.6727 - val_loss: 1.7653 - val_accuracy: 0.4825\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9416 - accuracy: 0.6662 - val_loss: 1.6926 - val_accuracy: 0.4712\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.9216 - accuracy: 0.6791 - val_loss: 1.6956 - val_accuracy: 0.4538\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9436 - accuracy: 0.6691 - val_loss: 1.7052 - val_accuracy: 0.4700\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9312 - accuracy: 0.6637 - val_loss: 1.7158 - val_accuracy: 0.4913\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9444 - accuracy: 0.6648 - val_loss: 1.7249 - val_accuracy: 0.4675\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9418 - accuracy: 0.6736 - val_loss: 1.8667 - val_accuracy: 0.4462\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9357 - accuracy: 0.6684 - val_loss: 1.6920 - val_accuracy: 0.4775\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9311 - accuracy: 0.6673 - val_loss: 1.7392 - val_accuracy: 0.4487\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9295 - accuracy: 0.6708 - val_loss: 1.7742 - val_accuracy: 0.4313\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9267 - accuracy: 0.6767 - val_loss: 1.7276 - val_accuracy: 0.4675\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9169 - accuracy: 0.6777 - val_loss: 1.7185 - val_accuracy: 0.4787\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9267 - accuracy: 0.6750 - val_loss: 1.8037 - val_accuracy: 0.4462\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9272 - accuracy: 0.6720 - val_loss: 1.7911 - val_accuracy: 0.4625\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9187 - accuracy: 0.6788 - val_loss: 1.7221 - val_accuracy: 0.4650\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9145 - accuracy: 0.6761 - val_loss: 1.8298 - val_accuracy: 0.4525\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9398 - accuracy: 0.6695 - val_loss: 1.7505 - val_accuracy: 0.4600\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.9202 - accuracy: 0.6713 - val_loss: 1.8165 - val_accuracy: 0.4688\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9361 - accuracy: 0.6672 - val_loss: 1.7865 - val_accuracy: 0.4600\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.9135 - accuracy: 0.6770 - val_loss: 1.8131 - val_accuracy: 0.4475\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.9016 - accuracy: 0.6808 - val_loss: 1.8204 - val_accuracy: 0.4487\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9323 - accuracy: 0.6716 - val_loss: 1.7489 - val_accuracy: 0.4800\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9133 - accuracy: 0.6739 - val_loss: 1.8715 - val_accuracy: 0.4487\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9129 - accuracy: 0.6806 - val_loss: 1.7743 - val_accuracy: 0.4550\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9132 - accuracy: 0.6783 - val_loss: 1.8034 - val_accuracy: 0.4837\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9135 - accuracy: 0.6734 - val_loss: 1.7762 - val_accuracy: 0.4512\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9126 - accuracy: 0.6813 - val_loss: 1.7772 - val_accuracy: 0.4800\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9112 - accuracy: 0.6748 - val_loss: 1.7672 - val_accuracy: 0.4762\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9111 - accuracy: 0.6792 - val_loss: 1.7774 - val_accuracy: 0.4625\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9059 - accuracy: 0.6817 - val_loss: 1.8274 - val_accuracy: 0.4300\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9125 - accuracy: 0.6789 - val_loss: 1.8122 - val_accuracy: 0.4437\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9252 - accuracy: 0.6770 - val_loss: 1.8153 - val_accuracy: 0.4625\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 0.9336 - accuracy: 0.6669 - val_loss: 1.8099 - val_accuracy: 0.4538\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 5)       50        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 5)       20        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 5)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 48, 351, 5)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 48, 351, 5)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 351, 8)        368       \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 351, 8)        32        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 48, 351, 8)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 87, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 87, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 87, 8)         584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 87, 8)         32        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 87, 8)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 17, 8)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 17, 8)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1088)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 8712      \n",
            "=================================================================\n",
            "Total params: 10,182\n",
            "Trainable params: 9,948\n",
            "Non-trainable params: 234\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 3.5543 - accuracy: 0.2478INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.54.11/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 31s 154ms/step - loss: 3.5543 - accuracy: 0.2478 - val_loss: 2.6316 - val_accuracy: 0.2550\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.8992 - accuracy: 0.3436INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.54.11/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 30s 152ms/step - loss: 1.8992 - accuracy: 0.3436 - val_loss: 2.0215 - val_accuracy: 0.2950\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.5845 - accuracy: 0.4465INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.54.11/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 30s 151ms/step - loss: 1.5845 - accuracy: 0.4465 - val_loss: 1.6759 - val_accuracy: 0.4162\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.4564 - accuracy: 0.4937INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.54.11/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 30s 150ms/step - loss: 1.4564 - accuracy: 0.4937 - val_loss: 1.5739 - val_accuracy: 0.4275\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 1.4039 - accuracy: 0.5170 - val_loss: 1.6657 - val_accuracy: 0.4062\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3398 - accuracy: 0.5448INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.54.11/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 31s 157ms/step - loss: 1.3398 - accuracy: 0.5448 - val_loss: 1.5480 - val_accuracy: 0.4600\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 1.2988 - accuracy: 0.5506 - val_loss: 1.6812 - val_accuracy: 0.3663\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 1.2666 - accuracy: 0.5684 - val_loss: 1.5950 - val_accuracy: 0.4075\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.2119 - accuracy: 0.5836INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.54.11/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 30s 151ms/step - loss: 1.2119 - accuracy: 0.5836 - val_loss: 1.5242 - val_accuracy: 0.4888\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 1.1979 - accuracy: 0.5870 - val_loss: 1.5596 - val_accuracy: 0.4700\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 1.1692 - accuracy: 0.6028 - val_loss: 1.5599 - val_accuracy: 0.4825\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 1.1221 - accuracy: 0.6195 - val_loss: 1.6745 - val_accuracy: 0.4613\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 1.1192 - accuracy: 0.6162 - val_loss: 1.6144 - val_accuracy: 0.4850\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 1.0744 - accuracy: 0.6265 - val_loss: 1.6521 - val_accuracy: 0.4850\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 1.0518 - accuracy: 0.6392 - val_loss: 1.7036 - val_accuracy: 0.4600\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.0320 - accuracy: 0.6419INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.54.11/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 30s 151ms/step - loss: 1.0320 - accuracy: 0.6419 - val_loss: 1.6781 - val_accuracy: 0.4925\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.0160 - accuracy: 0.6437INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 00.54.11/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 30s 151ms/step - loss: 1.0160 - accuracy: 0.6437 - val_loss: 1.6974 - val_accuracy: 0.5075\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.9698 - accuracy: 0.6591 - val_loss: 1.7119 - val_accuracy: 0.4638\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.9401 - accuracy: 0.6814 - val_loss: 1.6343 - val_accuracy: 0.4913\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.9151 - accuracy: 0.6789 - val_loss: 1.7869 - val_accuracy: 0.4875\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.8927 - accuracy: 0.6925 - val_loss: 1.8777 - val_accuracy: 0.4475\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.8692 - accuracy: 0.6952 - val_loss: 1.9620 - val_accuracy: 0.4425\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.8593 - accuracy: 0.7024 - val_loss: 1.8290 - val_accuracy: 0.4762\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.8349 - accuracy: 0.7110 - val_loss: 1.9181 - val_accuracy: 0.4725\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.8005 - accuracy: 0.7263 - val_loss: 1.8775 - val_accuracy: 0.4487\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.8021 - accuracy: 0.7186 - val_loss: 1.8733 - val_accuracy: 0.4625\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.7472 - accuracy: 0.7428 - val_loss: 1.8335 - val_accuracy: 0.4588\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.7576 - accuracy: 0.7347 - val_loss: 2.0888 - val_accuracy: 0.4550\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.7715 - accuracy: 0.7313 - val_loss: 1.9739 - val_accuracy: 0.4875\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.7122 - accuracy: 0.7530 - val_loss: 1.9764 - val_accuracy: 0.4600\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.6987 - accuracy: 0.7514 - val_loss: 1.9358 - val_accuracy: 0.4850\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.6829 - accuracy: 0.7597 - val_loss: 2.1742 - val_accuracy: 0.4475\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.6770 - accuracy: 0.7604 - val_loss: 2.1674 - val_accuracy: 0.4375\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.6801 - accuracy: 0.7658 - val_loss: 2.0749 - val_accuracy: 0.4900\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.6516 - accuracy: 0.7672 - val_loss: 2.1011 - val_accuracy: 0.4712\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.6324 - accuracy: 0.7758 - val_loss: 2.2155 - val_accuracy: 0.4525\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.5840 - accuracy: 0.7935 - val_loss: 2.1752 - val_accuracy: 0.4688\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.6213 - accuracy: 0.7846 - val_loss: 2.2870 - val_accuracy: 0.4550\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.5793 - accuracy: 0.7962 - val_loss: 2.2137 - val_accuracy: 0.4825\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.6052 - accuracy: 0.7893 - val_loss: 2.2064 - val_accuracy: 0.4888\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.5567 - accuracy: 0.7994 - val_loss: 2.2849 - val_accuracy: 0.4812\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.5679 - accuracy: 0.7972 - val_loss: 2.2942 - val_accuracy: 0.4812\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.5721 - accuracy: 0.8018 - val_loss: 2.2535 - val_accuracy: 0.4700\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.5379 - accuracy: 0.8132 - val_loss: 2.3273 - val_accuracy: 0.4675\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.5201 - accuracy: 0.8174 - val_loss: 2.4244 - val_accuracy: 0.4600\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.5357 - accuracy: 0.8112 - val_loss: 2.2819 - val_accuracy: 0.4675\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.5211 - accuracy: 0.8169 - val_loss: 2.3686 - val_accuracy: 0.4638\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.4996 - accuracy: 0.8243 - val_loss: 2.4871 - val_accuracy: 0.4450\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.5227 - accuracy: 0.8112 - val_loss: 2.3821 - val_accuracy: 0.4737\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.4982 - accuracy: 0.8234 - val_loss: 2.3808 - val_accuracy: 0.4688\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.5257 - accuracy: 0.8112 - val_loss: 2.4304 - val_accuracy: 0.4663\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.4678 - accuracy: 0.8327 - val_loss: 2.2193 - val_accuracy: 0.4837\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.4660 - accuracy: 0.8334 - val_loss: 2.6773 - val_accuracy: 0.4250\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.4781 - accuracy: 0.8291 - val_loss: 2.5156 - val_accuracy: 0.4487\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.4568 - accuracy: 0.8360 - val_loss: 2.5389 - val_accuracy: 0.4737\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.4756 - accuracy: 0.8315 - val_loss: 2.4626 - val_accuracy: 0.4800\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.4580 - accuracy: 0.8429 - val_loss: 2.4096 - val_accuracy: 0.4700\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 27s 136ms/step - loss: 0.4479 - accuracy: 0.8446 - val_loss: 2.6057 - val_accuracy: 0.4625\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 27s 136ms/step - loss: 0.4633 - accuracy: 0.8382 - val_loss: 2.4106 - val_accuracy: 0.4650\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.4326 - accuracy: 0.8481 - val_loss: 2.5353 - val_accuracy: 0.4575\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.4299 - accuracy: 0.8496 - val_loss: 2.6151 - val_accuracy: 0.4700\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.4321 - accuracy: 0.8435 - val_loss: 2.5640 - val_accuracy: 0.4875\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 27s 133ms/step - loss: 0.4338 - accuracy: 0.8516 - val_loss: 2.4995 - val_accuracy: 0.4650\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.4203 - accuracy: 0.8524 - val_loss: 2.7560 - val_accuracy: 0.4338\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.4274 - accuracy: 0.8540 - val_loss: 2.5608 - val_accuracy: 0.4725\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.4053 - accuracy: 0.8582 - val_loss: 2.6652 - val_accuracy: 0.4712\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.4099 - accuracy: 0.8546 - val_loss: 2.4786 - val_accuracy: 0.4888\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.4239 - accuracy: 0.8471 - val_loss: 2.6604 - val_accuracy: 0.4625\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 27s 136ms/step - loss: 0.3962 - accuracy: 0.8643 - val_loss: 2.6096 - val_accuracy: 0.4725\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 27s 136ms/step - loss: 0.4022 - accuracy: 0.8577 - val_loss: 2.6386 - val_accuracy: 0.4475\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 27s 136ms/step - loss: 0.4254 - accuracy: 0.8491 - val_loss: 2.5819 - val_accuracy: 0.4863\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 27s 136ms/step - loss: 0.4030 - accuracy: 0.8620 - val_loss: 2.6632 - val_accuracy: 0.4538\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.3917 - accuracy: 0.8629 - val_loss: 2.6451 - val_accuracy: 0.4487\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 27s 136ms/step - loss: 0.3848 - accuracy: 0.8685 - val_loss: 2.6158 - val_accuracy: 0.4688\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 27s 136ms/step - loss: 0.3900 - accuracy: 0.8652 - val_loss: 2.6992 - val_accuracy: 0.4538\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.3677 - accuracy: 0.8740 - val_loss: 2.6819 - val_accuracy: 0.4425\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.4023 - accuracy: 0.8646 - val_loss: 2.6074 - val_accuracy: 0.4725\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.4021 - accuracy: 0.8612 - val_loss: 2.7781 - val_accuracy: 0.4625\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.3573 - accuracy: 0.8679 - val_loss: 2.7245 - val_accuracy: 0.4787\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.3838 - accuracy: 0.8668 - val_loss: 2.7298 - val_accuracy: 0.4688\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.3806 - accuracy: 0.8645 - val_loss: 2.8339 - val_accuracy: 0.4725\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 27s 136ms/step - loss: 0.3825 - accuracy: 0.8642 - val_loss: 2.7999 - val_accuracy: 0.4487\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.3603 - accuracy: 0.8734 - val_loss: 2.7803 - val_accuracy: 0.4600\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.3623 - accuracy: 0.8738 - val_loss: 2.9073 - val_accuracy: 0.4462\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.3690 - accuracy: 0.8753 - val_loss: 2.7626 - val_accuracy: 0.4575\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.3625 - accuracy: 0.8782 - val_loss: 2.7849 - val_accuracy: 0.4600\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.3459 - accuracy: 0.8815 - val_loss: 2.7903 - val_accuracy: 0.4688\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.3625 - accuracy: 0.8737 - val_loss: 2.6740 - val_accuracy: 0.4725\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.3507 - accuracy: 0.8779 - val_loss: 2.7553 - val_accuracy: 0.4525\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 27s 136ms/step - loss: 0.3577 - accuracy: 0.8738 - val_loss: 2.6536 - val_accuracy: 0.4950\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 27s 136ms/step - loss: 0.3519 - accuracy: 0.8806 - val_loss: 2.6597 - val_accuracy: 0.4550\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 27s 136ms/step - loss: 0.3422 - accuracy: 0.8810 - val_loss: 2.8230 - val_accuracy: 0.4762\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 27s 136ms/step - loss: 0.3572 - accuracy: 0.8785 - val_loss: 2.8418 - val_accuracy: 0.4588\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.3553 - accuracy: 0.8770 - val_loss: 2.7993 - val_accuracy: 0.4588\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.3590 - accuracy: 0.8748 - val_loss: 2.6881 - val_accuracy: 0.4812\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.3532 - accuracy: 0.8798 - val_loss: 2.8255 - val_accuracy: 0.4888\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 27s 136ms/step - loss: 0.3567 - accuracy: 0.8779 - val_loss: 2.6348 - val_accuracy: 0.4725\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.3372 - accuracy: 0.8817 - val_loss: 2.9118 - val_accuracy: 0.4462\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 27s 136ms/step - loss: 0.3406 - accuracy: 0.8807 - val_loss: 2.8965 - val_accuracy: 0.4338\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.3426 - accuracy: 0.8835 - val_loss: 2.7739 - val_accuracy: 0.4975\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 16)      160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 16)      64        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 16)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 48, 351, 16)       0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 48, 351, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 351, 32)       4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 351, 32)       128       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 48, 351, 32)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 87, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 87, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 87, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 87, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 87, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 17, 32)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 17, 32)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4352)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 34824     \n",
            "=================================================================\n",
            "Total params: 49,576\n",
            "Trainable params: 49,224\n",
            "Non-trainable params: 352\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 5.4749 - accuracy: 0.2359INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 01.39.53/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 47s 236ms/step - loss: 5.4749 - accuracy: 0.2359 - val_loss: 2.3338 - val_accuracy: 0.3050\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - 42s 209ms/step - loss: 2.1761 - accuracy: 0.3075 - val_loss: 1.9821 - val_accuracy: 0.2875\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.7260 - accuracy: 0.3839INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 01.39.53/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 45s 224ms/step - loss: 1.7260 - accuracy: 0.3839 - val_loss: 1.7370 - val_accuracy: 0.3525\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.5589 - accuracy: 0.4521INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 01.39.53/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 45s 225ms/step - loss: 1.5589 - accuracy: 0.4521 - val_loss: 1.5775 - val_accuracy: 0.4462\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.4663 - accuracy: 0.4863INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 01.39.53/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 45s 225ms/step - loss: 1.4663 - accuracy: 0.4863 - val_loss: 1.5546 - val_accuracy: 0.4650\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 42s 209ms/step - loss: 1.3936 - accuracy: 0.5152 - val_loss: 1.5479 - val_accuracy: 0.4638\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 1.3464 - accuracy: 0.5246 - val_loss: 1.7474 - val_accuracy: 0.4087\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3038 - accuracy: 0.5465INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 01.39.53/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 45s 224ms/step - loss: 1.3038 - accuracy: 0.5465 - val_loss: 1.4732 - val_accuracy: 0.4775\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 42s 209ms/step - loss: 1.2686 - accuracy: 0.5606 - val_loss: 1.5855 - val_accuracy: 0.4688\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 42s 209ms/step - loss: 1.2204 - accuracy: 0.5795 - val_loss: 1.6297 - val_accuracy: 0.4512\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 42s 209ms/step - loss: 1.1953 - accuracy: 0.5897 - val_loss: 1.9233 - val_accuracy: 0.3825\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 42s 209ms/step - loss: 1.1382 - accuracy: 0.6125 - val_loss: 1.7311 - val_accuracy: 0.4512\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 42s 209ms/step - loss: 1.0963 - accuracy: 0.6237 - val_loss: 1.6634 - val_accuracy: 0.4487\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 42s 209ms/step - loss: 1.0613 - accuracy: 0.6334 - val_loss: 1.7694 - val_accuracy: 0.4575\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.0219 - accuracy: 0.6444INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 01.39.53/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 47s 233ms/step - loss: 1.0219 - accuracy: 0.6444 - val_loss: 1.6715 - val_accuracy: 0.4863\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 42s 209ms/step - loss: 0.9780 - accuracy: 0.6562 - val_loss: 1.7034 - val_accuracy: 0.4563\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 42s 209ms/step - loss: 0.9339 - accuracy: 0.6741 - val_loss: 1.7235 - val_accuracy: 0.4412\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 42s 209ms/step - loss: 0.9001 - accuracy: 0.6916 - val_loss: 1.7940 - val_accuracy: 0.4663\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 42s 209ms/step - loss: 0.8659 - accuracy: 0.6947 - val_loss: 1.8472 - val_accuracy: 0.4487\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.8269 - accuracy: 0.7050INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 01.39.53/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 45s 224ms/step - loss: 0.8269 - accuracy: 0.7050 - val_loss: 1.7755 - val_accuracy: 0.5038\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.7818 - accuracy: 0.7230 - val_loss: 2.0284 - val_accuracy: 0.4663\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.7749 - accuracy: 0.7261 - val_loss: 1.9483 - val_accuracy: 0.4563\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 42s 209ms/step - loss: 0.7136 - accuracy: 0.7486 - val_loss: 1.9499 - val_accuracy: 0.4850\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 42s 209ms/step - loss: 0.6779 - accuracy: 0.7627 - val_loss: 2.0407 - val_accuracy: 0.4888\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 42s 209ms/step - loss: 0.6475 - accuracy: 0.7744 - val_loss: 2.1681 - val_accuracy: 0.4550\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.6552 - accuracy: 0.7719 - val_loss: 2.2010 - val_accuracy: 0.4538\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 42s 209ms/step - loss: 0.6038 - accuracy: 0.7880 - val_loss: 2.1780 - val_accuracy: 0.4737\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.5743 - accuracy: 0.8005 - val_loss: 2.2809 - val_accuracy: 0.4450\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.5628 - accuracy: 0.8010 - val_loss: 2.4233 - val_accuracy: 0.4475\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.5246 - accuracy: 0.8152 - val_loss: 2.5451 - val_accuracy: 0.4575\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.5414 - accuracy: 0.8019 - val_loss: 2.3714 - val_accuracy: 0.4712\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.5121 - accuracy: 0.8257 - val_loss: 2.5421 - val_accuracy: 0.4675\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.4739 - accuracy: 0.8380 - val_loss: 2.6336 - val_accuracy: 0.4575\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.4516 - accuracy: 0.8452 - val_loss: 2.4911 - val_accuracy: 0.4588\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.4205 - accuracy: 0.8532 - val_loss: 2.6828 - val_accuracy: 0.4675\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.4203 - accuracy: 0.8556 - val_loss: 2.5391 - val_accuracy: 0.4525\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.4284 - accuracy: 0.8527 - val_loss: 2.6958 - val_accuracy: 0.4613\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.4312 - accuracy: 0.8568 - val_loss: 2.8176 - val_accuracy: 0.4512\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.3958 - accuracy: 0.8602 - val_loss: 2.9683 - val_accuracy: 0.4225\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.3844 - accuracy: 0.8740 - val_loss: 2.7119 - val_accuracy: 0.4412\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.3850 - accuracy: 0.8648 - val_loss: 2.9935 - val_accuracy: 0.4363\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.3493 - accuracy: 0.8796 - val_loss: 3.2368 - val_accuracy: 0.4212\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.3744 - accuracy: 0.8781 - val_loss: 2.8883 - val_accuracy: 0.4663\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.3439 - accuracy: 0.8815 - val_loss: 3.2074 - val_accuracy: 0.4350\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.3273 - accuracy: 0.8879 - val_loss: 3.2056 - val_accuracy: 0.4263\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.3159 - accuracy: 0.8951 - val_loss: 3.1742 - val_accuracy: 0.4500\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.3154 - accuracy: 0.8898 - val_loss: 3.2066 - val_accuracy: 0.4500\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.3471 - accuracy: 0.8845 - val_loss: 3.2395 - val_accuracy: 0.4750\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.3210 - accuracy: 0.8909 - val_loss: 3.1267 - val_accuracy: 0.4600\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2823 - accuracy: 0.9020 - val_loss: 3.0275 - val_accuracy: 0.4812\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.3016 - accuracy: 0.8973 - val_loss: 3.4446 - val_accuracy: 0.4700\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.3024 - accuracy: 0.8957 - val_loss: 3.2974 - val_accuracy: 0.4625\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2848 - accuracy: 0.9045 - val_loss: 3.3114 - val_accuracy: 0.4588\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.3057 - accuracy: 0.8962 - val_loss: 3.4596 - val_accuracy: 0.4725\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2986 - accuracy: 0.9000 - val_loss: 3.5800 - val_accuracy: 0.4588\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2852 - accuracy: 0.9045 - val_loss: 3.3675 - val_accuracy: 0.4462\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 42s 209ms/step - loss: 0.2589 - accuracy: 0.9143 - val_loss: 3.3617 - val_accuracy: 0.4750\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2420 - accuracy: 0.9167 - val_loss: 3.4744 - val_accuracy: 0.4700\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2464 - accuracy: 0.9182 - val_loss: 3.4968 - val_accuracy: 0.4512\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2746 - accuracy: 0.9053 - val_loss: 3.7394 - val_accuracy: 0.4487\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2536 - accuracy: 0.9143 - val_loss: 3.6563 - val_accuracy: 0.4613\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2649 - accuracy: 0.9140 - val_loss: 3.5976 - val_accuracy: 0.4450\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2723 - accuracy: 0.9101 - val_loss: 3.8073 - val_accuracy: 0.4563\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2279 - accuracy: 0.9192 - val_loss: 3.6315 - val_accuracy: 0.4425\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2504 - accuracy: 0.9192 - val_loss: 3.5555 - val_accuracy: 0.4725\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2655 - accuracy: 0.9151 - val_loss: 3.6654 - val_accuracy: 0.4762\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2358 - accuracy: 0.9229 - val_loss: 3.6562 - val_accuracy: 0.4625\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.1994 - accuracy: 0.9322 - val_loss: 3.9315 - val_accuracy: 0.4563\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2205 - accuracy: 0.9270 - val_loss: 3.7580 - val_accuracy: 0.4613\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2251 - accuracy: 0.9217 - val_loss: 4.0202 - val_accuracy: 0.4650\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2296 - accuracy: 0.9259 - val_loss: 3.6689 - val_accuracy: 0.4600\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2209 - accuracy: 0.9254 - val_loss: 3.6227 - val_accuracy: 0.4850\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 42s 209ms/step - loss: 0.2231 - accuracy: 0.9270 - val_loss: 3.6753 - val_accuracy: 0.4663\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 42s 209ms/step - loss: 0.2201 - accuracy: 0.9259 - val_loss: 3.7374 - val_accuracy: 0.4725\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2146 - accuracy: 0.9315 - val_loss: 3.7086 - val_accuracy: 0.4725\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 42s 209ms/step - loss: 0.2148 - accuracy: 0.9340 - val_loss: 4.0259 - val_accuracy: 0.4425\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2265 - accuracy: 0.9326 - val_loss: 3.7794 - val_accuracy: 0.4712\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2247 - accuracy: 0.9265 - val_loss: 3.9799 - val_accuracy: 0.4688\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2274 - accuracy: 0.9290 - val_loss: 3.8198 - val_accuracy: 0.4475\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.1912 - accuracy: 0.9376 - val_loss: 3.8287 - val_accuracy: 0.4750\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2115 - accuracy: 0.9301 - val_loss: 4.0068 - val_accuracy: 0.4712\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2229 - accuracy: 0.9293 - val_loss: 4.0147 - val_accuracy: 0.4650\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.1930 - accuracy: 0.9390 - val_loss: 4.1024 - val_accuracy: 0.4663\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.1902 - accuracy: 0.9376 - val_loss: 4.0236 - val_accuracy: 0.4588\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.1766 - accuracy: 0.9411 - val_loss: 4.1838 - val_accuracy: 0.4688\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2029 - accuracy: 0.9334 - val_loss: 4.3498 - val_accuracy: 0.4638\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.2300 - accuracy: 0.9300 - val_loss: 3.9246 - val_accuracy: 0.4787\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.1885 - accuracy: 0.9431 - val_loss: 4.3678 - val_accuracy: 0.4462\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.1958 - accuracy: 0.9370 - val_loss: 4.2670 - val_accuracy: 0.4512\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.1977 - accuracy: 0.9365 - val_loss: 4.3695 - val_accuracy: 0.4350\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.1980 - accuracy: 0.9398 - val_loss: 4.3721 - val_accuracy: 0.4487\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.1712 - accuracy: 0.9447 - val_loss: 4.1433 - val_accuracy: 0.4600\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.1753 - accuracy: 0.9442 - val_loss: 4.0456 - val_accuracy: 0.4700\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.1749 - accuracy: 0.9470 - val_loss: 4.1546 - val_accuracy: 0.4850\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.1902 - accuracy: 0.9404 - val_loss: 4.1224 - val_accuracy: 0.4650\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.1983 - accuracy: 0.9379 - val_loss: 4.3322 - val_accuracy: 0.4525\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.1909 - accuracy: 0.9383 - val_loss: 4.6745 - val_accuracy: 0.4812\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.1733 - accuracy: 0.9429 - val_loss: 4.2897 - val_accuracy: 0.4762\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 41s 207ms/step - loss: 0.1978 - accuracy: 0.9408 - val_loss: 4.4358 - val_accuracy: 0.4613\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 0.1877 - accuracy: 0.9403 - val_loss: 4.4790 - val_accuracy: 0.4613\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 27)      270       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 27)      108       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 27)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 48, 351, 27)       0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 48, 351, 27)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 351, 54)       13176     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 351, 54)       216       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 48, 351, 54)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 87, 54)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 87, 54)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 87, 54)        26298     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 87, 54)        216       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 87, 54)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 17, 54)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 17, 54)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 7344)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 58760     \n",
            "=================================================================\n",
            "Total params: 99,428\n",
            "Trainable params: 98,966\n",
            "Non-trainable params: 462\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 9.6586 - accuracy: 0.2081INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 02.50.07/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 86s 432ms/step - loss: 9.6586 - accuracy: 0.2081 - val_loss: 4.2309 - val_accuracy: 0.1625\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 2.6640 - accuracy: 0.2726INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 02.50.07/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 85s 423ms/step - loss: 2.6640 - accuracy: 0.2726 - val_loss: 2.1517 - val_accuracy: 0.2575\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.9705 - accuracy: 0.3309INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 02.50.07/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 86s 430ms/step - loss: 1.9705 - accuracy: 0.3309 - val_loss: 1.7875 - val_accuracy: 0.3688\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 1.7078 - accuracy: 0.3921 - val_loss: 1.7451 - val_accuracy: 0.3400\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 1.6065 - accuracy: 0.4329 - val_loss: 1.7367 - val_accuracy: 0.3638\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.5356 - accuracy: 0.4572INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 02.50.07/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 85s 423ms/step - loss: 1.5356 - accuracy: 0.4572 - val_loss: 1.6032 - val_accuracy: 0.4350\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.4850 - accuracy: 0.4768INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 02.50.07/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 85s 423ms/step - loss: 1.4850 - accuracy: 0.4768 - val_loss: 1.5801 - val_accuracy: 0.4663\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 1.4480 - accuracy: 0.5020 - val_loss: 1.5906 - val_accuracy: 0.4275\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 1.4079 - accuracy: 0.5040 - val_loss: 1.6103 - val_accuracy: 0.4288\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 1.3677 - accuracy: 0.5281 - val_loss: 1.6604 - val_accuracy: 0.4200\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 1.3581 - accuracy: 0.5296 - val_loss: 1.6694 - val_accuracy: 0.4375\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3563 - accuracy: 0.5224INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 02.50.07/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 84s 422ms/step - loss: 1.3563 - accuracy: 0.5224 - val_loss: 1.6008 - val_accuracy: 0.4750\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 1.2885 - accuracy: 0.5568 - val_loss: 1.5745 - val_accuracy: 0.4525\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 1.2826 - accuracy: 0.5565 - val_loss: 1.6134 - val_accuracy: 0.4550\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 1.2596 - accuracy: 0.5620 - val_loss: 1.6575 - val_accuracy: 0.4675\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 1.2397 - accuracy: 0.5667 - val_loss: 1.6864 - val_accuracy: 0.4212\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.2101 - accuracy: 0.5820INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 02.50.07/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 84s 422ms/step - loss: 1.2101 - accuracy: 0.5820 - val_loss: 1.5435 - val_accuracy: 0.4913\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 1.1865 - accuracy: 0.5959 - val_loss: 1.6288 - val_accuracy: 0.4563\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 82s 408ms/step - loss: 1.1742 - accuracy: 0.5997 - val_loss: 1.6159 - val_accuracy: 0.4900\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 1.1390 - accuracy: 0.6101 - val_loss: 1.6361 - val_accuracy: 0.4338\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 1.1432 - accuracy: 0.6101 - val_loss: 1.6410 - val_accuracy: 0.4462\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 1.1085 - accuracy: 0.6129 - val_loss: 1.7767 - val_accuracy: 0.4325\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 1.0808 - accuracy: 0.6328 - val_loss: 1.6153 - val_accuracy: 0.4700\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 1.0763 - accuracy: 0.6300 - val_loss: 1.6968 - val_accuracy: 0.4712\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 1.0374 - accuracy: 0.6489 - val_loss: 1.7546 - val_accuracy: 0.4575\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 1.0081 - accuracy: 0.6541 - val_loss: 1.8670 - val_accuracy: 0.4437\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 1.0174 - accuracy: 0.6487 - val_loss: 1.7395 - val_accuracy: 0.4500\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 1.0156 - accuracy: 0.6509 - val_loss: 1.6962 - val_accuracy: 0.4550\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.9673 - accuracy: 0.6688 - val_loss: 1.8481 - val_accuracy: 0.4263\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 82s 408ms/step - loss: 0.9357 - accuracy: 0.6795 - val_loss: 1.7598 - val_accuracy: 0.4400\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.9376 - accuracy: 0.6788 - val_loss: 1.7453 - val_accuracy: 0.4588\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 82s 408ms/step - loss: 0.9083 - accuracy: 0.6903 - val_loss: 1.8648 - val_accuracy: 0.4563\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.9099 - accuracy: 0.6858 - val_loss: 1.8659 - val_accuracy: 0.4487\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.8527 - accuracy: 0.7060 - val_loss: 1.7809 - val_accuracy: 0.4850\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.8376 - accuracy: 0.7096INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 02.50.07/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 86s 429ms/step - loss: 0.8376 - accuracy: 0.7096 - val_loss: 1.7634 - val_accuracy: 0.5000\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.8486 - accuracy: 0.7055 - val_loss: 1.9019 - val_accuracy: 0.4450\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 82s 408ms/step - loss: 0.8439 - accuracy: 0.7114 - val_loss: 1.8394 - val_accuracy: 0.4875\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.8081 - accuracy: 0.7181 - val_loss: 1.9066 - val_accuracy: 0.4825\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 0.7506 - accuracy: 0.7443 - val_loss: 1.9907 - val_accuracy: 0.4850\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 0.7571 - accuracy: 0.7355 - val_loss: 1.9399 - val_accuracy: 0.4600\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.7813 - accuracy: 0.7360 - val_loss: 1.9273 - val_accuracy: 0.4700\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.7478 - accuracy: 0.7419 - val_loss: 2.1217 - val_accuracy: 0.4437\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.7561 - accuracy: 0.7502 - val_loss: 2.1755 - val_accuracy: 0.4375\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.7331 - accuracy: 0.7524 - val_loss: 2.1300 - val_accuracy: 0.4375\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.7161 - accuracy: 0.7538 - val_loss: 2.1539 - val_accuracy: 0.4538\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.7037 - accuracy: 0.7585 - val_loss: 2.1136 - val_accuracy: 0.4563\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.6733 - accuracy: 0.7740 - val_loss: 2.0012 - val_accuracy: 0.4588\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.6904 - accuracy: 0.7640 - val_loss: 2.1339 - val_accuracy: 0.4800\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.6544 - accuracy: 0.7744 - val_loss: 2.1946 - val_accuracy: 0.4812\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.6441 - accuracy: 0.7818 - val_loss: 2.4113 - val_accuracy: 0.4575\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 82s 408ms/step - loss: 0.6300 - accuracy: 0.7844 - val_loss: 2.1134 - val_accuracy: 0.4950\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.6228 - accuracy: 0.7877 - val_loss: 2.6056 - val_accuracy: 0.4462\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.6275 - accuracy: 0.7879 - val_loss: 2.3108 - val_accuracy: 0.4688\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.6178 - accuracy: 0.7968 - val_loss: 2.4630 - val_accuracy: 0.4375\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.5954 - accuracy: 0.8004 - val_loss: 2.3448 - val_accuracy: 0.4750\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.5923 - accuracy: 0.8013 - val_loss: 2.3858 - val_accuracy: 0.4675\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.5796 - accuracy: 0.8055 - val_loss: 2.3855 - val_accuracy: 0.4787\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 82s 408ms/step - loss: 0.6037 - accuracy: 0.8016 - val_loss: 2.5404 - val_accuracy: 0.4663\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.5884 - accuracy: 0.8046 - val_loss: 2.3098 - val_accuracy: 0.4712\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.5566 - accuracy: 0.8113 - val_loss: 2.6299 - val_accuracy: 0.4575\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.5473 - accuracy: 0.8184 - val_loss: 2.5821 - val_accuracy: 0.4762\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.5727 - accuracy: 0.8108 - val_loss: 2.4012 - val_accuracy: 0.4650\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.5523 - accuracy: 0.8226 - val_loss: 2.5665 - val_accuracy: 0.4700\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.5313 - accuracy: 0.8257 - val_loss: 2.5655 - val_accuracy: 0.4850\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.5289 - accuracy: 0.8262 - val_loss: 2.6842 - val_accuracy: 0.4812\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 0.5304 - accuracy: 0.8271 - val_loss: 2.5627 - val_accuracy: 0.4725\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.5112 - accuracy: 0.8360 - val_loss: 2.5140 - val_accuracy: 0.4650\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.5265 - accuracy: 0.8266 - val_loss: 2.5937 - val_accuracy: 0.4950\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.4872 - accuracy: 0.8401 - val_loss: 2.7238 - val_accuracy: 0.4712\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.4799 - accuracy: 0.8515 - val_loss: 2.8791 - val_accuracy: 0.4575\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.5051 - accuracy: 0.8387 - val_loss: 2.7960 - val_accuracy: 0.4512\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.4846 - accuracy: 0.8416 - val_loss: 2.6142 - val_accuracy: 0.4913\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.4796 - accuracy: 0.8460 - val_loss: 2.7307 - val_accuracy: 0.4775\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.5131 - accuracy: 0.8348 - val_loss: 2.9822 - val_accuracy: 0.4750\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.4735 - accuracy: 0.8546 - val_loss: 2.9364 - val_accuracy: 0.4762\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.4802 - accuracy: 0.8459 - val_loss: 2.8880 - val_accuracy: 0.4512\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.4878 - accuracy: 0.8484 - val_loss: 2.9119 - val_accuracy: 0.4750\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.4663 - accuracy: 0.8557INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 02.50.07/models_cnn_k2c2_4layer/assets\n",
            "200/200 [==============================] - 85s 423ms/step - loss: 0.4663 - accuracy: 0.8557 - val_loss: 2.7184 - val_accuracy: 0.5175\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 0.4397 - accuracy: 0.8554 - val_loss: 2.9483 - val_accuracy: 0.4400\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.4324 - accuracy: 0.8634 - val_loss: 2.9709 - val_accuracy: 0.4737\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.4816 - accuracy: 0.8501 - val_loss: 3.0169 - val_accuracy: 0.4500\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.4595 - accuracy: 0.8559 - val_loss: 3.0276 - val_accuracy: 0.4750\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.4619 - accuracy: 0.8595 - val_loss: 2.8185 - val_accuracy: 0.5025\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.4376 - accuracy: 0.8668 - val_loss: 3.1027 - val_accuracy: 0.4613\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.4457 - accuracy: 0.8606 - val_loss: 3.1272 - val_accuracy: 0.5150\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.4674 - accuracy: 0.8592 - val_loss: 3.1106 - val_accuracy: 0.4875\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 81s 407ms/step - loss: 0.4431 - accuracy: 0.8671 - val_loss: 3.1717 - val_accuracy: 0.4712\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 0.4460 - accuracy: 0.8652 - val_loss: 3.2415 - val_accuracy: 0.4550\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 0.4307 - accuracy: 0.8709 - val_loss: 3.0769 - val_accuracy: 0.4638\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 81s 405ms/step - loss: 0.4141 - accuracy: 0.8745 - val_loss: 3.2374 - val_accuracy: 0.5063\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 0.4558 - accuracy: 0.8690 - val_loss: 3.1836 - val_accuracy: 0.4800\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 0.4593 - accuracy: 0.8671 - val_loss: 3.2521 - val_accuracy: 0.4538\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 81s 405ms/step - loss: 0.4184 - accuracy: 0.8681 - val_loss: 3.3263 - val_accuracy: 0.4675\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 0.4294 - accuracy: 0.8709 - val_loss: 3.3536 - val_accuracy: 0.4737\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 81s 405ms/step - loss: 0.4398 - accuracy: 0.8682 - val_loss: 3.2984 - val_accuracy: 0.4812\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 81s 405ms/step - loss: 0.4424 - accuracy: 0.8696 - val_loss: 3.2942 - val_accuracy: 0.4700\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 81s 405ms/step - loss: 0.4132 - accuracy: 0.8757 - val_loss: 3.2606 - val_accuracy: 0.5013\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 81s 406ms/step - loss: 0.4359 - accuracy: 0.8717 - val_loss: 3.2225 - val_accuracy: 0.4762\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 81s 405ms/step - loss: 0.3951 - accuracy: 0.8767 - val_loss: 3.6296 - val_accuracy: 0.4613\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 81s 405ms/step - loss: 0.4251 - accuracy: 0.8774 - val_loss: 3.6042 - val_accuracy: 0.4938\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 51)      510       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 51)      204       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 51)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 48, 351, 51)       0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 48, 351, 51)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 351, 101)      46460     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 351, 101)      404       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 48, 351, 101)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 87, 101)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 87, 101)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 87, 101)       91910     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 87, 101)       404       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 87, 101)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 17, 101)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 17, 101)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 13736)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 109896    \n",
            "=================================================================\n",
            "Total params: 250,172\n",
            "Trainable params: 249,474\n",
            "Non-trainable params: 698\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ki0vw_MxaM65",
        "colab_type": "text"
      },
      "source": [
        "## Train 2-level fully convolutional neural networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7SjugM0aULZ",
        "colab_type": "code",
        "outputId": "210326f4-fe2c-4efe-835a-a726e9ddfa8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Experiment 8\n",
        "# Deep k2c2\n",
        "\n",
        "params = {17000:[1, 1],\n",
        "    50000:[2, 3],\n",
        "          100000: [3, 6],\n",
        "                    250000: [8, 15]}\n",
        "\n",
        "num = 10000\n",
        "dropouts = [0.1, 0.2, 0.2, 0.4]\n",
        "\n",
        "for i, num in enumerate([17000, 50000, 100000, 250000]):\n",
        "\n",
        "  hyperparams = {\"number_filters\" : params[num],\n",
        "                \"number_params\" : num,\n",
        "                \"kernel_size\" : [(3, 3), (3,3)],\n",
        "                \"pooling_size\" : [(2,4), (2,4)],\n",
        "                \"hidden_layers\": [],\n",
        "                \"epsilon\": 0.01, \n",
        "                \"learning_rate\": 0.01, \n",
        "                \"batch_size\": 32, \n",
        "                \"epochs\": 100,\n",
        "                \"dropout\" : dropouts[i],\n",
        "                \"drop_out_hidden\" : 0\n",
        "                }\n",
        "\n",
        "\n",
        "  model_string = \"cnn_k2c2_2layer\"\n",
        "  model = cnn_k1c2_model(hyperparams)\n",
        "\n",
        "\n",
        "  history = run_experiment(model, model_string, hyperparams)\n",
        "  model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "199/200 [============================>.] - ETA: 0s - loss: 2.4902 - accuracy: 0.2676INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 05.14.59/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 14s 69ms/step - loss: 2.4879 - accuracy: 0.2679 - val_loss: 1.8593 - val_accuracy: 0.2975\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.7423 - accuracy: 0.3728INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 05.14.59/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 14s 68ms/step - loss: 1.7423 - accuracy: 0.3728 - val_loss: 1.8427 - val_accuracy: 0.3000\n",
            "Epoch 3/100\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.6943 - accuracy: 0.3927INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 05.14.59/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 1.6945 - accuracy: 0.3928 - val_loss: 1.8692 - val_accuracy: 0.3212\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.6718 - accuracy: 0.4030 - val_loss: 1.7767 - val_accuracy: 0.3175\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.6114 - accuracy: 0.4310INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 05.14.59/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 14s 68ms/step - loss: 1.6114 - accuracy: 0.4310 - val_loss: 1.8275 - val_accuracy: 0.3400\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.5596 - accuracy: 0.4505 - val_loss: 1.7629 - val_accuracy: 0.3237\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.5166 - accuracy: 0.4662 - val_loss: 1.7760 - val_accuracy: 0.3313\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 1.4724 - accuracy: 0.4783 - val_loss: 1.7610 - val_accuracy: 0.3237\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.4295 - accuracy: 0.4946 - val_loss: 1.7599 - val_accuracy: 0.3250\n",
            "Epoch 10/100\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.3814 - accuracy: 0.5163INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 05.14.59/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 14s 68ms/step - loss: 1.3813 - accuracy: 0.5162 - val_loss: 1.7810 - val_accuracy: 0.3450\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.3290 - accuracy: 0.5385 - val_loss: 1.9174 - val_accuracy: 0.3250\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2879 - accuracy: 0.5556 - val_loss: 1.9004 - val_accuracy: 0.3200\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2554 - accuracy: 0.5582 - val_loss: 1.8494 - val_accuracy: 0.3450\n",
            "Epoch 14/100\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.2367 - accuracy: 0.5638INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 05.14.59/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 14s 68ms/step - loss: 1.2362 - accuracy: 0.5643 - val_loss: 1.8195 - val_accuracy: 0.3587\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2056 - accuracy: 0.5770 - val_loss: 1.9073 - val_accuracy: 0.3425\n",
            "Epoch 16/100\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.1826 - accuracy: 0.5850INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 05.14.59/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 14s 68ms/step - loss: 1.1829 - accuracy: 0.5850 - val_loss: 1.9694 - val_accuracy: 0.3600\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.1717 - accuracy: 0.5929 - val_loss: 2.0396 - val_accuracy: 0.3500\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.1585 - accuracy: 0.5873 - val_loss: 1.9850 - val_accuracy: 0.3413\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.1248 - accuracy: 0.6050 - val_loss: 1.9572 - val_accuracy: 0.3425\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.1297 - accuracy: 0.5997 - val_loss: 1.9874 - val_accuracy: 0.3288\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 1.1094 - accuracy: 0.6158 - val_loss: 2.0782 - val_accuracy: 0.3462\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.0888 - accuracy: 0.6095 - val_loss: 2.0329 - val_accuracy: 0.3237\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 1.0765 - accuracy: 0.6156 - val_loss: 2.0736 - val_accuracy: 0.3438\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.0786 - accuracy: 0.6200 - val_loss: 2.0967 - val_accuracy: 0.3500\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.0632 - accuracy: 0.6220 - val_loss: 2.1872 - val_accuracy: 0.3050\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.0626 - accuracy: 0.6219 - val_loss: 2.0575 - val_accuracy: 0.3237\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.0431 - accuracy: 0.6353 - val_loss: 1.9936 - val_accuracy: 0.3450\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 1.0293 - accuracy: 0.6258 - val_loss: 2.1132 - val_accuracy: 0.3175\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.0371 - accuracy: 0.6309 - val_loss: 2.1213 - val_accuracy: 0.3388\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.0228 - accuracy: 0.6370 - val_loss: 2.1814 - val_accuracy: 0.3275\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.0282 - accuracy: 0.6342 - val_loss: 2.2030 - val_accuracy: 0.3063\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.0231 - accuracy: 0.6447 - val_loss: 2.1870 - val_accuracy: 0.3537\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.0123 - accuracy: 0.6434 - val_loss: 2.2171 - val_accuracy: 0.3375\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9851 - accuracy: 0.6486 - val_loss: 2.1492 - val_accuracy: 0.3500\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9884 - accuracy: 0.6533 - val_loss: 2.1594 - val_accuracy: 0.3462\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9943 - accuracy: 0.6475 - val_loss: 2.1399 - val_accuracy: 0.3275\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9954 - accuracy: 0.6469 - val_loss: 2.1348 - val_accuracy: 0.3300\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9724 - accuracy: 0.6587 - val_loss: 2.2183 - val_accuracy: 0.3212\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9737 - accuracy: 0.6523 - val_loss: 2.2311 - val_accuracy: 0.3187\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9716 - accuracy: 0.6544 - val_loss: 2.2470 - val_accuracy: 0.3325\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9549 - accuracy: 0.6577 - val_loss: 2.2310 - val_accuracy: 0.3088\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9577 - accuracy: 0.6614 - val_loss: 2.2518 - val_accuracy: 0.3262\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9707 - accuracy: 0.6634 - val_loss: 2.2156 - val_accuracy: 0.3338\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9549 - accuracy: 0.6603 - val_loss: 2.2777 - val_accuracy: 0.3288\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9716 - accuracy: 0.6498 - val_loss: 2.2331 - val_accuracy: 0.3100\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9432 - accuracy: 0.6598 - val_loss: 2.2751 - val_accuracy: 0.3525\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9443 - accuracy: 0.6642 - val_loss: 2.2232 - val_accuracy: 0.3288\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9402 - accuracy: 0.6650 - val_loss: 2.2321 - val_accuracy: 0.3237\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9357 - accuracy: 0.6670 - val_loss: 2.3015 - val_accuracy: 0.3275\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 0.9378 - accuracy: 0.6616 - val_loss: 2.2520 - val_accuracy: 0.3375\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9497 - accuracy: 0.6639 - val_loss: 2.2033 - val_accuracy: 0.3288\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 0.9233 - accuracy: 0.6761 - val_loss: 2.3753 - val_accuracy: 0.3200\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9482 - accuracy: 0.6542 - val_loss: 2.2373 - val_accuracy: 0.3363\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9275 - accuracy: 0.6728 - val_loss: 2.2940 - val_accuracy: 0.3063\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 0.9327 - accuracy: 0.6734 - val_loss: 2.1954 - val_accuracy: 0.3212\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 0.9154 - accuracy: 0.6824 - val_loss: 2.3342 - val_accuracy: 0.3338\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9197 - accuracy: 0.6748 - val_loss: 2.3373 - val_accuracy: 0.3450\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9271 - accuracy: 0.6738 - val_loss: 2.2301 - val_accuracy: 0.3162\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9289 - accuracy: 0.6734 - val_loss: 2.2518 - val_accuracy: 0.3262\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9180 - accuracy: 0.6705 - val_loss: 2.3102 - val_accuracy: 0.3187\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8956 - accuracy: 0.6803 - val_loss: 2.3231 - val_accuracy: 0.3325\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8985 - accuracy: 0.6811 - val_loss: 2.3442 - val_accuracy: 0.3413\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9124 - accuracy: 0.6705 - val_loss: 2.3913 - val_accuracy: 0.3325\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 0.9034 - accuracy: 0.6803 - val_loss: 2.2464 - val_accuracy: 0.3512\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9190 - accuracy: 0.6702 - val_loss: 2.2948 - val_accuracy: 0.3125\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9122 - accuracy: 0.6705 - val_loss: 2.3484 - val_accuracy: 0.3250\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8940 - accuracy: 0.6784 - val_loss: 2.2411 - val_accuracy: 0.3187\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8917 - accuracy: 0.6866 - val_loss: 2.2559 - val_accuracy: 0.3325\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.9062 - accuracy: 0.6763 - val_loss: 2.3340 - val_accuracy: 0.3325\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8866 - accuracy: 0.6797 - val_loss: 2.2946 - val_accuracy: 0.3250\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8810 - accuracy: 0.6808 - val_loss: 2.4128 - val_accuracy: 0.3475\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8667 - accuracy: 0.6966 - val_loss: 2.3477 - val_accuracy: 0.3400\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 0.8938 - accuracy: 0.6788 - val_loss: 2.3268 - val_accuracy: 0.3338\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8723 - accuracy: 0.6892 - val_loss: 2.3812 - val_accuracy: 0.3100\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8954 - accuracy: 0.6789 - val_loss: 2.3278 - val_accuracy: 0.3338\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8884 - accuracy: 0.6769 - val_loss: 2.4268 - val_accuracy: 0.3438\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 0.8786 - accuracy: 0.6891 - val_loss: 2.4279 - val_accuracy: 0.3375\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 0.8638 - accuracy: 0.6936 - val_loss: 2.4326 - val_accuracy: 0.3338\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8665 - accuracy: 0.6928 - val_loss: 2.4472 - val_accuracy: 0.3338\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8737 - accuracy: 0.6922 - val_loss: 2.3287 - val_accuracy: 0.3450\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8678 - accuracy: 0.6949 - val_loss: 2.3720 - val_accuracy: 0.3313\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 0.8676 - accuracy: 0.6905 - val_loss: 2.3549 - val_accuracy: 0.3200\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8922 - accuracy: 0.6819 - val_loss: 2.3751 - val_accuracy: 0.3400\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8732 - accuracy: 0.6917 - val_loss: 2.3211 - val_accuracy: 0.3363\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8572 - accuracy: 0.6914 - val_loss: 2.4060 - val_accuracy: 0.3438\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8704 - accuracy: 0.6927 - val_loss: 2.4253 - val_accuracy: 0.3187\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8528 - accuracy: 0.6974 - val_loss: 2.2935 - val_accuracy: 0.3438\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 0.8465 - accuracy: 0.6981 - val_loss: 2.4945 - val_accuracy: 0.3413\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8650 - accuracy: 0.6914 - val_loss: 2.3815 - val_accuracy: 0.3125\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8793 - accuracy: 0.6813 - val_loss: 2.2799 - val_accuracy: 0.3313\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8643 - accuracy: 0.6867 - val_loss: 2.3762 - val_accuracy: 0.3125\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8694 - accuracy: 0.6902 - val_loss: 2.3835 - val_accuracy: 0.3075\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8594 - accuracy: 0.6958 - val_loss: 2.3190 - val_accuracy: 0.3187\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8620 - accuracy: 0.6895 - val_loss: 2.4809 - val_accuracy: 0.3375\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8557 - accuracy: 0.6884 - val_loss: 2.3934 - val_accuracy: 0.3300\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8597 - accuracy: 0.6895 - val_loss: 2.3996 - val_accuracy: 0.3250\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8517 - accuracy: 0.6935 - val_loss: 2.2912 - val_accuracy: 0.3350\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8609 - accuracy: 0.6906 - val_loss: 2.3596 - val_accuracy: 0.3262\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8464 - accuracy: 0.6936 - val_loss: 2.4163 - val_accuracy: 0.3262\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.8514 - accuracy: 0.6938 - val_loss: 2.3491 - val_accuracy: 0.3450\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_54 (Batc (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 96, 1405, 1)       10        \n",
            "_________________________________________________________________\n",
            "batch_normalization_55 (Batc (None, 96, 1405, 1)       4         \n",
            "_________________________________________________________________\n",
            "activation_36 (Activation)   (None, 96, 1405, 1)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_36 (MaxPooling (None, 48, 351, 1)        0         \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 48, 351, 1)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 48, 351, 1)        10        \n",
            "_________________________________________________________________\n",
            "batch_normalization_56 (Batc (None, 48, 351, 1)        4         \n",
            "_________________________________________________________________\n",
            "activation_37 (Activation)   (None, 48, 351, 1)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 24, 87, 1)         0         \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 24, 87, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 2088)              0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 8)                 16712     \n",
            "=================================================================\n",
            "Total params: 17,124\n",
            "Trainable params: 16,928\n",
            "Non-trainable params: 196\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 3.6297 - accuracy: 0.2728INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 05.34.11/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 3.6297 - accuracy: 0.2728 - val_loss: 2.7905 - val_accuracy: 0.2325\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.6822 - accuracy: 0.4046INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 05.34.11/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 1.6822 - accuracy: 0.4046 - val_loss: 1.7752 - val_accuracy: 0.3300\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.5046 - accuracy: 0.4710INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 05.34.11/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 1.5046 - accuracy: 0.4710 - val_loss: 1.8316 - val_accuracy: 0.3613\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 1.3711 - accuracy: 0.5223 - val_loss: 1.8613 - val_accuracy: 0.3438\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.2745 - accuracy: 0.5564INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 05.34.11/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 14s 71ms/step - loss: 1.2745 - accuracy: 0.5564 - val_loss: 1.8534 - val_accuracy: 0.3812\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 1.2028 - accuracy: 0.5873 - val_loss: 1.8853 - val_accuracy: 0.3475\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 1.1160 - accuracy: 0.6117 - val_loss: 2.1611 - val_accuracy: 0.3325\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 1.0291 - accuracy: 0.6447 - val_loss: 2.2404 - val_accuracy: 0.3237\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.9728 - accuracy: 0.6664 - val_loss: 2.1538 - val_accuracy: 0.3688\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.9524 - accuracy: 0.6702 - val_loss: 2.1289 - val_accuracy: 0.3500\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.8893 - accuracy: 0.6942 - val_loss: 2.2151 - val_accuracy: 0.3200\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.8655 - accuracy: 0.6978 - val_loss: 2.4050 - val_accuracy: 0.3562\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.8417 - accuracy: 0.7024 - val_loss: 2.3559 - val_accuracy: 0.3800\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.7990 - accuracy: 0.7186 - val_loss: 2.7541 - val_accuracy: 0.3438\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.7591 - accuracy: 0.7352 - val_loss: 2.5729 - val_accuracy: 0.3162\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.7682 - accuracy: 0.7307 - val_loss: 2.6914 - val_accuracy: 0.3375\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.7328 - accuracy: 0.7350 - val_loss: 2.6614 - val_accuracy: 0.3038\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.7073 - accuracy: 0.7539 - val_loss: 2.8443 - val_accuracy: 0.3300\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.7004 - accuracy: 0.7582 - val_loss: 2.9130 - val_accuracy: 0.3288\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.6666 - accuracy: 0.7619 - val_loss: 2.6927 - val_accuracy: 0.3713\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.6811 - accuracy: 0.7622 - val_loss: 2.7392 - val_accuracy: 0.3587\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.6406 - accuracy: 0.7716 - val_loss: 2.7496 - val_accuracy: 0.3425\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.6430 - accuracy: 0.7752 - val_loss: 2.9883 - val_accuracy: 0.3175\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.6257 - accuracy: 0.7851 - val_loss: 2.6347 - val_accuracy: 0.3500\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.6310 - accuracy: 0.7774 - val_loss: 2.7864 - val_accuracy: 0.3388\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.5922 - accuracy: 0.7890 - val_loss: 2.8531 - val_accuracy: 0.3425\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.6011 - accuracy: 0.7887 - val_loss: 2.8294 - val_accuracy: 0.3512\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.5751 - accuracy: 0.7966 - val_loss: 2.9767 - val_accuracy: 0.3338\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.6050 - accuracy: 0.7854 - val_loss: 2.9007 - val_accuracy: 0.3438\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.5914 - accuracy: 0.7924 - val_loss: 2.8723 - val_accuracy: 0.3450\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.5696 - accuracy: 0.7988 - val_loss: 2.7892 - val_accuracy: 0.3313\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.5700 - accuracy: 0.8004 - val_loss: 2.9777 - val_accuracy: 0.3388\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.5595 - accuracy: 0.8024 - val_loss: 3.0453 - val_accuracy: 0.3525\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.5526 - accuracy: 0.8048 - val_loss: 3.0491 - val_accuracy: 0.3650\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.5346 - accuracy: 0.8173 - val_loss: 2.9598 - val_accuracy: 0.3438\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.5377 - accuracy: 0.8127 - val_loss: 2.8572 - val_accuracy: 0.3562\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.5417 - accuracy: 0.8121 - val_loss: 2.8486 - val_accuracy: 0.3137\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.5360 - accuracy: 0.8073 - val_loss: 3.0050 - val_accuracy: 0.3212\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.5507 - accuracy: 0.8027 - val_loss: 3.1615 - val_accuracy: 0.3375\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.5111 - accuracy: 0.8188 - val_loss: 3.1280 - val_accuracy: 0.3462\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.5144 - accuracy: 0.8196 - val_loss: 3.0796 - val_accuracy: 0.3300\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4934 - accuracy: 0.8268 - val_loss: 2.9504 - val_accuracy: 0.3525\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4924 - accuracy: 0.8276 - val_loss: 3.0328 - val_accuracy: 0.3562\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.5039 - accuracy: 0.8221 - val_loss: 3.2483 - val_accuracy: 0.3475\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.5055 - accuracy: 0.8248 - val_loss: 3.2451 - val_accuracy: 0.3487\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.5021 - accuracy: 0.8209 - val_loss: 3.1480 - val_accuracy: 0.3300\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.5061 - accuracy: 0.8248 - val_loss: 3.2010 - val_accuracy: 0.3175\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4975 - accuracy: 0.8246 - val_loss: 3.1007 - val_accuracy: 0.3200\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4760 - accuracy: 0.8388 - val_loss: 2.9676 - val_accuracy: 0.3237\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4890 - accuracy: 0.8274 - val_loss: 3.0641 - val_accuracy: 0.3150\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.4743 - accuracy: 0.8401 - val_loss: 3.2518 - val_accuracy: 0.3300\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4690 - accuracy: 0.8391 - val_loss: 3.1694 - val_accuracy: 0.3388\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4748 - accuracy: 0.8371 - val_loss: 3.2761 - val_accuracy: 0.3075\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4715 - accuracy: 0.8421 - val_loss: 3.4629 - val_accuracy: 0.3000\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4826 - accuracy: 0.8320 - val_loss: 3.1176 - val_accuracy: 0.3438\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 0.4679 - accuracy: 0.8363 - val_loss: 3.2710 - val_accuracy: 0.3212\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4513 - accuracy: 0.8499 - val_loss: 3.3557 - val_accuracy: 0.3475\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4548 - accuracy: 0.8373 - val_loss: 3.2895 - val_accuracy: 0.3225\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4456 - accuracy: 0.8387 - val_loss: 3.3501 - val_accuracy: 0.3212\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4649 - accuracy: 0.8366 - val_loss: 3.4858 - val_accuracy: 0.3088\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4511 - accuracy: 0.8415 - val_loss: 3.4446 - val_accuracy: 0.3300\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4539 - accuracy: 0.8424 - val_loss: 3.3127 - val_accuracy: 0.3425\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4430 - accuracy: 0.8487 - val_loss: 3.4856 - val_accuracy: 0.3125\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4576 - accuracy: 0.8391 - val_loss: 3.2794 - val_accuracy: 0.3200\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4231 - accuracy: 0.8509 - val_loss: 3.5046 - val_accuracy: 0.3075\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4437 - accuracy: 0.8470 - val_loss: 3.3782 - val_accuracy: 0.3400\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4324 - accuracy: 0.8521 - val_loss: 3.2472 - val_accuracy: 0.3275\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4510 - accuracy: 0.8393 - val_loss: 3.2638 - val_accuracy: 0.3425\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4632 - accuracy: 0.8376 - val_loss: 3.1718 - val_accuracy: 0.3375\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4536 - accuracy: 0.8410 - val_loss: 3.2303 - val_accuracy: 0.3425\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4413 - accuracy: 0.8484 - val_loss: 3.1592 - val_accuracy: 0.3462\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4626 - accuracy: 0.8348 - val_loss: 3.1919 - val_accuracy: 0.3113\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4470 - accuracy: 0.8418 - val_loss: 3.1968 - val_accuracy: 0.3350\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4283 - accuracy: 0.8498 - val_loss: 3.2690 - val_accuracy: 0.3587\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4160 - accuracy: 0.8502 - val_loss: 3.2559 - val_accuracy: 0.3438\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4162 - accuracy: 0.8501 - val_loss: 3.2867 - val_accuracy: 0.3475\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4178 - accuracy: 0.8523 - val_loss: 3.3950 - val_accuracy: 0.3038\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4275 - accuracy: 0.8531 - val_loss: 3.3494 - val_accuracy: 0.3537\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4145 - accuracy: 0.8542 - val_loss: 3.3211 - val_accuracy: 0.3250\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4164 - accuracy: 0.8521 - val_loss: 3.4085 - val_accuracy: 0.3325\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4216 - accuracy: 0.8551 - val_loss: 3.3428 - val_accuracy: 0.3475\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4298 - accuracy: 0.8518 - val_loss: 3.1938 - val_accuracy: 0.3237\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4270 - accuracy: 0.8501 - val_loss: 3.1843 - val_accuracy: 0.3350\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.3855 - accuracy: 0.8674 - val_loss: 3.5273 - val_accuracy: 0.3250\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4033 - accuracy: 0.8593 - val_loss: 3.2993 - val_accuracy: 0.3487\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4099 - accuracy: 0.8587 - val_loss: 3.4544 - val_accuracy: 0.3400\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4006 - accuracy: 0.8546 - val_loss: 3.3885 - val_accuracy: 0.3413\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4241 - accuracy: 0.8556 - val_loss: 3.3352 - val_accuracy: 0.3013\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.3942 - accuracy: 0.8610 - val_loss: 3.4493 - val_accuracy: 0.3325\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.3982 - accuracy: 0.8590 - val_loss: 3.3386 - val_accuracy: 0.3225\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.3856 - accuracy: 0.8656 - val_loss: 3.5048 - val_accuracy: 0.3025\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4091 - accuracy: 0.8585 - val_loss: 3.5174 - val_accuracy: 0.3200\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.3958 - accuracy: 0.8593 - val_loss: 3.4970 - val_accuracy: 0.3363\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.3699 - accuracy: 0.8721 - val_loss: 3.5439 - val_accuracy: 0.3325\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4135 - accuracy: 0.8556 - val_loss: 3.5400 - val_accuracy: 0.3425\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.3862 - accuracy: 0.8643 - val_loss: 3.4903 - val_accuracy: 0.3300\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.3827 - accuracy: 0.8663 - val_loss: 3.6946 - val_accuracy: 0.3212\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.3937 - accuracy: 0.8627 - val_loss: 3.5545 - val_accuracy: 0.3350\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.3722 - accuracy: 0.8652 - val_loss: 3.3721 - val_accuracy: 0.3388\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 0.4157 - accuracy: 0.8604 - val_loss: 3.5126 - val_accuracy: 0.3288\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 2)       20        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 2)       8         \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 2)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 48, 351, 2)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 48, 351, 2)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 351, 3)        57        \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 351, 3)        12        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 48, 351, 3)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 87, 3)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 87, 3)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6264)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 50120     \n",
            "=================================================================\n",
            "Total params: 50,601\n",
            "Trainable params: 50,399\n",
            "Non-trainable params: 202\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 9.0490 - accuracy: 0.2375INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 05.54.46/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 9.0490 - accuracy: 0.2375 - val_loss: 4.4058 - val_accuracy: 0.3162\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 2.2649 - accuracy: 0.3255 - val_loss: 2.2789 - val_accuracy: 0.2925\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.7475 - accuracy: 0.3958INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 05.54.46/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.7475 - accuracy: 0.3958 - val_loss: 1.8111 - val_accuracy: 0.3663\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 1.5923 - accuracy: 0.4413 - val_loss: 1.8897 - val_accuracy: 0.3100\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 1.5500 - accuracy: 0.4576 - val_loss: 1.8229 - val_accuracy: 0.3587\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 1.4738 - accuracy: 0.4937 - val_loss: 1.8157 - val_accuracy: 0.3525\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3575 - accuracy: 0.5304INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 05.54.46/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 16s 79ms/step - loss: 1.3575 - accuracy: 0.5304 - val_loss: 1.6815 - val_accuracy: 0.4125\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 1.2438 - accuracy: 0.5704 - val_loss: 1.7548 - val_accuracy: 0.4038\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.1331 - accuracy: 0.6109INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 05.54.46/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 1.1331 - accuracy: 0.6109 - val_loss: 1.8138 - val_accuracy: 0.4200\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 1.0131 - accuracy: 0.6609 - val_loss: 2.0337 - val_accuracy: 0.3688\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.9018 - accuracy: 0.6916 - val_loss: 2.1185 - val_accuracy: 0.3525\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.8289 - accuracy: 0.7155 - val_loss: 2.2843 - val_accuracy: 0.3688\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.7591 - accuracy: 0.7403 - val_loss: 2.4126 - val_accuracy: 0.3762\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.6962 - accuracy: 0.7563 - val_loss: 2.4878 - val_accuracy: 0.3887\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.6302 - accuracy: 0.7811 - val_loss: 2.4788 - val_accuracy: 0.4087\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.6023 - accuracy: 0.7805 - val_loss: 2.6631 - val_accuracy: 0.3862\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.5808 - accuracy: 0.7954 - val_loss: 2.5247 - val_accuracy: 0.3725\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.5263 - accuracy: 0.8163 - val_loss: 2.7652 - val_accuracy: 0.3837\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.5004 - accuracy: 0.8252 - val_loss: 3.0054 - val_accuracy: 0.3713\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.4881 - accuracy: 0.8349 - val_loss: 2.9499 - val_accuracy: 0.3750\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.4627 - accuracy: 0.8355INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 05.54.46/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 15s 77ms/step - loss: 0.4627 - accuracy: 0.8355 - val_loss: 2.9388 - val_accuracy: 0.4375\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.4271 - accuracy: 0.8498 - val_loss: 3.0772 - val_accuracy: 0.3938\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.4119 - accuracy: 0.8573 - val_loss: 3.1177 - val_accuracy: 0.4137\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.3810 - accuracy: 0.8698 - val_loss: 3.1481 - val_accuracy: 0.4162\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.3789 - accuracy: 0.8688 - val_loss: 3.1306 - val_accuracy: 0.3975\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.3546 - accuracy: 0.8754 - val_loss: 3.5658 - val_accuracy: 0.3975\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.3165 - accuracy: 0.8889 - val_loss: 3.5293 - val_accuracy: 0.4050\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.3096 - accuracy: 0.8953 - val_loss: 3.6412 - val_accuracy: 0.3613\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.2977 - accuracy: 0.8948 - val_loss: 3.9060 - val_accuracy: 0.3825\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.3100 - accuracy: 0.8923 - val_loss: 3.5973 - val_accuracy: 0.3688\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.2838 - accuracy: 0.9076 - val_loss: 3.2750 - val_accuracy: 0.3837\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.2853 - accuracy: 0.9042 - val_loss: 3.3935 - val_accuracy: 0.3925\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.2621 - accuracy: 0.9112 - val_loss: 3.6308 - val_accuracy: 0.3900\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.2571 - accuracy: 0.9090 - val_loss: 3.9010 - val_accuracy: 0.3925\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.2864 - accuracy: 0.9048 - val_loss: 3.7292 - val_accuracy: 0.3613\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.2483 - accuracy: 0.9129 - val_loss: 3.6657 - val_accuracy: 0.3862\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.2354 - accuracy: 0.9207 - val_loss: 3.8776 - val_accuracy: 0.3650\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.2341 - accuracy: 0.9218 - val_loss: 3.9832 - val_accuracy: 0.3950\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.2370 - accuracy: 0.9196 - val_loss: 3.8644 - val_accuracy: 0.3988\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.2139 - accuracy: 0.9290 - val_loss: 4.0272 - val_accuracy: 0.3750\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.2236 - accuracy: 0.9250 - val_loss: 3.8827 - val_accuracy: 0.3887\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.2265 - accuracy: 0.9217 - val_loss: 3.8767 - val_accuracy: 0.3925\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.2190 - accuracy: 0.9234 - val_loss: 4.1099 - val_accuracy: 0.3963\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.2162 - accuracy: 0.9250 - val_loss: 4.2882 - val_accuracy: 0.3725\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.2127 - accuracy: 0.9275 - val_loss: 4.0173 - val_accuracy: 0.3725\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.2132 - accuracy: 0.9312 - val_loss: 3.9360 - val_accuracy: 0.3913\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1914 - accuracy: 0.9340 - val_loss: 3.9200 - val_accuracy: 0.3913\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1735 - accuracy: 0.9387 - val_loss: 4.3846 - val_accuracy: 0.4013\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1895 - accuracy: 0.9334 - val_loss: 4.3169 - val_accuracy: 0.3663\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1806 - accuracy: 0.9361 - val_loss: 4.4489 - val_accuracy: 0.3688\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1994 - accuracy: 0.9312 - val_loss: 4.2043 - val_accuracy: 0.3938\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1890 - accuracy: 0.9354 - val_loss: 4.1767 - val_accuracy: 0.4000\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1741 - accuracy: 0.9359 - val_loss: 4.2892 - val_accuracy: 0.4000\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1738 - accuracy: 0.9425 - val_loss: 4.2242 - val_accuracy: 0.4038\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1673 - accuracy: 0.9450 - val_loss: 3.9728 - val_accuracy: 0.3975\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1693 - accuracy: 0.9403 - val_loss: 4.1858 - val_accuracy: 0.3775\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1774 - accuracy: 0.9418 - val_loss: 3.9894 - val_accuracy: 0.4025\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1729 - accuracy: 0.9414 - val_loss: 4.3119 - val_accuracy: 0.4000\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1599 - accuracy: 0.9439 - val_loss: 4.4956 - val_accuracy: 0.3738\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1576 - accuracy: 0.9459 - val_loss: 4.3740 - val_accuracy: 0.3775\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.1492 - accuracy: 0.9495 - val_loss: 4.2342 - val_accuracy: 0.3988\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1760 - accuracy: 0.9398 - val_loss: 4.4613 - val_accuracy: 0.3825\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.1931 - accuracy: 0.9356 - val_loss: 4.7856 - val_accuracy: 0.3975\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1509 - accuracy: 0.9486 - val_loss: 4.4429 - val_accuracy: 0.4038\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1524 - accuracy: 0.9500 - val_loss: 4.5560 - val_accuracy: 0.3913\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1702 - accuracy: 0.9425 - val_loss: 4.6886 - val_accuracy: 0.3787\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1530 - accuracy: 0.9503 - val_loss: 4.7270 - val_accuracy: 0.3537\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1563 - accuracy: 0.9500 - val_loss: 4.7099 - val_accuracy: 0.3688\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.1357 - accuracy: 0.9542 - val_loss: 4.7856 - val_accuracy: 0.3638\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1418 - accuracy: 0.9529 - val_loss: 4.4796 - val_accuracy: 0.4000\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1457 - accuracy: 0.9536 - val_loss: 4.7244 - val_accuracy: 0.3812\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1503 - accuracy: 0.9528 - val_loss: 4.8933 - val_accuracy: 0.3738\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1630 - accuracy: 0.9476 - val_loss: 4.5757 - val_accuracy: 0.3625\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1344 - accuracy: 0.9553 - val_loss: 4.7225 - val_accuracy: 0.3913\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1450 - accuracy: 0.9540 - val_loss: 4.4923 - val_accuracy: 0.3762\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.1380 - accuracy: 0.9539 - val_loss: 4.5690 - val_accuracy: 0.3762\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1435 - accuracy: 0.9519 - val_loss: 4.6939 - val_accuracy: 0.3950\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.1440 - accuracy: 0.9489 - val_loss: 4.6317 - val_accuracy: 0.3938\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.1291 - accuracy: 0.9575 - val_loss: 4.4688 - val_accuracy: 0.4062\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1282 - accuracy: 0.9583 - val_loss: 4.3757 - val_accuracy: 0.3887\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1411 - accuracy: 0.9522 - val_loss: 4.7210 - val_accuracy: 0.3925\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1160 - accuracy: 0.9628 - val_loss: 4.8971 - val_accuracy: 0.3725\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1408 - accuracy: 0.9558 - val_loss: 4.6275 - val_accuracy: 0.3812\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.1288 - accuracy: 0.9592 - val_loss: 4.8201 - val_accuracy: 0.3762\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1282 - accuracy: 0.9567 - val_loss: 5.0259 - val_accuracy: 0.3800\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1290 - accuracy: 0.9559 - val_loss: 4.8614 - val_accuracy: 0.3775\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1103 - accuracy: 0.9642 - val_loss: 4.6719 - val_accuracy: 0.3925\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1420 - accuracy: 0.9533 - val_loss: 4.8420 - val_accuracy: 0.3650\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1516 - accuracy: 0.9517 - val_loss: 4.5002 - val_accuracy: 0.3812\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.1257 - accuracy: 0.9595 - val_loss: 5.0174 - val_accuracy: 0.3762\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1425 - accuracy: 0.9551 - val_loss: 4.9762 - val_accuracy: 0.3787\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1354 - accuracy: 0.9533 - val_loss: 4.5764 - val_accuracy: 0.3825\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1222 - accuracy: 0.9590 - val_loss: 5.1031 - val_accuracy: 0.3837\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.1146 - accuracy: 0.9626 - val_loss: 5.1112 - val_accuracy: 0.3850\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1277 - accuracy: 0.9586 - val_loss: 5.0181 - val_accuracy: 0.3862\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.1150 - accuracy: 0.9637 - val_loss: 4.9137 - val_accuracy: 0.4013\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.1378 - accuracy: 0.9587 - val_loss: 4.9212 - val_accuracy: 0.3875\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1204 - accuracy: 0.9587 - val_loss: 5.0929 - val_accuracy: 0.3700\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1367 - accuracy: 0.9564 - val_loss: 4.9263 - val_accuracy: 0.3837\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1141 - accuracy: 0.9603 - val_loss: 4.8113 - val_accuracy: 0.3913\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 3)       30        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 3)       12        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 3)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 48, 351, 3)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 48, 351, 3)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 351, 6)        168       \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 351, 6)        24        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 48, 351, 6)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 87, 6)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 87, 6)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12528)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 100232    \n",
            "=================================================================\n",
            "Total params: 100,850\n",
            "Trainable params: 100,640\n",
            "Non-trainable params: 210\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 17.1966 - accuracy: 0.2331INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 06.17.00/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 21s 105ms/step - loss: 17.1966 - accuracy: 0.2331 - val_loss: 4.4036 - val_accuracy: 0.2750\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 2.3541 - accuracy: 0.3355INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 06.17.00/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 20s 101ms/step - loss: 2.3541 - accuracy: 0.3355 - val_loss: 1.8894 - val_accuracy: 0.3175\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.6696 - accuracy: 0.4078INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 06.17.00/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 21s 103ms/step - loss: 1.6696 - accuracy: 0.4078 - val_loss: 1.8120 - val_accuracy: 0.3363\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 1.6470 - accuracy: 0.4214 - val_loss: 1.9232 - val_accuracy: 0.3088\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.6184 - accuracy: 0.4283INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 06.17.00/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 20s 101ms/step - loss: 1.6184 - accuracy: 0.4283 - val_loss: 1.7412 - val_accuracy: 0.3688\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 1.6132 - accuracy: 0.4340 - val_loss: 1.8022 - val_accuracy: 0.3675\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 1.5839 - accuracy: 0.4458 - val_loss: 1.8401 - val_accuracy: 0.3325\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 1.5185 - accuracy: 0.4719 - val_loss: 1.9535 - val_accuracy: 0.3038\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 1.4864 - accuracy: 0.4813 - val_loss: 2.1213 - val_accuracy: 0.3300\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.4651 - accuracy: 0.4862INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 06.17.00/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 20s 101ms/step - loss: 1.4651 - accuracy: 0.4862 - val_loss: 1.8599 - val_accuracy: 0.3812\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.3962 - accuracy: 0.5160INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 06.17.00/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 21s 103ms/step - loss: 1.3962 - accuracy: 0.5160 - val_loss: 1.8021 - val_accuracy: 0.3825\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 1.3214 - accuracy: 0.5467 - val_loss: 1.8030 - val_accuracy: 0.3812\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 1.2553 - accuracy: 0.5668 - val_loss: 1.9314 - val_accuracy: 0.3762\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 1.2042 - accuracy: 0.5839 - val_loss: 1.9401 - val_accuracy: 0.3625\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.1389 - accuracy: 0.6059INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 06.17.00/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 20s 102ms/step - loss: 1.1389 - accuracy: 0.6059 - val_loss: 1.8090 - val_accuracy: 0.4025\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.0503 - accuracy: 0.6380INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 06.17.00/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 20s 101ms/step - loss: 1.0503 - accuracy: 0.6380 - val_loss: 1.9801 - val_accuracy: 0.4050\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 1.0084 - accuracy: 0.6497 - val_loss: 2.3076 - val_accuracy: 0.3762\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.9371 - accuracy: 0.6773 - val_loss: 1.9785 - val_accuracy: 0.3938\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.8522 - accuracy: 0.7060 - val_loss: 2.3707 - val_accuracy: 0.3725\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.8323 - accuracy: 0.7136 - val_loss: 2.2602 - val_accuracy: 0.3663\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.8152 - accuracy: 0.7160 - val_loss: 2.4506 - val_accuracy: 0.3738\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.7562 - accuracy: 0.7347 - val_loss: 2.4774 - val_accuracy: 0.3800\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.7000 - accuracy: 0.7574 - val_loss: 2.4509 - val_accuracy: 0.3887\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.6829 - accuracy: 0.7619INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 06.17.00/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 21s 103ms/step - loss: 0.6829 - accuracy: 0.7619 - val_loss: 2.4383 - val_accuracy: 0.4100\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.6403 - accuracy: 0.7822 - val_loss: 2.6722 - val_accuracy: 0.4025\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.6251 - accuracy: 0.7811 - val_loss: 2.5101 - val_accuracy: 0.4100\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.5614 - accuracy: 0.8062 - val_loss: 3.0327 - val_accuracy: 0.3862\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.5720 - accuracy: 0.8049 - val_loss: 2.7507 - val_accuracy: 0.3762\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.5196 - accuracy: 0.8204INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 06.17.00/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 20s 101ms/step - loss: 0.5196 - accuracy: 0.8204 - val_loss: 2.9162 - val_accuracy: 0.4212\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.5237 - accuracy: 0.8169 - val_loss: 2.7678 - val_accuracy: 0.3925\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.4958 - accuracy: 0.8330 - val_loss: 2.9569 - val_accuracy: 0.3750\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.5052 - accuracy: 0.8321 - val_loss: 2.8566 - val_accuracy: 0.3650\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.4268 - accuracy: 0.8537 - val_loss: 3.1618 - val_accuracy: 0.4087\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.4862 - accuracy: 0.8365 - val_loss: 2.9581 - val_accuracy: 0.3913\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.4338 - accuracy: 0.8516 - val_loss: 3.2284 - val_accuracy: 0.3913\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.4363 - accuracy: 0.8542 - val_loss: 3.7347 - val_accuracy: 0.3713\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.4233 - accuracy: 0.8576 - val_loss: 3.3067 - val_accuracy: 0.4013\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.4147 - accuracy: 0.8598 - val_loss: 3.2680 - val_accuracy: 0.3475\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.3845 - accuracy: 0.8688 - val_loss: 3.2274 - val_accuracy: 0.3950\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.4049 - accuracy: 0.8618 - val_loss: 3.4419 - val_accuracy: 0.3738\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 18s 92ms/step - loss: 0.3386 - accuracy: 0.8832 - val_loss: 3.3834 - val_accuracy: 0.3875\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.3284 - accuracy: 0.8910 - val_loss: 3.6778 - val_accuracy: 0.3862\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.3535 - accuracy: 0.8807 - val_loss: 3.5950 - val_accuracy: 0.3925\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.3475 - accuracy: 0.8871 - val_loss: 3.8195 - val_accuracy: 0.3550\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.3495 - accuracy: 0.8879 - val_loss: 3.5307 - val_accuracy: 0.3975\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.3327 - accuracy: 0.8904 - val_loss: 3.8941 - val_accuracy: 0.3837\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.3170 - accuracy: 0.8957 - val_loss: 3.6246 - val_accuracy: 0.3862\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.3130 - accuracy: 0.8993 - val_loss: 3.6305 - val_accuracy: 0.4050\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.2929 - accuracy: 0.9071 - val_loss: 3.7712 - val_accuracy: 0.3900\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.3072 - accuracy: 0.9014 - val_loss: 3.8608 - val_accuracy: 0.3825\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.3035 - accuracy: 0.8965 - val_loss: 4.0322 - val_accuracy: 0.4112\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.3105 - accuracy: 0.9065 - val_loss: 3.7303 - val_accuracy: 0.3887\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.2672 - accuracy: 0.9115 - val_loss: 3.9212 - val_accuracy: 0.3950\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2827 - accuracy: 0.9084 - val_loss: 3.9116 - val_accuracy: 0.4062\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.2797 - accuracy: 0.9118 - val_loss: 3.7778 - val_accuracy: 0.3825\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2568 - accuracy: 0.9140 - val_loss: 4.0489 - val_accuracy: 0.3913\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2497 - accuracy: 0.9196 - val_loss: 4.1835 - val_accuracy: 0.3963\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2877 - accuracy: 0.9104 - val_loss: 4.0264 - val_accuracy: 0.3688\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.2612 - accuracy: 0.9165INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 06.17.00/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 20s 102ms/step - loss: 0.2612 - accuracy: 0.9165 - val_loss: 3.9635 - val_accuracy: 0.4225\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.2544 - accuracy: 0.9201 - val_loss: 3.8083 - val_accuracy: 0.4175\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.2391 - accuracy: 0.9201 - val_loss: 4.1706 - val_accuracy: 0.4062\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2793 - accuracy: 0.9173 - val_loss: 3.8763 - val_accuracy: 0.4187\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.2521 - accuracy: 0.9223 - val_loss: 3.9685 - val_accuracy: 0.3963\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2223 - accuracy: 0.9286 - val_loss: 4.2798 - val_accuracy: 0.3887\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.2508 - accuracy: 0.9245 - val_loss: 4.3895 - val_accuracy: 0.4062\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.2397 - accuracy: 0.9229 - val_loss: 4.3054 - val_accuracy: 0.3787\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2527 - accuracy: 0.9231 - val_loss: 4.3325 - val_accuracy: 0.3913\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.2522 - accuracy: 0.9232 - val_loss: 4.6525 - val_accuracy: 0.3938\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.2365 - accuracy: 0.9273 - val_loss: 4.5022 - val_accuracy: 0.4013\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2646 - accuracy: 0.9181 - val_loss: 4.4994 - val_accuracy: 0.3938\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2225 - accuracy: 0.9268 - val_loss: 4.5030 - val_accuracy: 0.3688\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2326 - accuracy: 0.9228 - val_loss: 4.1075 - val_accuracy: 0.4075\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.2255 - accuracy: 0.9348 - val_loss: 4.4065 - val_accuracy: 0.3750\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2161 - accuracy: 0.9351 - val_loss: 4.2002 - val_accuracy: 0.4112\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.1962 - accuracy: 0.9364 - val_loss: 4.7780 - val_accuracy: 0.4013\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2188 - accuracy: 0.9312 - val_loss: 4.8369 - val_accuracy: 0.3988\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2093 - accuracy: 0.9354 - val_loss: 4.7771 - val_accuracy: 0.3963\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2392 - accuracy: 0.9290 - val_loss: 4.9646 - val_accuracy: 0.4038\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2169 - accuracy: 0.9347 - val_loss: 5.0849 - val_accuracy: 0.3875\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2203 - accuracy: 0.9317 - val_loss: 4.7380 - val_accuracy: 0.3913\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.2229 - accuracy: 0.9362 - val_loss: 5.2492 - val_accuracy: 0.3975\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.2176 - accuracy: 0.9354 - val_loss: 4.9036 - val_accuracy: 0.3925\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.1845 - accuracy: 0.9423 - val_loss: 5.0867 - val_accuracy: 0.3900\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2067 - accuracy: 0.9354 - val_loss: 4.9809 - val_accuracy: 0.4038\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2128 - accuracy: 0.9368 - val_loss: 4.8790 - val_accuracy: 0.3762\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2159 - accuracy: 0.9367 - val_loss: 4.9294 - val_accuracy: 0.3762\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2210 - accuracy: 0.9376 - val_loss: 5.3524 - val_accuracy: 0.3638\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2238 - accuracy: 0.9332 - val_loss: 5.2297 - val_accuracy: 0.3850\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2277 - accuracy: 0.9336 - val_loss: 5.1999 - val_accuracy: 0.3675\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2135 - accuracy: 0.9365 - val_loss: 4.7590 - val_accuracy: 0.3738\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.1952 - accuracy: 0.9411 - val_loss: 4.9869 - val_accuracy: 0.3913\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.1568 - accuracy: 0.9498 - val_loss: 5.3830 - val_accuracy: 0.3738\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.1752 - accuracy: 0.9478 - val_loss: 5.3461 - val_accuracy: 0.3850\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.1816 - accuracy: 0.9486 - val_loss: 5.4972 - val_accuracy: 0.3700\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.1953 - accuracy: 0.9392 - val_loss: 5.6263 - val_accuracy: 0.3862\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2219 - accuracy: 0.9375 - val_loss: 5.6138 - val_accuracy: 0.3963\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.2074 - accuracy: 0.9417 - val_loss: 5.0052 - val_accuracy: 0.3787\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.1948 - accuracy: 0.9431 - val_loss: 5.1095 - val_accuracy: 0.4150\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.1854 - accuracy: 0.9483 - val_loss: 5.0191 - val_accuracy: 0.4062\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.1739 - accuracy: 0.9497 - val_loss: 5.7908 - val_accuracy: 0.3762\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 8)       80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 8)       32        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 8)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 48, 351, 8)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 48, 351, 8)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 351, 15)       1095      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 351, 15)       60        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 48, 351, 15)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 87, 15)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 87, 15)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 31320)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 250568    \n",
            "=================================================================\n",
            "Total params: 252,219\n",
            "Trainable params: 251,981\n",
            "Non-trainable params: 238\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXflPoaKPIsV",
        "colab_type": "text"
      },
      "source": [
        "## Training 1-layer fully convolutional NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmsO08D-PFCE",
        "colab_type": "code",
        "outputId": "c8921184-b6e5-4030-dc6f-1b888add069d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Experiment 9\n",
        "# Deep k2c2\n",
        "\n",
        "params = {135000:[1], 270000:[2]}\n",
        "\n",
        "dropouts = [0.2, 0.4]\n",
        "\n",
        "for i, num in enumerate([135000, 270000]):\n",
        "\n",
        "  hyperparams = {\"number_filters\" : params[num],\n",
        "                \"number_params\" : num,\n",
        "                \"kernel_size\" : [(3, 3)],\n",
        "                \"pooling_size\" : [(2,4)],\n",
        "                \"hidden_layers\": [],\n",
        "                \"epsilon\": 0.01, \n",
        "                \"learning_rate\": 0.01, \n",
        "                \"batch_size\": 32, \n",
        "                \"epochs\": 50,\n",
        "                \"dropout\" : dropouts[i],\n",
        "                \"drop_out_hidden\" : 0\n",
        "                }\n",
        "\n",
        "\n",
        "  model_string = \"cnn_k2c2_1layer\"\n",
        "  model = cnn_k1c2_model(hyperparams)\n",
        "\n",
        "\n",
        "  history = run_experiment(model, model_string, hyperparams)\n",
        "  model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 6.9984 - accuracy: 0.2540INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 17.02.22/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 6.9984 - accuracy: 0.2540 - val_loss: 1.8594 - val_accuracy: 0.3100\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 1.4683 - accuracy: 0.4993 - val_loss: 1.9180 - val_accuracy: 0.2937\n",
            "Epoch 3/50\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.2300 - accuracy: 0.5854INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 17.02.22/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 1.2306 - accuracy: 0.5853 - val_loss: 1.9685 - val_accuracy: 0.3137\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.9643 - accuracy: 0.6883 - val_loss: 2.3276 - val_accuracy: 0.2988\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.7587 - accuracy: 0.7491 - val_loss: 2.6144 - val_accuracy: 0.2862\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.5671 - accuracy: 0.8160 - val_loss: 2.9771 - val_accuracy: 0.2763\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.4772 - accuracy: 0.8466 - val_loss: 3.3814 - val_accuracy: 0.2950\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.4262 - accuracy: 0.8626 - val_loss: 3.3880 - val_accuracy: 0.3088\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.3319 - accuracy: 0.8926 - val_loss: 3.7152 - val_accuracy: 0.2912\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.3062 - accuracy: 0.9017 - val_loss: 4.0139 - val_accuracy: 0.2438\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.2864 - accuracy: 0.9084 - val_loss: 3.8640 - val_accuracy: 0.2887\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.2329 - accuracy: 0.9264 - val_loss: 4.3455 - val_accuracy: 0.2862\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.2412 - accuracy: 0.9217 - val_loss: 3.9651 - val_accuracy: 0.2900\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.1843 - accuracy: 0.9404 - val_loss: 4.6657 - val_accuracy: 0.2937\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.2148 - accuracy: 0.9293 - val_loss: 3.9893 - val_accuracy: 0.2713\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.1632 - accuracy: 0.9487 - val_loss: 4.7137 - val_accuracy: 0.2800\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.1600 - accuracy: 0.9525 - val_loss: 4.7775 - val_accuracy: 0.2887\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.1800 - accuracy: 0.9398 - val_loss: 4.8477 - val_accuracy: 0.3000\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.1568 - accuracy: 0.9476 - val_loss: 4.6517 - val_accuracy: 0.2837\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.1645 - accuracy: 0.9475 - val_loss: 4.5320 - val_accuracy: 0.2700\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 10s 50ms/step - loss: 0.1554 - accuracy: 0.9478 - val_loss: 5.0216 - val_accuracy: 0.2825\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.1422 - accuracy: 0.9569 - val_loss: 5.0304 - val_accuracy: 0.2788\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.1167 - accuracy: 0.9619 - val_loss: 5.1505 - val_accuracy: 0.2950\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.1157 - accuracy: 0.9644 - val_loss: 5.5191 - val_accuracy: 0.2738\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.1051 - accuracy: 0.9648 - val_loss: 5.7579 - val_accuracy: 0.2850\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.1067 - accuracy: 0.9655 - val_loss: 5.2186 - val_accuracy: 0.2850\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.1158 - accuracy: 0.9630 - val_loss: 5.0413 - val_accuracy: 0.2788\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.1120 - accuracy: 0.9634 - val_loss: 5.4327 - val_accuracy: 0.2812\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.1028 - accuracy: 0.9670 - val_loss: 5.2924 - val_accuracy: 0.2925\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.0891 - accuracy: 0.9719 - val_loss: 5.5242 - val_accuracy: 0.2887\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.1009 - accuracy: 0.9701 - val_loss: 5.3493 - val_accuracy: 0.2950\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.1023 - accuracy: 0.9686 - val_loss: 5.9893 - val_accuracy: 0.2700\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.0761 - accuracy: 0.9759 - val_loss: 6.0130 - val_accuracy: 0.2862\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.0809 - accuracy: 0.9744 - val_loss: 5.6676 - val_accuracy: 0.2975\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.0908 - accuracy: 0.9717 - val_loss: 6.1037 - val_accuracy: 0.2688\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.0886 - accuracy: 0.9719 - val_loss: 5.9787 - val_accuracy: 0.2850\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.0814 - accuracy: 0.9728 - val_loss: 6.4871 - val_accuracy: 0.2837\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.0676 - accuracy: 0.9786 - val_loss: 6.1466 - val_accuracy: 0.3025\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.0834 - accuracy: 0.9730 - val_loss: 5.8569 - val_accuracy: 0.2663\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.0735 - accuracy: 0.9786 - val_loss: 5.9512 - val_accuracy: 0.2763\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.0606 - accuracy: 0.9797 - val_loss: 5.8584 - val_accuracy: 0.2837\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.0607 - accuracy: 0.9806 - val_loss: 6.5291 - val_accuracy: 0.2600\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.0895 - accuracy: 0.9725 - val_loss: 6.3784 - val_accuracy: 0.2650\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.0689 - accuracy: 0.9770 - val_loss: 6.7843 - val_accuracy: 0.2962\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.0640 - accuracy: 0.9791 - val_loss: 6.5989 - val_accuracy: 0.2900\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.0726 - accuracy: 0.9751 - val_loss: 6.0302 - val_accuracy: 0.2637\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.0619 - accuracy: 0.9814 - val_loss: 6.2612 - val_accuracy: 0.3000\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.0585 - accuracy: 0.9823 - val_loss: 6.7316 - val_accuracy: 0.2663\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.0608 - accuracy: 0.9801 - val_loss: 6.0684 - val_accuracy: 0.2862\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.0665 - accuracy: 0.9803 - val_loss: 7.1795 - val_accuracy: 0.2975\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_16 (Batc (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 96, 1405, 1)       10        \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 96, 1405, 1)       4         \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 96, 1405, 1)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 48, 351, 1)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 48, 351, 1)        0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 16848)             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 8)                 134792    \n",
            "=================================================================\n",
            "Total params: 135,190\n",
            "Trainable params: 134,996\n",
            "Non-trainable params: 194\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 10.5497 - accuracy: 0.2590INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 17.10.29/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 12s 62ms/step - loss: 10.5497 - accuracy: 0.2590 - val_loss: 2.2515 - val_accuracy: 0.3200\n",
            "Epoch 2/50\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.3722 - accuracy: 0.5319INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 17.10.29/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 1.3723 - accuracy: 0.5320 - val_loss: 1.9062 - val_accuracy: 0.3438\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 1.1909 - accuracy: 0.5934INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 17.10.29/models_cnn_k2c2_2layer/assets\n",
            "200/200 [==============================] - 12s 61ms/step - loss: 1.1909 - accuracy: 0.5934 - val_loss: 1.8869 - val_accuracy: 0.3525\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.9839 - accuracy: 0.6672 - val_loss: 2.0443 - val_accuracy: 0.3212\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.8138 - accuracy: 0.7294 - val_loss: 2.2353 - val_accuracy: 0.3275\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.7312 - accuracy: 0.7665 - val_loss: 2.3897 - val_accuracy: 0.2950\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.6149 - accuracy: 0.7946 - val_loss: 2.6671 - val_accuracy: 0.2975\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.5475 - accuracy: 0.8201 - val_loss: 2.6538 - val_accuracy: 0.3088\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.4636 - accuracy: 0.8542 - val_loss: 2.8869 - val_accuracy: 0.3325\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.4423 - accuracy: 0.8598 - val_loss: 3.1919 - val_accuracy: 0.3075\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.3726 - accuracy: 0.8779 - val_loss: 3.1582 - val_accuracy: 0.3262\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.3518 - accuracy: 0.8884 - val_loss: 3.4448 - val_accuracy: 0.3088\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.3130 - accuracy: 0.9025 - val_loss: 3.6321 - val_accuracy: 0.2812\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.2918 - accuracy: 0.9073 - val_loss: 3.5764 - val_accuracy: 0.3313\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.2732 - accuracy: 0.9100 - val_loss: 3.8475 - val_accuracy: 0.2725\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.2602 - accuracy: 0.9182 - val_loss: 3.2758 - val_accuracy: 0.3438\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.2307 - accuracy: 0.9207 - val_loss: 3.7784 - val_accuracy: 0.3137\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.2225 - accuracy: 0.9248 - val_loss: 3.9170 - val_accuracy: 0.3350\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.2015 - accuracy: 0.9336 - val_loss: 4.4289 - val_accuracy: 0.3250\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.2038 - accuracy: 0.9337 - val_loss: 3.9422 - val_accuracy: 0.3225\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.1952 - accuracy: 0.9378 - val_loss: 4.3286 - val_accuracy: 0.3150\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.1718 - accuracy: 0.9429 - val_loss: 4.6175 - val_accuracy: 0.3137\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.1814 - accuracy: 0.9433 - val_loss: 4.4269 - val_accuracy: 0.2925\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.1343 - accuracy: 0.9565 - val_loss: 4.1406 - val_accuracy: 0.3388\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.1647 - accuracy: 0.9492 - val_loss: 4.1019 - val_accuracy: 0.3000\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.1294 - accuracy: 0.9581 - val_loss: 4.4901 - val_accuracy: 0.3425\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.1406 - accuracy: 0.9575 - val_loss: 4.2312 - val_accuracy: 0.2925\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.1194 - accuracy: 0.9619 - val_loss: 4.4782 - val_accuracy: 0.3100\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.1203 - accuracy: 0.9605 - val_loss: 5.0132 - val_accuracy: 0.3125\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.1165 - accuracy: 0.9617 - val_loss: 4.5995 - val_accuracy: 0.3025\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.1254 - accuracy: 0.9622 - val_loss: 4.4639 - val_accuracy: 0.3212\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.1014 - accuracy: 0.9675 - val_loss: 5.4176 - val_accuracy: 0.2912\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.1198 - accuracy: 0.9631 - val_loss: 4.9726 - val_accuracy: 0.3063\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0886 - accuracy: 0.9726 - val_loss: 5.1876 - val_accuracy: 0.3100\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.1136 - accuracy: 0.9642 - val_loss: 4.6992 - val_accuracy: 0.3137\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.1081 - accuracy: 0.9639 - val_loss: 5.1899 - val_accuracy: 0.3113\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0999 - accuracy: 0.9675 - val_loss: 4.9518 - val_accuracy: 0.3038\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.1000 - accuracy: 0.9703 - val_loss: 4.8643 - val_accuracy: 0.2887\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0885 - accuracy: 0.9712 - val_loss: 4.8369 - val_accuracy: 0.3212\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0870 - accuracy: 0.9728 - val_loss: 5.4507 - val_accuracy: 0.3025\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0798 - accuracy: 0.9750 - val_loss: 5.3246 - val_accuracy: 0.2925\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0832 - accuracy: 0.9730 - val_loss: 5.7803 - val_accuracy: 0.3137\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0973 - accuracy: 0.9701 - val_loss: 5.4970 - val_accuracy: 0.3125\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0889 - accuracy: 0.9692 - val_loss: 5.4677 - val_accuracy: 0.2962\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0894 - accuracy: 0.9725 - val_loss: 5.5431 - val_accuracy: 0.3025\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0652 - accuracy: 0.9787 - val_loss: 5.3024 - val_accuracy: 0.3025\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0712 - accuracy: 0.9792 - val_loss: 5.8595 - val_accuracy: 0.3063\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0806 - accuracy: 0.9751 - val_loss: 5.6626 - val_accuracy: 0.2975\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.0981 - accuracy: 0.9725 - val_loss: 5.6392 - val_accuracy: 0.3000\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0699 - accuracy: 0.9776 - val_loss: 5.4905 - val_accuracy: 0.3275\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 2)       20        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 2)       8         \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 2)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 48, 351, 2)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 48, 351, 2)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 33696)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 269576    \n",
            "=================================================================\n",
            "Total params: 269,988\n",
            "Trainable params: 269,792\n",
            "Non-trainable params: 196\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRvmqr_7KNAX",
        "colab_type": "text"
      },
      "source": [
        "##1' layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0VSk9-UKT5S",
        "colab_type": "code",
        "outputId": "9d8eddce-71e7-424c-ecae-28aea6812b69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Experiment 11\n",
        "# Deep k2c2\n",
        "\n",
        "params = {135000:[4], 270000:[8], 540000:[16]}\n",
        "\n",
        "dropouts = [0.2, 0.4, 0.5]\n",
        "\n",
        "for i, num in enumerate([135000, 270000, 540000]):\n",
        "\n",
        "  hyperparams = {\"number_filters\" : params[num],\n",
        "                \"number_params\" : num,\n",
        "                \"kernel_size\" : [(3, 3)],\n",
        "                \"pooling_size\" : [(4,8)],\n",
        "                \"hidden_layers\": [],\n",
        "                \"epsilon\": 0.01, \n",
        "                \"learning_rate\": 0.01, \n",
        "                \"batch_size\": 32, \n",
        "                \"epochs\": 50,\n",
        "                \"dropout\" : dropouts[i],\n",
        "                \"drop_out_hidden\" : 0\n",
        "                }\n",
        "\n",
        "\n",
        "  model_string = \"cnn_k2c2_1modlayer\"\n",
        "  model = cnn_k1c2_model(hyperparams)\n",
        "\n",
        "\n",
        "  history = run_experiment(model, model_string, hyperparams)\n",
        "  model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "199/200 [============================>.] - ETA: 0s - loss: 7.9333 - accuracy: 0.2671INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 22.56.07/models_cnn_k2c2_1modlayer/assets\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 7.9071 - accuracy: 0.2676 - val_loss: 2.9433 - val_accuracy: 0.2800\n",
            "Epoch 2/50\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.9509 - accuracy: 0.4022INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 22.56.07/models_cnn_k2c2_1modlayer/assets\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 1.9505 - accuracy: 0.4022 - val_loss: 2.0391 - val_accuracy: 0.3125\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 1.4482 - accuracy: 0.5024 - val_loss: 2.0062 - val_accuracy: 0.2512\n",
            "Epoch 4/50\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.3265 - accuracy: 0.5465INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 22.56.07/models_cnn_k2c2_1modlayer/assets\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 1.3252 - accuracy: 0.5468 - val_loss: 1.9197 - val_accuracy: 0.3325\n",
            "Epoch 5/50\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.2400 - accuracy: 0.5757INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 22.56.07/models_cnn_k2c2_1modlayer/assets\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 1.2405 - accuracy: 0.5754 - val_loss: 1.7931 - val_accuracy: 0.3462\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 1.0981 - accuracy: 0.6306 - val_loss: 2.1160 - val_accuracy: 0.3088\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.9973 - accuracy: 0.6689 - val_loss: 2.1348 - val_accuracy: 0.2975\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.8375 - accuracy: 0.7216 - val_loss: 2.1353 - val_accuracy: 0.3388\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.7716 - accuracy: 0.7389 - val_loss: 2.4341 - val_accuracy: 0.3200\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.6815 - accuracy: 0.7694 - val_loss: 2.5661 - val_accuracy: 0.3275\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.5790 - accuracy: 0.8068 - val_loss: 2.7112 - val_accuracy: 0.3212\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.5081 - accuracy: 0.8285 - val_loss: 2.9448 - val_accuracy: 0.3212\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.4801 - accuracy: 0.8421 - val_loss: 3.0006 - val_accuracy: 0.3212\n",
            "Epoch 14/50\n",
            "199/200 [============================>.] - ETA: 0s - loss: 0.4266 - accuracy: 0.8640INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 22.56.07/models_cnn_k2c2_1modlayer/assets\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.4293 - accuracy: 0.8638 - val_loss: 3.4894 - val_accuracy: 0.3562\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.3861 - accuracy: 0.8784 - val_loss: 3.6270 - val_accuracy: 0.2900\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.3591 - accuracy: 0.8785 - val_loss: 3.3860 - val_accuracy: 0.3313\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.3250 - accuracy: 0.8910 - val_loss: 3.4573 - val_accuracy: 0.3125\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.3103 - accuracy: 0.8967 - val_loss: 3.6063 - val_accuracy: 0.3250\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.2845 - accuracy: 0.9068 - val_loss: 3.7495 - val_accuracy: 0.3212\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.2818 - accuracy: 0.9103 - val_loss: 3.7898 - val_accuracy: 0.3200\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.2754 - accuracy: 0.9096 - val_loss: 3.7976 - val_accuracy: 0.3288\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.2331 - accuracy: 0.9223 - val_loss: 4.0091 - val_accuracy: 0.3262\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.2206 - accuracy: 0.9293 - val_loss: 4.2117 - val_accuracy: 0.3225\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.2300 - accuracy: 0.9267 - val_loss: 4.3214 - val_accuracy: 0.3262\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.2330 - accuracy: 0.9306 - val_loss: 3.8790 - val_accuracy: 0.2925\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.2138 - accuracy: 0.9281 - val_loss: 4.2900 - val_accuracy: 0.3075\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.2542 - accuracy: 0.9215 - val_loss: 4.0240 - val_accuracy: 0.3375\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1571 - accuracy: 0.9503 - val_loss: 4.5815 - val_accuracy: 0.3187\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1991 - accuracy: 0.9373 - val_loss: 4.5759 - val_accuracy: 0.3262\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.1654 - accuracy: 0.9472 - val_loss: 4.5944 - val_accuracy: 0.3187\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1873 - accuracy: 0.9415 - val_loss: 4.6175 - val_accuracy: 0.3088\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1395 - accuracy: 0.9590 - val_loss: 4.7861 - val_accuracy: 0.3288\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1566 - accuracy: 0.9484 - val_loss: 5.2476 - val_accuracy: 0.3150\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1403 - accuracy: 0.9567 - val_loss: 5.0265 - val_accuracy: 0.3225\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.1427 - accuracy: 0.9523 - val_loss: 4.9136 - val_accuracy: 0.3175\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1479 - accuracy: 0.9551 - val_loss: 5.0791 - val_accuracy: 0.3250\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1505 - accuracy: 0.9520 - val_loss: 5.0890 - val_accuracy: 0.2962\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1442 - accuracy: 0.9570 - val_loss: 4.8026 - val_accuracy: 0.3075\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1410 - accuracy: 0.9554 - val_loss: 4.8723 - val_accuracy: 0.3025\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1333 - accuracy: 0.9572 - val_loss: 4.9980 - val_accuracy: 0.3212\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1176 - accuracy: 0.9612 - val_loss: 5.2134 - val_accuracy: 0.3388\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1161 - accuracy: 0.9645 - val_loss: 5.5911 - val_accuracy: 0.3100\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1524 - accuracy: 0.9554 - val_loss: 6.2059 - val_accuracy: 0.3050\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1665 - accuracy: 0.9495 - val_loss: 5.5856 - val_accuracy: 0.2700\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1039 - accuracy: 0.9642 - val_loss: 5.3318 - val_accuracy: 0.3175\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1085 - accuracy: 0.9631 - val_loss: 5.5268 - val_accuracy: 0.3175\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1109 - accuracy: 0.9650 - val_loss: 5.4625 - val_accuracy: 0.3100\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 0.1270 - accuracy: 0.9595 - val_loss: 5.4126 - val_accuracy: 0.2975\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1359 - accuracy: 0.9589 - val_loss: 5.8327 - val_accuracy: 0.3025\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1024 - accuracy: 0.9676 - val_loss: 5.6575 - val_accuracy: 0.2912\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 4)       40        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 4)       16        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 4)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 24, 175, 4)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 24, 175, 4)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16800)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 134408    \n",
            "=================================================================\n",
            "Total params: 134,848\n",
            "Trainable params: 134,648\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 18.3535 - accuracy: 0.2747INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 23.01.54/models_cnn_k2c2_1modlayer/assets\n",
            "200/200 [==============================] - 9s 45ms/step - loss: 18.3535 - accuracy: 0.2747 - val_loss: 6.5857 - val_accuracy: 0.2713\n",
            "Epoch 2/50\n",
            "199/200 [============================>.] - ETA: 0s - loss: 3.2152 - accuracy: 0.3882INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 23.01.54/models_cnn_k2c2_1modlayer/assets\n",
            "200/200 [==============================] - 9s 44ms/step - loss: 3.2126 - accuracy: 0.3875 - val_loss: 2.1408 - val_accuracy: 0.3000\n",
            "Epoch 3/50\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.4483 - accuracy: 0.5099INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 23.01.54/models_cnn_k2c2_1modlayer/assets\n",
            "200/200 [==============================] - 9s 45ms/step - loss: 1.4470 - accuracy: 0.5104 - val_loss: 1.9230 - val_accuracy: 0.3587\n",
            "Epoch 4/50\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.2946 - accuracy: 0.5524INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 23.01.54/models_cnn_k2c2_1modlayer/assets\n",
            "200/200 [==============================] - 9s 44ms/step - loss: 1.2952 - accuracy: 0.5524 - val_loss: 1.7314 - val_accuracy: 0.4025\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 1.2021 - accuracy: 0.5887 - val_loss: 1.7929 - val_accuracy: 0.3725\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 1.1074 - accuracy: 0.6278 - val_loss: 1.9666 - val_accuracy: 0.3175\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 1.0487 - accuracy: 0.6447 - val_loss: 1.9141 - val_accuracy: 0.3575\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.9082 - accuracy: 0.6988 - val_loss: 2.3749 - val_accuracy: 0.3275\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.8670 - accuracy: 0.7149 - val_loss: 2.4268 - val_accuracy: 0.3025\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.8112 - accuracy: 0.7264 - val_loss: 2.3472 - val_accuracy: 0.3325\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.7225 - accuracy: 0.7602 - val_loss: 2.4948 - val_accuracy: 0.3613\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.6888 - accuracy: 0.7711 - val_loss: 2.3707 - val_accuracy: 0.3462\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.6257 - accuracy: 0.7972 - val_loss: 2.5288 - val_accuracy: 0.3625\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.5867 - accuracy: 0.8035 - val_loss: 2.5666 - val_accuracy: 0.3575\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.5681 - accuracy: 0.8124 - val_loss: 2.7097 - val_accuracy: 0.3450\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.5603 - accuracy: 0.8116 - val_loss: 2.9508 - val_accuracy: 0.3250\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.4848 - accuracy: 0.8363 - val_loss: 3.2692 - val_accuracy: 0.3388\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.4920 - accuracy: 0.8385 - val_loss: 2.8747 - val_accuracy: 0.3700\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.4521 - accuracy: 0.8504 - val_loss: 3.0956 - val_accuracy: 0.3100\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.4288 - accuracy: 0.8567 - val_loss: 3.4105 - val_accuracy: 0.3400\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.4030 - accuracy: 0.8684 - val_loss: 3.1532 - val_accuracy: 0.3487\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.3980 - accuracy: 0.8713 - val_loss: 2.8512 - val_accuracy: 0.3713\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.3957 - accuracy: 0.8717 - val_loss: 3.4075 - val_accuracy: 0.3400\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.3720 - accuracy: 0.8784 - val_loss: 3.8847 - val_accuracy: 0.3137\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.3332 - accuracy: 0.8890 - val_loss: 3.3767 - val_accuracy: 0.3237\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.3227 - accuracy: 0.8970 - val_loss: 3.7642 - val_accuracy: 0.3275\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.3236 - accuracy: 0.8948 - val_loss: 3.9009 - val_accuracy: 0.3150\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.3171 - accuracy: 0.8954 - val_loss: 3.4305 - val_accuracy: 0.3550\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.2612 - accuracy: 0.9125 - val_loss: 3.8641 - val_accuracy: 0.3475\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.2769 - accuracy: 0.9154 - val_loss: 3.8447 - val_accuracy: 0.3350\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.2737 - accuracy: 0.9087 - val_loss: 4.2598 - val_accuracy: 0.3537\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.2957 - accuracy: 0.9054 - val_loss: 3.8538 - val_accuracy: 0.3638\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.2736 - accuracy: 0.9143 - val_loss: 4.2244 - val_accuracy: 0.3187\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.2509 - accuracy: 0.9164 - val_loss: 3.9818 - val_accuracy: 0.3512\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.2422 - accuracy: 0.9204 - val_loss: 4.2817 - val_accuracy: 0.3137\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.2255 - accuracy: 0.9314 - val_loss: 4.2732 - val_accuracy: 0.3162\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.2425 - accuracy: 0.9245 - val_loss: 4.4037 - val_accuracy: 0.3288\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.2406 - accuracy: 0.9259 - val_loss: 4.5896 - val_accuracy: 0.3450\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.2659 - accuracy: 0.9203 - val_loss: 5.3704 - val_accuracy: 0.3100\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.2604 - accuracy: 0.9206 - val_loss: 4.4282 - val_accuracy: 0.3212\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.2592 - accuracy: 0.9211 - val_loss: 4.5207 - val_accuracy: 0.3175\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.2004 - accuracy: 0.9370 - val_loss: 4.3486 - val_accuracy: 0.3537\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.2128 - accuracy: 0.9337 - val_loss: 4.3836 - val_accuracy: 0.3475\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.2270 - accuracy: 0.9317 - val_loss: 4.9485 - val_accuracy: 0.3175\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.2023 - accuracy: 0.9362 - val_loss: 4.8926 - val_accuracy: 0.3475\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.2349 - accuracy: 0.9261 - val_loss: 5.2146 - val_accuracy: 0.3088\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.1946 - accuracy: 0.9406 - val_loss: 4.7978 - val_accuracy: 0.3200\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.1942 - accuracy: 0.9381 - val_loss: 5.1695 - val_accuracy: 0.3063\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.2425 - accuracy: 0.9264 - val_loss: 4.8277 - val_accuracy: 0.3125\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.1931 - accuracy: 0.9423 - val_loss: 4.6536 - val_accuracy: 0.3350\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 8)       80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 8)       32        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 8)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 24, 175, 8)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 24, 175, 8)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 33600)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 268808    \n",
            "=================================================================\n",
            "Total params: 269,304\n",
            "Trainable params: 269,096\n",
            "Non-trainable params: 208\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 27.8120 - accuracy: 0.2496INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 23.08.09/models_cnn_k2c2_1modlayer/assets\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 27.8120 - accuracy: 0.2496 - val_loss: 10.2248 - val_accuracy: 0.2500\n",
            "Epoch 2/50\n",
            "199/200 [============================>.] - ETA: 0s - loss: 3.7052 - accuracy: 0.4061INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 23.08.09/models_cnn_k2c2_1modlayer/assets\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 3.6954 - accuracy: 0.4069 - val_loss: 1.9150 - val_accuracy: 0.3700\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 1.3950 - accuracy: 0.5306 - val_loss: 1.8338 - val_accuracy: 0.3550\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 1.2728 - accuracy: 0.5664 - val_loss: 1.8815 - val_accuracy: 0.3288\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 1.2000 - accuracy: 0.5953 - val_loss: 1.8995 - val_accuracy: 0.3525\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 1.1444 - accuracy: 0.6114 - val_loss: 2.1539 - val_accuracy: 0.3450\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 1.0444 - accuracy: 0.6519 - val_loss: 2.3004 - val_accuracy: 0.3250\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.9743 - accuracy: 0.6738 - val_loss: 2.1312 - val_accuracy: 0.3350\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 9s 43ms/step - loss: 0.8748 - accuracy: 0.7066 - val_loss: 2.4752 - val_accuracy: 0.3262\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.8371 - accuracy: 0.7144 - val_loss: 2.4868 - val_accuracy: 0.3262\n",
            "Epoch 11/50\n",
            "199/200 [============================>.] - ETA: 0s - loss: 0.7574 - accuracy: 0.7467INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 23.08.09/models_cnn_k2c2_1modlayer/assets\n",
            "200/200 [==============================] - 10s 50ms/step - loss: 0.7566 - accuracy: 0.7469 - val_loss: 2.3462 - val_accuracy: 0.3988\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.7123 - accuracy: 0.7661 - val_loss: 2.7932 - val_accuracy: 0.3200\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.6914 - accuracy: 0.7793 - val_loss: 2.7922 - val_accuracy: 0.3200\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.6386 - accuracy: 0.7949 - val_loss: 2.7263 - val_accuracy: 0.3325\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.6376 - accuracy: 0.7947 - val_loss: 2.8579 - val_accuracy: 0.3325\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.5516 - accuracy: 0.8218 - val_loss: 3.4794 - val_accuracy: 0.3338\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.5861 - accuracy: 0.8132 - val_loss: 3.0911 - val_accuracy: 0.3450\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.5199 - accuracy: 0.8316 - val_loss: 3.1059 - val_accuracy: 0.3512\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.5224 - accuracy: 0.8355 - val_loss: 3.3294 - val_accuracy: 0.3175\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.4891 - accuracy: 0.8415 - val_loss: 3.3927 - val_accuracy: 0.3875\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.4595 - accuracy: 0.8559 - val_loss: 3.8067 - val_accuracy: 0.3225\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.4146 - accuracy: 0.8701 - val_loss: 3.3603 - val_accuracy: 0.3225\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.4471 - accuracy: 0.8554 - val_loss: 3.8743 - val_accuracy: 0.3500\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.4916 - accuracy: 0.8487 - val_loss: 4.0279 - val_accuracy: 0.3462\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.4609 - accuracy: 0.8582 - val_loss: 3.8614 - val_accuracy: 0.3613\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.3905 - accuracy: 0.8795 - val_loss: 4.0423 - val_accuracy: 0.3275\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.4449 - accuracy: 0.8635 - val_loss: 4.4874 - val_accuracy: 0.3225\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 9s 43ms/step - loss: 0.4255 - accuracy: 0.8768 - val_loss: 3.8131 - val_accuracy: 0.3500\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.4162 - accuracy: 0.8737 - val_loss: 4.6165 - val_accuracy: 0.2988\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.3543 - accuracy: 0.8935 - val_loss: 4.3528 - val_accuracy: 0.3250\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.3879 - accuracy: 0.8865 - val_loss: 4.1348 - val_accuracy: 0.3438\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.3264 - accuracy: 0.9004 - val_loss: 4.8879 - val_accuracy: 0.3250\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.3611 - accuracy: 0.8912 - val_loss: 4.8139 - val_accuracy: 0.3250\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.3639 - accuracy: 0.8946 - val_loss: 4.1481 - val_accuracy: 0.3450\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 9s 43ms/step - loss: 0.3428 - accuracy: 0.8964 - val_loss: 5.0716 - val_accuracy: 0.3487\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.3530 - accuracy: 0.8951 - val_loss: 4.5857 - val_accuracy: 0.3475\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.3453 - accuracy: 0.9003 - val_loss: 4.7932 - val_accuracy: 0.3625\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.3348 - accuracy: 0.9023 - val_loss: 5.1362 - val_accuracy: 0.3187\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.3233 - accuracy: 0.9123 - val_loss: 4.7347 - val_accuracy: 0.3413\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.2764 - accuracy: 0.9182 - val_loss: 5.1166 - val_accuracy: 0.3438\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.3009 - accuracy: 0.9125 - val_loss: 4.9950 - val_accuracy: 0.3587\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.3235 - accuracy: 0.9089 - val_loss: 5.2795 - val_accuracy: 0.3650\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.2887 - accuracy: 0.9161 - val_loss: 5.4104 - val_accuracy: 0.3325\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 9s 43ms/step - loss: 0.4009 - accuracy: 0.8970 - val_loss: 5.7213 - val_accuracy: 0.3338\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 9s 43ms/step - loss: 0.3226 - accuracy: 0.9125 - val_loss: 5.9386 - val_accuracy: 0.3250\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.3236 - accuracy: 0.9132 - val_loss: 5.4947 - val_accuracy: 0.3313\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 9s 43ms/step - loss: 0.3218 - accuracy: 0.9187 - val_loss: 6.6676 - val_accuracy: 0.3288\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.3063 - accuracy: 0.9161 - val_loss: 5.8428 - val_accuracy: 0.3650\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.3486 - accuracy: 0.9100 - val_loss: 5.8738 - val_accuracy: 0.3450\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 8s 42ms/step - loss: 0.3257 - accuracy: 0.9190 - val_loss: 7.4297 - val_accuracy: 0.3038\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 96, 1405, 16)      160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 16)      64        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 96, 1405, 16)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 24, 175, 16)       0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 24, 175, 16)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 67200)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 537608    \n",
            "=================================================================\n",
            "Total params: 538,216\n",
            "Trainable params: 537,992\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtEUxFlJEY6Q",
        "colab_type": "text"
      },
      "source": [
        "##No layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2VOgR42ESSR",
        "colab_type": "code",
        "outputId": "d1aace54-5f8e-4abe-e89e-53bb4a8558e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Experiment 10\n",
        "# Deep k2c2\n",
        "\n",
        "params = {1000000:[]}\n",
        "\n",
        "dropouts = [0.2]\n",
        "\n",
        "for i, num in enumerate([1000000]):\n",
        "\n",
        "  hyperparams = {\"number_filters\" : params[num],\n",
        "                \"number_params\" : num,\n",
        "                \"kernel_size\" : [],\n",
        "                \"pooling_size\" : [],\n",
        "                \"hidden_layers\": [],\n",
        "                \"epsilon\": 0.01, \n",
        "                \"learning_rate\": 0.01, \n",
        "                \"batch_size\": 32, \n",
        "                \"epochs\": 50,\n",
        "                \"dropout\" : dropouts[i],\n",
        "                \"drop_out_hidden\" : 0\n",
        "                }\n",
        "\n",
        "\n",
        "  model_string = \"cnn_k2c2_0layer\"\n",
        "  model = cnn_k1c2_model(hyperparams)\n",
        "\n",
        "\n",
        "  history = run_experiment(model, model_string, hyperparams)\n",
        "  model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 56.6382 - accuracy: 0.2634WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 22.13.00/models_cnn_k2c2_0layer/assets\n",
            "200/200 [==============================] - 4s 20ms/step - loss: 56.6382 - accuracy: 0.2634 - val_loss: 11.1477 - val_accuracy: 0.2525\n",
            "Epoch 2/50\n",
            "199/200 [============================>.] - ETA: 0s - loss: 1.8561 - accuracy: 0.5427INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 22.13.00/models_cnn_k2c2_0layer/assets\n",
            "200/200 [==============================] - 4s 19ms/step - loss: 1.8550 - accuracy: 0.5426 - val_loss: 2.2871 - val_accuracy: 0.2988\n",
            "Epoch 3/50\n",
            "197/200 [============================>.] - ETA: 0s - loss: 1.1296 - accuracy: 0.6267INFO:tensorflow:Assets written to: /content/drive/My Drive/DD2424Files/Results/20-05-13 22.13.00/models_cnn_k2c2_0layer/assets\n",
            "200/200 [==============================] - 4s 18ms/step - loss: 1.1277 - accuracy: 0.6276 - val_loss: 2.4534 - val_accuracy: 0.3113\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 1.0189 - accuracy: 0.6695 - val_loss: 2.5943 - val_accuracy: 0.2912\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.8784 - accuracy: 0.7205 - val_loss: 2.7028 - val_accuracy: 0.2812\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.8337 - accuracy: 0.7441 - val_loss: 2.8393 - val_accuracy: 0.2688\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.7264 - accuracy: 0.7860 - val_loss: 3.3314 - val_accuracy: 0.2163\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.7150 - accuracy: 0.7949 - val_loss: 4.1846 - val_accuracy: 0.2138\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.7502 - accuracy: 0.7868 - val_loss: 3.7760 - val_accuracy: 0.2338\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.6912 - accuracy: 0.8030 - val_loss: 3.8575 - val_accuracy: 0.2475\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.5967 - accuracy: 0.8340 - val_loss: 5.0105 - val_accuracy: 0.2250\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.6753 - accuracy: 0.8146 - val_loss: 4.8504 - val_accuracy: 0.2587\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.6474 - accuracy: 0.8307 - val_loss: 4.5716 - val_accuracy: 0.2713\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.6180 - accuracy: 0.8346 - val_loss: 5.6205 - val_accuracy: 0.1875\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.6580 - accuracy: 0.8316 - val_loss: 5.3269 - val_accuracy: 0.2000\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.5561 - accuracy: 0.8590 - val_loss: 5.8934 - val_accuracy: 0.2150\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.5803 - accuracy: 0.8502 - val_loss: 5.6170 - val_accuracy: 0.2013\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 3s 15ms/step - loss: 0.7015 - accuracy: 0.8299 - val_loss: 7.3796 - val_accuracy: 0.2300\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.6333 - accuracy: 0.8470 - val_loss: 6.3532 - val_accuracy: 0.1688\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.7145 - accuracy: 0.8431 - val_loss: 8.3393 - val_accuracy: 0.1800\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.6404 - accuracy: 0.8612 - val_loss: 6.1227 - val_accuracy: 0.2163\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.4507 - accuracy: 0.8928 - val_loss: 6.5209 - val_accuracy: 0.2925\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 3s 15ms/step - loss: 0.7824 - accuracy: 0.8506 - val_loss: 7.7168 - val_accuracy: 0.2237\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.6048 - accuracy: 0.8745 - val_loss: 7.8459 - val_accuracy: 0.2587\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.5074 - accuracy: 0.8934 - val_loss: 7.6915 - val_accuracy: 0.2338\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.5534 - accuracy: 0.8854 - val_loss: 7.7520 - val_accuracy: 0.2400\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.7259 - accuracy: 0.8707 - val_loss: 8.3872 - val_accuracy: 0.2700\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 1.1437 - accuracy: 0.8184 - val_loss: 8.8056 - val_accuracy: 0.2575\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.7355 - accuracy: 0.8660 - val_loss: 7.7860 - val_accuracy: 0.2475\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.5312 - accuracy: 0.8942 - val_loss: 8.9924 - val_accuracy: 0.2175\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.7167 - accuracy: 0.8734 - val_loss: 9.9318 - val_accuracy: 0.2200\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.5235 - accuracy: 0.8968 - val_loss: 9.5780 - val_accuracy: 0.2025\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.4015 - accuracy: 0.9214 - val_loss: 10.6314 - val_accuracy: 0.2450\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.5241 - accuracy: 0.9095 - val_loss: 12.2501 - val_accuracy: 0.2100\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.5152 - accuracy: 0.9153 - val_loss: 13.0155 - val_accuracy: 0.1663\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.8781 - accuracy: 0.8760 - val_loss: 13.4849 - val_accuracy: 0.2338\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.9269 - accuracy: 0.8732 - val_loss: 12.8937 - val_accuracy: 0.2163\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.4789 - accuracy: 0.9203 - val_loss: 11.4751 - val_accuracy: 0.2325\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.5519 - accuracy: 0.9107 - val_loss: 11.0116 - val_accuracy: 0.2438\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.6780 - accuracy: 0.9092 - val_loss: 13.5396 - val_accuracy: 0.2338\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.6765 - accuracy: 0.9032 - val_loss: 14.6833 - val_accuracy: 0.2250\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.6390 - accuracy: 0.9126 - val_loss: 14.6017 - val_accuracy: 0.2037\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.7450 - accuracy: 0.9003 - val_loss: 13.9741 - val_accuracy: 0.2438\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.6249 - accuracy: 0.9148 - val_loss: 17.0856 - val_accuracy: 0.1950\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 3s 17ms/step - loss: 0.7857 - accuracy: 0.9034 - val_loss: 15.6028 - val_accuracy: 0.1850\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.6049 - accuracy: 0.9173 - val_loss: 14.7427 - val_accuracy: 0.2463\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.2704 - accuracy: 0.9579 - val_loss: 14.2947 - val_accuracy: 0.2188\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.3894 - accuracy: 0.9376 - val_loss: 16.6542 - val_accuracy: 0.2000\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.5520 - accuracy: 0.9329 - val_loss: 16.1351 - val_accuracy: 0.2438\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 3s 14ms/step - loss: 0.6928 - accuracy: 0.9175 - val_loss: 13.7377 - val_accuracy: 0.2525\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_1 (Batch (None, 96, 1405, 1)       384       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 134880)            0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 1079048   \n",
            "=================================================================\n",
            "Total params: 1,079,432\n",
            "Trainable params: 1,079,240\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEFaa-G8_4xS",
        "colab_type": "text"
      },
      "source": [
        "## Train series of shallow networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbgXvwb1_4IK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shallow networks\n",
        "# Deep k2c1\n",
        "\n",
        "\n",
        "\n",
        "network_index = 1\n",
        "\n",
        "\n",
        "\n",
        "hyperparams = {\"number_filters\" : [43, 43, 87, 87],\n",
        "               \"kernel_size\" : [(96, 4), (1,4), (1,4), (1,4)],\n",
        "               \"pooling_size\" : [(96,4), (1,4), (1,5), (1,4)],\n",
        "               \"hidden_layers\": [70, 70],\n",
        "               \"epsilon\": 0.01, \n",
        "               \"learning_rate\": 0.01, \n",
        "               \"batch_size\": 32, \n",
        "               \"epochs\": 60,\n",
        "               \"dropout\" : 0,\n",
        "               \"drop_out_hidden\" : 0\n",
        "               }\n",
        "\n",
        "\n",
        "model_string = \"cnn_k1c2_deep\"\n",
        "model = cnn_k1c2_model(hyperparams)\n",
        "\n",
        "\n",
        "history = run_experiment(model, model_string, hyperparams)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vALCBwA7C90j",
        "colab_type": "text"
      },
      "source": [
        "## Use test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpd-FttxG3O-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use test data on some models\n",
        "test_X = tf.convert_to_tensor(np.expand_dims(np.load(test_X_path)['arr_0'], -1))\n",
        "test_y = np.load(test_y_path)['arr_0']\n",
        "test_y = tf.one_hot(test_y, 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlfTKxBZEhxp",
        "colab_type": "code",
        "outputId": "01c30f64-066b-4621-ba47-1b95307f218c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "# import model and evaluate on test data\n",
        "\n",
        "date_and_time = \"20-05-12 00.28.22\"\n",
        "date_and_time = \"20-05-12 12.04.17\"\n",
        "custom_name = \"cnn_k1c2\"\n",
        "\n",
        "model_location = \"/content/drive/My Drive/DD2424Files/Results/\" + date_and_time + \"/models_\" + custom_name\n",
        "\n",
        "my_model = tf.keras.models.load_model(model_location)\n",
        "\n",
        "\n",
        "my_model.evaluate(train_X, train_y)\n",
        "my_model.evaluate(val_X, val_y)\n",
        "my_model.evaluate(test_X, test_y)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200/200 [==============================] - 4s 22ms/step - loss: 1.1109 - accuracy: 0.6161\n",
            "25/25 [==============================] - 1s 20ms/step - loss: 1.3616 - accuracy: 0.5575\n",
            "25/25 [==============================] - 1s 20ms/step - loss: 1.5519 - accuracy: 0.4425\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5518596172332764, 0.4424999952316284]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2jnwXsqIEnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP2HqMjojima",
        "colab_type": "text"
      },
      "source": [
        "## The one and only graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQZ3n97iScsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = \"/content/drive/My Drive/DD2424Files/Results/\"\n",
        "test_X = tf.convert_to_tensor(np.expand_dims(np.load(test_X_path)['arr_0'], -1))\n",
        "test_y = np.load(test_y_path)['arr_0']\n",
        "test_y = tf.one_hot(test_y, 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO5JIzk4TVB6",
        "colab_type": "code",
        "outputId": "e2189af2-4a69-454e-b3ee-226c0ce2dadc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Teacher models ensamble\n",
        "\n",
        "params = [2000, 4000, 10000, 50000, 100000, 250000]\n",
        "\n",
        "m = \"/models_cnn_k2c2_deep\"\n",
        "def s(time):\n",
        "  return l + time + m\n",
        "teacher_models = [s(\"20-05-12 20.02.37\"), \n",
        "                  s(\"20-05-12 19.45.54\"), \n",
        "                  s(\"20-05-12 19.28.35\"), \n",
        "                  s(\"20-05-12 19.05.12\"), \n",
        "                  s(\"20-05-12 16.31.06\"), \n",
        "                  s(\"20-05-12 18.28.17\")]\n",
        "\n",
        "my_model = tf.keras.models.load_model(teacher_models[0])\n",
        "val_logits = my_model.predict(val_X)\n",
        "test_logits = my_model.predict(test_X)\n",
        "\n",
        "for i in range(4):\n",
        "  my_model = tf.keras.models.load_model(teacher_models[i+1])\n",
        "  val_logits += my_model.predict(val_X)\n",
        "  test_logits += my_model.predict(test_X)\n",
        "\n",
        "val_acc = tf.keras.metrics.CategoricalAccuracy()\n",
        "val_acc.update_state(val_y, val_logits)\n",
        "\n",
        "test_acc = tf.keras.metrics.CategoricalAccuracy()\n",
        "test_acc.update_state(test_y, test_logits)\n",
        "\n",
        "\n",
        "print(val_acc.result().numpy())\n",
        "print(test_acc.result().numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6275\n",
            "0.515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY7cyE1Tjkl9",
        "colab_type": "code",
        "outputId": "99a17f1c-3e1f-44bd-c11c-2e0115db18e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 40
        }
      },
      "source": [
        "# 5-layer\n",
        "\n",
        "params = [2000, 4000, 10000, 50000, 100000, 250000]\n",
        "\n",
        "m = \"/models_cnn_k2c2_deep\"\n",
        "def s(time):\n",
        "  return l + time + m\n",
        "layer5_models = [s(\"20-05-12 20.02.37\"), \n",
        "                  s(\"20-05-12 19.45.54\"), \n",
        "                  s(\"20-05-12 19.28.35\"), \n",
        "                  s(\"20-05-12 19.05.12\"), \n",
        "                  s(\"20-05-12 16.31.06\"), \n",
        "                  s(\"20-05-12 18.28.17\")]\n",
        "layer5_accs = np.zeros(len(params))\n",
        "layer5_test_accs = np.zeros(len(params))\n",
        "for i, el in enumerate(layer5_models):\n",
        "  my_model = tf.keras.models.load_model(el)\n",
        "  layer5_accs[i] = my_model.evaluate(val_X, val_y, verbose = 0)[1]\n",
        "  layer5_test_accs[i] = my_model.evaluate(test_X, test_y, verbose = 0)[1]\n",
        "\n",
        "print(layer5_accs)\n",
        "print(layer5_test_accs)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5625     0.57375002 0.59750003 0.59625    0.60874999 0.61000001]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mKn_TmR9rWC",
        "colab_type": "code",
        "outputId": "fb735932-9158-4402-a94a-0f557929448d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# 5-layer Student\n",
        "\n",
        "params = [2000, 4000, 10000, 50000, 100000, 250000]\n",
        "\n",
        "m = \"/models_cnn_k2c2_5layerstudent\"\n",
        "def s(time):\n",
        "  return l + time + m\n",
        "layer5s_models = [s(\"20-05-14 20.41.54\"), \n",
        "                  s(\"20-05-14 20.49.27\"), \n",
        "                  s(\"20-05-14 20.57.19\"), \n",
        "                  s(\"20-05-14 21.06.12\"), \n",
        "                  s(\"20-05-14 21.16.56\"), \n",
        "                  s(\"20-05-14 22.05.53\")]\n",
        "layer5s_accs = np.zeros(len(params))\n",
        "layer5s_test_accs = np.zeros(len(params))\n",
        "for i, el in enumerate(layer5s_models):\n",
        "  my_model = tf.keras.models.load_model(el)\n",
        "  layer5s_accs[i] = my_model.evaluate(val_X, val_y, verbose = 0)[2]\n",
        "  layer5s_test_accs[i] = my_model.evaluate(test_X, test_y, verbose = 0)[2]\n",
        "\n",
        "print(layer5s_accs)\n",
        "print(layer5s_test_accs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.54250002 0.54750001 0.60624999 0.62       0.63499999 0.62625003]\n",
            "[0.45875001 0.45750001 0.49250001 0.495      0.50875002 0.49375001]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygMf2Wm0WJzj",
        "colab_type": "code",
        "outputId": "bae3e87b-812b-4bce-deaa-fe0c3763417f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# 4-layer\n",
        "\n",
        "layer4_params = [2000, 4000, 10000, 50000, 100000, 250000]\n",
        "m = \"/models_cnn_k2c2_4layer\" \n",
        "def s(time):\n",
        "  return l + time + m\n",
        "layer4_models = [s(\"20-05-12 21.50.51\"), \n",
        "                  s(\"20-05-12 22.23.42\"), \n",
        "                  s(\"20-05-12 22.57.53\"), \n",
        "                  s(\"20-05-13 08.48.32\"),\n",
        "                  s(\"20-05-13 14.18.47\"),\n",
        "                  s(\"20-05-13 15.40.46\")]\n",
        "layer4_accs = np.zeros(len(layer4_params))\n",
        "layer4_test_accs = np.zeros(len(layer4_params))\n",
        "for i, el in enumerate(layer4_models):\n",
        "  my_model = tf.keras.models.load_model(el)\n",
        "  layer4_accs[i] = my_model.evaluate(val_X, val_y, verbose = 0)[1]\n",
        "  layer4_test_accs[i] = my_model.evaluate(test_X, test_y, verbose = 0)[1]\n",
        "\n",
        "print(layer4_accs)\n",
        "print(layer4_test_accs)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5625     0.56999999 0.58375001 0.5675     0.57999998 0.59750003]\n",
            "[0.46625    0.46125001 0.48374999 0.46000001 0.48500001 0.45249999]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ON1AND-9-KN",
        "colab_type": "code",
        "outputId": "e335afa7-7c01-438d-d9ab-e81a0864f7bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# 4-layer Student\n",
        "\n",
        "layer4s_params = [2000, 4000, 10000, 50000, 100000, 250000]\n",
        "m = \"/models_cnn_k2c2_4layerstudent\" \n",
        "def s(time):\n",
        "  return l + time + m\n",
        "layer4s_models = [s(\"20-05-14 19.33.34\"), \n",
        "                  s(\"20-05-14 19.41.08\"), \n",
        "                  s(\"20-05-14 19.48.56\"), \n",
        "                  s(\"20-05-14 19.57.31\"),\n",
        "                  s(\"20-05-14 20.08.46\"),\n",
        "                  s(\"20-05-14 20.22.24\")]\n",
        "layer4s_accs = np.zeros(len(layer4s_params))\n",
        "layer4s_test_accs = np.zeros(len(layer4s_params))\n",
        "for i, el in enumerate(layer4s_models):\n",
        "  my_model = tf.keras.models.load_model(el)\n",
        "  layer4s_accs[i] = my_model.evaluate(val_X, val_y, verbose = 0)[2]\n",
        "  layer4s_test_accs[i] = my_model.evaluate(test_X, test_y, verbose = 0)[2]\n",
        "\n",
        "print(layer4s_accs)\n",
        "print(layer4s_test_accs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.53625    0.59375    0.59249997 0.62       0.62625003 0.61624998]\n",
            "[0.42250001 0.46000001 0.4675     0.47999999 0.49875    0.48875001]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUDUsX8dT-BT",
        "colab_type": "code",
        "outputId": "22ab1303-6049-4ddf-8a0a-988abd850ec3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 40
        }
      },
      "source": [
        "# 3-layer\n",
        "\n",
        "layer3_params = [2000, 4000, 10000, 50000, 100000, 250000]\n",
        "m = \"/models_cnn_k2c2_4layer\" #mistake\n",
        "def s(time):\n",
        "  return l + time + m\n",
        "layer3_models = [s(\"20-05-12 23.43.45\"), \n",
        "                  s(\"20-05-13 00.04.28\"), \n",
        "                  s(\"20-05-13 00.26.51\"), \n",
        "                  s(\"20-05-13 00.54.11\"),\n",
        "                  s(\"20-05-13 01.39.53\"),\n",
        "                  s(\"20-05-13 02.50.07\")]\n",
        "layer3_accs = np.zeros(len(layer3_params))\n",
        "layer3_test_accs = np.zeros(len(layer3_params))\n",
        "for i, el in enumerate(layer3_models):\n",
        "  my_model = tf.keras.models.load_model(el)\n",
        "  layer3_accs[i] = my_model.evaluate(val_X, val_y, verbose = 0)[1]\n",
        "  layer3_test_accs[i] = my_model.evaluate(test_X, test_y, verbose = 0)[1]\n",
        "\n",
        "print(layer3_accs)\n",
        "print(layer3_test_accs)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.44       0.47749999 0.505      0.50749999 0.50375003 0.51749998]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X9DCf2TCREc",
        "colab_type": "code",
        "outputId": "9cdb21f3-330c-4795-c6d7-36bb20bd1f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# 3-layer student\n",
        "\n",
        "layer3s_params = [2000, 4000, 10000, 50000, 100000, 250000]\n",
        "m = \"/models_cnn_k2c2_3layer_student\"\n",
        "def s(time):\n",
        "  return l + time + m\n",
        "layer3s_models = [s(\"20-05-14 16.08.51\"), \n",
        "                  s(\"20-05-14 16.21.43\"), \n",
        "                  s(\"20-05-14 16.35.28\"), \n",
        "                  s(\"20-05-14 16.50.06\"),\n",
        "                  s(\"20-05-14 17.09.35\"),\n",
        "                  s(\"20-05-14 17.33.59\")]\n",
        "layer3s_accs = np.zeros(len(layer3s_params))\n",
        "layer3s_test_accs = np.zeros(len(layer3s_params))\n",
        "for i, el in enumerate(layer3s_models):\n",
        "  my_model = tf.keras.models.load_model(el)\n",
        "  layer3s_accs[i] = my_model.evaluate(val_X, val_y, verbose = 0)[2]\n",
        "  layer3s_test_accs[i] = my_model.evaluate(test_X, test_y, verbose = 0)[2]\n",
        "\n",
        "print(layer3s_accs)\n",
        "print(layer3s_test_accs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.36875001 0.51749998 0.57499999 0.625      0.61874998 0.62124997]\n",
            "[0.31874999 0.40625    0.47       0.51125002 0.49000001 0.50749999]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBydkkQcLH-N",
        "colab_type": "code",
        "outputId": "20cf79d2-e2cc-4678-cef3-88e1d96d8b94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# 3-layer student 2\n",
        "\n",
        "layer3s2_params = [2000, 2000, 4000, 10000, 50000, 100000, 250000]\n",
        "m = \"/models_cnn_k2c2_3layer_student\"\n",
        "def s(time):\n",
        "  return l + time + m\n",
        "layer3s2_models = [s(\"20-05-15 20.40.25\"),\n",
        "                  s(\"20-05-15 21.08.37\"), \n",
        "                  s(\"20-05-15 21.28.31\"), \n",
        "                  s(\"20-05-15 21.49.27\"), \n",
        "                  s(\"20-05-15 22.15.58\"),\n",
        "                  s(\"20-05-15 23.00.11\"),\n",
        "                  s(\"20-05-16 00.07.14\")]\n",
        "layer3s2_accs = np.zeros(len(layer3s2_params))\n",
        "layer3s2_test_accs = np.zeros(len(layer3s2_params))\n",
        "for i, el in enumerate(layer3s2_models):\n",
        "  my_model = tf.keras.models.load_model(el)\n",
        "  layer3s2_accs[i] = my_model.evaluate(val_X, val_y, verbose = 0)[2]\n",
        "  layer3s2_test_accs[i] = my_model.evaluate(test_X, test_y, verbose = 0)[2]\n",
        "\n",
        "print(\"layer3s2_accs= \" + str(layer3s2_accs))\n",
        "print(\"layer3s2_test_accs= \" + str(layer3s2_test_accs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer3s2_accs= [0.43000001 0.36375001 0.46000001 0.60374999 0.62875003 0.61750001\n",
            " 0.61750001]\n",
            "layer3s2_test_accs= [0.35374999 0.34875    0.4025     0.44999999 0.50749999 0.47874999\n",
            " 0.50875002]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWccNDldSZg5",
        "colab_type": "code",
        "outputId": "e826df38-489e-415a-d6a6-4f9f49c8142e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 40
        }
      },
      "source": [
        "# 2-layer\n",
        "\n",
        "layer2_params = [17000, 50000, 100000, 250000]\n",
        "m = \"/models_cnn_k2c2_2layer\"\n",
        "def s(time):\n",
        "  return l + time + m\n",
        "layer2_models = [s(\"20-05-13 05.14.59\"), \n",
        "                  s(\"20-05-13 05.34.11\"), \n",
        "                  s(\"20-05-13 05.54.46\"), \n",
        "                  s(\"20-05-13 06.17.00\")]\n",
        "layer2_accs = np.zeros(len(layer2_params))\n",
        "layer2_test_accs = np.zeros(len(layer2_params))\n",
        "for i, el in enumerate(layer2_models):\n",
        "  my_model = tf.keras.models.load_model(el)\n",
        "  layer2_accs[i] = my_model.evaluate(val_X, val_y, verbose = 0)[1]\n",
        "  layer2_test_accs[i] = my_model.evaluate(test_X, test_y, verbose = 0)[1]\n",
        "\n",
        "print(layer2_accs)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.36000001 0.38124999 0.4375     0.42250001]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip_guPHnPHyp",
        "colab_type": "code",
        "outputId": "24f3c92b-1804-4505-ecf5-55aade432ce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# 2-layer student\n",
        "\n",
        "layer2s_params = [17000, 50000, 100000, 250000]\n",
        "m = \"/models_cnn_k2c2_2layer\"\n",
        "def s(time):\n",
        "  return l + time + m\n",
        "layer2s_models = [s(\"20-05-14 14.35.07\"), \n",
        "                  s(\"20-05-14 14.47.50\"), \n",
        "                  s(\"20-05-14 14.15.31\"), \n",
        "                  s(\"20-05-14 15.01.01\")]\n",
        "layer2s_accs = np.zeros(len(layer2s_params))\n",
        "layer2s_test_accs = np.zeros(len(layer2s_params))\n",
        "for i, el in enumerate(layer2s_models):\n",
        "  my_model = tf.keras.models.load_model(el)\n",
        "  layer2s_accs[i] = my_model.evaluate(val_X, val_y, verbose = 0)[2]\n",
        "  layer2s_test_accs[i] = my_model.evaluate(test_X, test_y, verbose = 0)[2]\n",
        "\n",
        "print(layer2s_accs)\n",
        "print(layer2s_test_accs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.44999999 0.44624999 0.53874999 0.55000001]\n",
            "[0.34875    0.38124999 0.3775     0.4025    ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8sr1c3I-fJw",
        "colab_type": "code",
        "outputId": "1441fd6a-72c9-48f1-8882-7f1a9363bb35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "# 1-layer\n",
        "\n",
        "layer1_params = [135000, 270000]\n",
        "m = \"/models_cnn_k2c2_2layer\"\n",
        "def s(time):\n",
        "  return l + time + m\n",
        "layer1_models = [s(\"20-05-13 17.02.22\"), \n",
        "                  s(\"20-05-13 17.10.29\")]\n",
        "layer1_accs = np.zeros(len(layer1_params))\n",
        "layer1_test_accs = np.zeros(len(layer1_params))\n",
        "for i, el in enumerate(layer1_models):\n",
        "  my_model = tf.keras.models.load_model(el)\n",
        "  layer1_accs[i] = my_model.evaluate(val_X, val_y, verbose = 0)[1]\n",
        "  layer1_test_accs[i] = my_model.evaluate(test_X, test_y, verbose = 0)[1]\n",
        "\n",
        "print(layer1_accs)\n",
        "print(layer1_test_accs)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.31375    0.35249999]\n",
            "[0.26875001 0.30000001]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fWraE-T82BB",
        "colab_type": "code",
        "outputId": "9c5780bf-ef64-40f1-a23b-2266b1ad5ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# 1-layer student\n",
        "\n",
        "layer1s_params = [135000, 270000]\n",
        "m = \"/models_cnn_k2c2_1layerstudent\"\n",
        "def s(time):\n",
        "  return l + time + m\n",
        "layer1s_models = [s(\"20-05-14 19.21.55\"), \n",
        "                  s(\"20-05-14 19.27.38\")]\n",
        "layer1s_accs = np.zeros(len(layer1s_params))\n",
        "layer1s_test_accs = np.zeros(len(layer1s_params))\n",
        "for i, el in enumerate(layer1s_models):\n",
        "  my_model = tf.keras.models.load_model(el)\n",
        "  layer1s_accs[i] = my_model.evaluate(val_X, val_y, verbose = 0)[2]\n",
        "  layer1s_test_accs[i] = my_model.evaluate(test_X, test_y, verbose = 0)[2]\n",
        "\n",
        "print(layer1s_accs)\n",
        "print(layer1s_test_accs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.33250001 0.42250001]\n",
            "[0.28874999 0.30250001]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W2W0Rf1UxTa",
        "colab_type": "code",
        "outputId": "938f97a2-4ebc-4e38-b114-0819ebd57cec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "# 1'-layer\n",
        "\n",
        "layer1mod_params = [135000, 270000, 1000000]\n",
        "m = \"/models_cnn_k2c2_1modlayer\"\n",
        "def s(time):\n",
        "  return l + time + m\n",
        "layer1mod_models = [s(\"20-05-13 22.56.07\"), \n",
        "                  s(\"20-05-13 23.01.54\"), s(\"20-05-13 23.08.09\")]\n",
        "layer1mod_accs = np.zeros(len(layer1mod_params))\n",
        "layer1mod_test_accs = np.zeros(len(layer1mod_params))\n",
        "for i, el in enumerate(layer1mod_models):\n",
        "  my_model = tf.keras.models.load_model(el)\n",
        "  layer1mod_accs[i] = my_model.evaluate(val_X, val_y, verbose = 0)[1]\n",
        "  layer1mod_test_accs[i] = my_model.evaluate(test_X, test_y, verbose = 0)[1]\n",
        "\n",
        "print(layer1mod_accs)\n",
        "print(layer1mod_test_accs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.35624999 0.4025     0.39875001]\n",
            "[0.29374999 0.31625    0.32124999]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6M6fA4qHKnn",
        "colab_type": "code",
        "outputId": "ee115d0e-ccb1-4bd9-8a7a-acab1eb73b72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "# 0-layer\n",
        "\n",
        "layer0_params = [1000000]\n",
        "m = \"/models_cnn_k2c2_0layer\"\n",
        "def s(time):\n",
        "  return l + time + m\n",
        "layer0_models = [s(\"20-05-13 22.13.00\")]\n",
        "layer0_accs = np.zeros(len(layer0_params))\n",
        "layer0_test_accs = np.zeros(len(layer0_params))\n",
        "for i, el in enumerate(layer0_models):\n",
        "  my_model = tf.keras.models.load_model(el)\n",
        "  layer0_accs[i] = my_model.evaluate(val_X, val_y, verbose = 0)[1]\n",
        "  layer0_test_accs[i] = my_model.evaluate(test_X, test_y, verbose = 0)[1]\n",
        "\n",
        "print(layer0_accs)\n",
        "print(layer0_test_accs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.31125]\n",
            "[0.255]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IokZybI6hvhu",
        "colab_type": "code",
        "outputId": "783ef136-fa4c-4a25-a0fb-52caf92f2c8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# 0-layer student\n",
        "\n",
        "layer0s_params = [1000000]\n",
        "m = \"/models_cnn_k2c2_0layerstudent\"\n",
        "def s(time):\n",
        "  return l + time + m\n",
        "layer0s_models = [s(\"20-05-14 18.38.47\")]\n",
        "layer0s_accs = np.zeros(len(layer0s_params))\n",
        "layer0s_test_accs = np.zeros(len(layer0s_params))\n",
        "for i, el in enumerate(layer0s_models):\n",
        "  my_model = tf.keras.models.load_model(el)\n",
        "  layer0s_accs[i] = my_model.evaluate(val_X, val_y, verbose = 0)[2]\n",
        "  layer0s_test_accs[i] = my_model.evaluate(test_X, test_y, verbose = 0)[2]\n",
        "\n",
        "print(layer0s_accs)\n",
        "print(layer0s_test_accs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.30000001]\n",
            "[0.23]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2IiEuhn8q0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ensemble_accs = [0.6275]\n",
        "ensemble_test_accs = [0.515]\n",
        "\n",
        "layer5_accs = [0.5625, 0.57375002, 0.59750003, 0.59625, 0.60874999, 0.61000001]\n",
        "layer5_test_accs = [0.47999999, 0.43625, 0.49000001, 0.4675, 0.50375003, 0.46250001]\n",
        "layer5_params = [2000, 4000, 10000, 50000, 100000, 250000]\n",
        "\n",
        "layer4_accs = [0.5625, 0.56999999, 0.58375001, 0.5675, 0.57999998, 0.59750003]\n",
        "layer4_test_accs = [0.46625, 0.46125001, 0.48374999, 0.46000001, 0.48500001, 0.45249999]\n",
        "layer4_params = [2000, 4000, 10000, 50000, 100000, 250000]\n",
        "\n",
        "layer3_accs = [0.44, 0.47749999, 0.505, 0.50749999, 0.50375003, 0.51749998]\n",
        "layer3_test_accs = [0.40000001, 0.41, 0.39125001, 0.38999999, 0.39125001, 0.41125]\n",
        "layer3_params = [2000, 4000, 10000, 50000, 100000, 250000]\n",
        "\n",
        "layer2_accs = [0.36000001, 0.38124999, 0.4375, 0.42250001]\n",
        "layer2_test_accs = [0.33500001, 0.33375001, 0.33125001, 0.34]\n",
        "layer2_params = [17000, 50000, 100000, 250000]\n",
        "\n",
        "layer1_accs = [0.31375, 0.35249999]\n",
        "layer1_test_accs = [0.26875001, 0.30000001]\n",
        "layer1_params = [135000, 270000]\n",
        "\n",
        "layer1mod_accs = [0.35624999, 0.4025, 0.39875001]\n",
        "layer1mod_test_accs = [0.29374999, 0.31625, 0.32124999]\n",
        "layer1mod_params = [135000, 270000, 1000000]\n",
        "\n",
        "layer0_accs =  [0.31125]\n",
        "layer0_test_accs = [0.255]\n",
        "layer0_params = [1000000]\n",
        "\n",
        "# Students\n",
        "layer5s_accs = [0.54250002, 0.54750001, 0.60624999, 0.62, 0.63499999, 0.62625003]\n",
        "layer5s_test_accs = [0.45875001, 0.45750001, 0.49250001, 0.495, 0.50875002, 0.49375001]\n",
        "layer5s_params = [2000, 4000, 10000, 50000, 100000, 250000]\n",
        "\n",
        "layer4s_accs = [0.53625, 0.59375, 0.59249997, 0.62, 0.62625003, 0.61624998]\n",
        "layer4s_test_accs = [0.42250001, 0.46000001, 0.4675, 0.47999999, 0.49875, 0.48875001]\n",
        "layer4s_params = [2000, 4000, 10000, 50000, 100000, 250000]\n",
        "\n",
        "layer3s_accs = [0.36875001, 0.51749998, 0.57499999, 0.625, 0.61874998, 0.62124997]\n",
        "layer3s_test_accs = [0.31874999, 0.40625, 0.47, 0.51125002, 0.49000001, 0.50749999]\n",
        "layer3s_params = [2000, 4000, 10000, 50000, 100000, 250000]\n",
        "\n",
        "layer3s2_accs= [0.43000001, 0.36375001, 0.46000001, 0.60374999, 0.62875003, 0.61750001, 0.61750001]\n",
        "layer3s2_test_accs= [0.35374999, 0.34875, 0.4025, 0.44999999, 0.50749999, 0.47874999, 0.50875002]\n",
        "layer3s2_params = [2000, 2000, 4000, 10000, 50000, 100000, 250000]\n",
        "\n",
        "layer2st_accs = [0.50625002, 0.50625002, 0.50625002, 0.50625002]\n",
        "layer2st_test_accs = [0.40625, 0.40625, 0.40625, 0.40625]\n",
        "layer2st_params = [17000, 50000, 100000, 250000]\n",
        "\n",
        "layer2s_accs = [0.44999999, 0.44624999, 0.53874999, 0.55000001]\n",
        "layer2s_test_accs = [0.34875, 0.38124999, 0.3775, 0.4025]\n",
        "layer2s_params = [17000, 50000, 100000, 250000]\n",
        "\n",
        "layer1s_accs = [0.33250001, 0.42250001]\n",
        "layer1s_test_accs = [0.28874999, 0.30250001]\n",
        "layer1s_params = [135000, 270000]\n",
        "\n",
        "layer0s_accs = [0.30000001]\n",
        "layer0s_test_accs = [0.23]\n",
        "layer0s_params = [1000000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKIobjQ5HKjO",
        "colab_type": "text"
      },
      "source": [
        "##Plot test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmeAJ3IWl4Cd",
        "colab_type": "code",
        "outputId": "e9e925e5-9147-4320-d67d-a87ef5405358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.figure(1)\n",
        "\n",
        "plt.semilogx([0, 1000000], [ensemble_test_accs, ensemble_test_accs], '--y', label = \"Ensemble Test Acc\")\n",
        "\n",
        "plt.semilogx(layer5_params, layer5_test_accs, 'x-b', label = \"5-layer Test Acc\")\n",
        "plt.semilogx(layer5s_params, layer5s_test_accs, '*--b', label = \"5-layer Student Test Acc\")\n",
        "\n",
        "plt.semilogx(layer4_params, layer4_test_accs, 'x-k', label = \"4-Layer Test Acc\")\n",
        "plt.semilogx(layer4s_params, layer4s_test_accs, '*--k', label = \"4-Layer Student Test Acc\")\n",
        "\n",
        "plt.semilogx(layer3_params, layer3_test_accs, 'x-r', label = \"3-Layer Test Acc\")\n",
        "plt.semilogx(layer3s_params, layer3s_test_accs, '*--r', label = \"3-Layer Student Test Acc\")\n",
        "plt.semilogx(layer3s2_params, layer3s2_test_accs, 'x--r', label = \"3-Layer Student2 Test Acc\")\n",
        "\n",
        "plt.semilogx(layer2_params, layer2_test_accs, 'x-g', label = \"2-Layer Test Acc\")\n",
        "plt.semilogx(layer2s_params, layer2s_test_accs, '*--g', label = \"2-Layer Student Test Acc\")\n",
        "#plt.semilogx(layer2st_params[2], layer2st_test_accs[2], '*--g', label = \"2-Layer Student special Test Acc\")\n",
        "\n",
        "plt.semilogx(layer1_params, layer1_test_accs, 'x-c', label = \"1-Layer Test Acc\")\n",
        "plt.semilogx(layer1s_params, layer1s_test_accs, '*--c', label = \"1-Layer Student Test Acc\")\n",
        "#plt.semilogx(layer1mod_params, layer1mod_test_accs, '*-y', label = \"1'-Layer more filters Test Acc\")\n",
        "\n",
        "plt.semilogx(layer0_params, layer0_test_accs, 'x-m', label = \"0-Layer Test Acc\")\n",
        "plt.semilogx(layer0s_params, layer0s_test_accs, '*--m', label = \"0-Layer Student Test Acc\")\n",
        "\n",
        "plt.xlabel(\"Nr of params\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(loc = \"upper right\", bbox_to_anchor = [1.5, 1])\n",
        "#plt.xlim([1000, 30000000])\n",
        "plt.savefig(l+\"Student_test\", dpi = 300, bbox_inches = \"tight\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAEKCAYAAAA8dH4YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd1QUVxvGn9mldwSkKyi9yKcEMHawomDDhsYodiyxGxtosLdoNLZoNMGCYotiiw17AURFkEVEUWCRIt0Ftt3vj8siICCoqNH5nTNn3Sl37syuzLNvZQghYGFhYWFhYWH5EuF87gmwsLCwsLCwsNQEK1RYWFhYWFhYvlhYocLCwsLCwsLyxcIKFRYWFhYWFpYvFlaosLCwsLCwsHyxsEKFhYWFhYWF5YtF7nNP4GOhq6tLzMzMPvc0WFhYWP5T3L17N5sQove558HCUhNfjVAxMzNDVFTU554GCwsLy38KhmGef+45sLDUBuv6YWFhYWFhYfliYYUKCwsLCwsLyxcLK1RYWFhYWFhYvli+mhgVFhYWFpa6IRKJkJqaipKSEpw/f97xwYMHyZ97TizfNFIAsWKxeIyzs3Nm1Y2sUGFhYWH5xkhNTYW6ujrMzMwgkUjEDg4O2Z97TizfLlKplMnKyrJ7+fLlTgC9q25nXT8sLCws3xglJSXQ0dEBwzCfeyosLOBwOERPTy8fgEN1278ai4pAkIB79zrBwmID1NX/h5ycC3j+fOlb+1lbb4eKijWys8OQkrLure22tnugpGSKzMyDSEvb+tZ2e/vDUFDQRXr6X3j58q+3trdocRpcrgrS0rYgMzP0re0tW14GALx4sRavXp2stI3LVUaLFmcAAMnJS5Cbe7HSdnl5HTg4HAEAPH06D/n5typtV1Q0gZ3dXgBAYuI0FBXdr7RdRcUK1tZ/AAASEsZBIHhcabua2v9gabkBAPDo0Q8oLU2ttF1T83s0a7YCABAb6wOR6FWl7dranWFmFgAAiInxhERSXGm7jo4XmjSZBQC4d68TqtK48SAYG0+ERCJATEzPt7YbGIyEoeFICIXZiIsb8NZ2Y2N/NG48GCUlKYiPH/7WdlPTmdDV9YZAkICEhPFvbW/adCEaNeqCwsL7ePJk2lvbmzVbDk3NNsjPv4mnT+e/tZ397rHfvc/13ZN9tvWBFSksXxIcDoegBuMJa1FhYfkMyGWVwmLMfchlCz/3VFhYPgtcLtfZxsbGTrbMnz/f4FPPYcaMGUaBgYH6VdcnJCQoWFpa2tdljJcvX3Jl16Crq+vUuHHjFrL3JSUldVKDJ0+eVD9//rxqbft06dKluZOTk01dxvvaYAghn3sOH4XvvvuOsAXfWP4zTJwIbN8OjB8PbNnyuWfD8o0RHx8PW1tbAEBsbKzAwcEh/lPPQUVFpaVAILj3qc9bkRkzZhipqalJgoKCMiquT0hIUPDy8rJMTEyM+xjjfehx2dnZXAcHB3sVFRXJyZMnE+3s7L7KXzgPHjzQdXJyMqu6nrWosLB8SpSVAYYBtm4FpFL6yjB0/WcgPR3o2BF4+fKznL5+rF4NhIdXXhceTtezfDUYGxs7Tp8+3cjOzs7WysrK7t69e0oAcOrUKTWZpcLW1tYuNzeXAwABAQH6Dg4OtlZWVnbTp083AqjQMDc3t/fx8TEzMzNz6N27t/k///yj3qpVK5umTZs6hIeHq8jOFxMTo/K///3PpmnTpg7r1q3TrTofsViM8ePHm8jOsWbNmrf2qY5r166puLi4WNvb29u2a9fO8vnz5/IAsHTp0sbNmze3t7KysvPy8mqWkJCgEBwcrLdt2zZ9Gxsbu7Nnz6pVHWvv3r1aXbp0yevXr19OcHBwI9n62NhYxTZt2lhZW1vb2dnZ2cbFxSkCwIIFCwysrKzsrK2t7SZOnGhcv0/gy+OriVFhYfmiKSykgmTmTODoUSC+wg9YVVWqFsRiQO7T/pdcsgS4fh0ICvoPGHZcXIBBg6i427QJ+OknYMIEIPTteByW+nH3rqt11XW6uv1zmjadmyUWF3IePOhsWXW7vv4P2SYmP70qLU2Xi43t07ziNmfniIR3nbO0tJRjY2NjJ3s/c+bM9LFjx+bSc+uKHz16FL9y5Uq9lStX6h88ePD5unXrDDZu3Pi8W7dur/Pz8zkqKirSo0ePajx58kQpJiYmnhCCLl26WJw5c0atWbNmwpSUFKWDBw8+dXZ2Tm7RooXtvn37dKKionj79+/XWrZsmaG7u3sSAMTHxyvfvXs3vrCwkNuyZUs7Hx+f/Irz3LBhg66mpqYkNjY2vri4mHFxcbHx9vYusLGxqdGqUVpayvz0009NTp069cTIyEi8Y8cO7VmzZhkfOnQoeePGjQbPnz9/qKysTLKzs7m6urqSH3/8Mas2i0poaGijwMDAdCMjI9GAAQOar1y58iUADB061HzWrFkvf/zxxzyBQMBIJBImNDRU4/Tp01p3797lqaurSzMyMrjv+iy+dFihwsLSUIjFwPnzwN69wLFjwIoVQOfOwLqyQFolJaCkBBAIgEePAG7Z35PXr6l4acBpqakBpaVv1m3dShcFBSAv77MZeGrH3Z2Kku7dAZEIiIgATp+m61n+cygqKkp5PN6j6rYNHTo0FwBcXV0FJ06c0AaA1q1bF82aNct00KBBOb6+vrnNmzeXnj17VuPq1asadnZ2dgAgEAg4PB5PqVmzZkJjY+NSV1fXYgCwsrIq9vDwKOBwOGjVqpVg6dKlRrJzeXp65qmpqRE1NTXx999/X3Dt2jVVV1dXgWz7hQsXNHg8nopsHoWFhdxHjx4p1SZUYmJiFBMTE5U9PDysAEAqlUJPT08EANbW1sX9+vUz7927d96wYcPy3nWfUlJS5J4/f67UrVu3Ig6HAzk5ORIZGalkYWEhzMjIUPjxxx/zAEBFRYUAIOfPn9f44YcfstXV1aUAoK+vL3nXOb50WKHCwvKxkUqBOXOoQMnIALS1gREjgA4dgP/9D3BwAGJjgR9/BHbvBpydgePHqcWlsBAwNwe6dAGmTgVat6brP5C0NODff4GzZ6l2srYG9PSAW7eoTmIYgBBAKAQ0NYFdu4AffqDbioqAxo0/wn15X4RCYMMGYP58QFLhb25JCeDhQQVfcXHNx7O8k9osIHJy6tLatisqGorrYkGpD0pKSoSeW46IxWIGAJYvX/6yb9+++cePH9ds3769zalTpxIJIZg2bVr67NmzK9WBSUhIUFBQUCgPwORwOOVjcrlcSCSS8v9UVbOfqr4nhDDr1q174ePjU1DX+RNCGAsLi+L79+/zqm4LDw9PPHPmjPrx48c1165da5iQkFBrHExwcHCjgoICrqmpqSMAFBUVcYODg3WCgoLS6zqf/zpsjAoLy8cgJeWNC4LDoUKkbVtqSUlPp36V7GygTRsgIQGYPBn44w9qGXjxgqoHQuj7kSOpomjTBnBzA/bvpw/reiCVvvl3796AiQkwejRw8ybg4wMMGUJdPsXF9DkPAIqKwLJlwIwZVE8BdBr6+oCVFTBqFPDnnwCPR6fa4BQVAcOHAyoqwM8/U5Eim6yMzp2BZ88+wWRYPjdxcXGKrq6uxcuWLXvZokWL17GxsUqenp4Fe/bs0c3Pz+cAwLNnz+TT0tLq9QP8zJkzWgKBgHn58iX39u3b6u3atXtdcXvXrl3zt27dqldaWsoA1FpSUFBQ67OzRYsWJTk5OXIXLlxQBagrKCoqSkkikSApKUnB29u7cPPmzWlFRUXc/Px8rrq6uqSwsLBaF83hw4cbHTt2LDEtLe1hWlrawzt37jz6559/tLW1taUGBgbCPXv2aAFAcXExU1hYyOnevXvB3r17dQsLCzkA8DW4fhpUqDAM04NhmASGYZ4wDDO3mu0jGYbJYhjmftkypsK2EQzDJJYtIxpyniws70VBATU9uLsDTZsCw4YBubl02+nTwJEjQJ8+wI0bQPv2QLdu1LQxZgzw119AQACgpUX9MD/8QPd5/hxYuxZITQU2bwby8+m4Dx/ScWtRCElJ9BBvb6BZszfGh27daLxpTAzVUzt3AvPm0ZAPeXn6qqBAX+fPB1aupEYfAHByAlatAmxtgRMn6NRtbYEnT+j2Bw/o5VV0I70XpaXApUt0Yt99B0yfDjRpQq1S2trApEnAnj10X4ahgoVh6MnjP3nCCstHQBajIlveFfS5evXqxpaWlvZWVlZ28vLyZMCAAfn9+/cvGDhwYI6Li4uNlZWVXb9+/Zrn5eXV68Fsa2sraNOmjbWbm5vtrFmz0s3MzEQVt0+fPj3bxsamxNHR0dbS0tJ+7NixTUUiUa1mTiUlJXLgwIGkuXPnmlhbW9vZ29vbXblyRU0sFjNDhw41t7KysnNwcLAbM2ZMpq6ursTHxyfv1KlTWlWDaRMSEhTS0tIUPDw8ysWTjY2NUF1dXXLp0iXVvXv3Ptu8eXNjKysru++++84mJSVFbsCAAQWenp55//vf/2xtbGzslixZ8snTvj82DZaezDAMF8BjAF0BpAKIBOBLCHlUYZ+RAL4jhEyucmwjAFEAvgNAANwF4EwIya3pfGx6Mssn5dgxYOhQ6n6wsKC//H/4gSqEisTHA3Z2gJERsGAB0Lw53S80lAqc8HAaIDpyJPD333S81FRAQ4MeL5VS/0zbtvS9vz99qE+dSlUEaGzuzz+/EQ/NmgGensDy5W+GqQoh1Os0fjyNWdHVpd6nNm1qvmRCqDHozh3qtWKYN9OWCZ22bYF27QAvrzp6rF68oJO4coWad7hcOglra2qB+vln6v4CqNoKCwNatADGjaMWqZgYqszmzKnDyVhkfAnpySwsVakpPbkhY1RcATwhhDwFAIZhDgDoA6Da4KkqdAdwnhCSU3bseQA9AIQ00FxZWGqGEODuXfrrvmtXoFcvoFUr6gsZPpy6Zyo+la9fByIjqVXA1pYqgG7dqBVg9eo3IgV4EyAaGQk8fkxfNTToOY8cAfr2LRcphACvBMrQDAmG/O7dyG/VCZoBU6Gl7g1ray6mTgV69KC6qTYKC2myzP79gJxcOnR0huDVq4No29YAEyfSmN/qBA7DADY2dJGxZg2d4o0bdFm/nl6utzfd/vvv1GDUti1goZoO5sJ56uZq1YreH11dagoyMaGvu3fTe0rI20pnzpzKgmTz5jp+gCwsLP9lGtL1YwwgpcL71LJ1VfFhGCaGYZjDDMOY1vNYFpaG4/lzapaws6Pmgq1bgbiyuLemTemDsmKw661bVJC0b08ze16XWWt7934TWzFnzttZKu7udL2WFhVCAHWDDBwIODsj7/gVjBlDPSF6wb+isSgV6/RXQyHlKdCvHzyuB+HkSRr28i6Rcu8e1QghITT0w9NzCXJzr6NHjyAoKdFQGjs76uapC3p6VKisWUPjX/LzqdFDxm+/AS/8AlFi5QjG2AgYMQIlx8/S1KILF+jBiYk06HjWLBpEDHyUAGIWFpavg88dTBsGwIwQ0gLAeQB/1+dghmHGMQwTxTBMVFZWVoNMkOUbQ1TBPd2jB3XX6OlRN0NGRvUuhsRE6mtp0wa4f5/GmDx+XGuKcU2F1qRSICoKWHrTA+fGHQby8qDVtxO89w9BT8cU7NgBPEzRxsyXs6HMTwIOH6b+F4C6TyZPpueuAiHUutG6NfWwcDhKEAgYhIVthVQqxZkzW1FSwoDDUQCwE336XEfv3lng8+vhGpZKofzoLiyPrATGjgVAXUVTu8VD20YfB1qtgrdxNALHZQCBgZD6T0T2lVicdV+FcztfIHfuKsDQsO7nY2Fh+SZoSKGSBsC0wnuTsnXlEEJeEUJkYXg7ATjX9diy4/8ghHxHCPlOT0/vo02c5RtDJKJmgMGDqdmipISu37EDePoUuHqVPni1tCofJ4sgVVKisRKrVtEMlJkzqbmiFioWWgOol2fYMJph4+ICBAQyCH7tQ2NcFi1Cb3Ic25O6YMwoKUxMygaRk6MpPObm9H1MDJ2ztTXQsyfNRyYEubl0tylTADe3GLi6+oLLpQJEloqpoqKCYcOGwd29A9LSxgJoj7CwxjAx0UXLlv3KY3gjIiLA4/EgqijoLl2i965xYxoIO28eVVvFxeBwAM2zoTCJDsOQMeoIM/HH8sASgMtF+rYT6O3wDF5X56D7IE00akSDeM+epcNKpdXHDv+nqumysLB8MA0ZoxIJwJJhGHNQkTEEwNCKOzAMY0gIkeWC9wYgC+j6F8ByhmG0y953AzCvAefK8h6kp9M014MHAYP/Ylx5UhL1TYSE0MBNXV16Qa9fU/HRrl2l3WXZw+LIe5Bbuhjk9WtwL12AnKkpXkU/Bz9TDkIezSQWCum+HTrQQNOHD+kycmRlo42s0BqHA+joUCNOjx7UA0Rrl6gAixeDGTmSpuxwOHTwixfpjhVdJFOm0MDc7dupD6dHD+Q7u8Px5S5kZHCxbp0pWrXKRf/+/2LcuHF4+fIljh49CkVFRZSUlEBDQwPBwcF48eIFeDwerl7l4a+/EnD/vjLc3alRacqIETDg8dCdYRBqZgZNR0dMU1WF+/XrgJcXBO3aQcXbmyouAMjJoXPZuBHIygJcXSGXyQc0LGDc2QY379LbHRFBhduNG2/04KlTNM62XTsa49K2LU2b/k9V02VhYflgGrQpIcMwPQFsAMAFsIsQsoxhmCAAUYSQEwzDrAAVKGIAOQD8CSG8smNHAZD1M19GCNld27nYrJ9Pz4f01ZNI6AObw6EPcpEI4PMrP+SFQhoKoq9PQxquXXuzXvbaqRNNpHn+/E25kYrbx44F7O1pLOy6dYBmbjLEYiBVzgzNs25j48NO4PTpjUib4Rh7pAeKxfKVjr9wgSaZbNsGbPGPwWIsRn8cQy608CtmYARvPiysuVizpnqvUHo6FXGBgfQBWxVlZaB/f2DhQlqrhFMXG+f27TQatnt3WgjN5u2Gqq9z8vBXz3m4e+cKdiMeQwZMQohjY5ARI1Cqrw8lJSX0798fhoaGGDduHP744w+kp6fj6NGjlcaRSoH9GzKRsmArOpaehxtug0skEMrLY42rK0Ly8tDWzQ3bd+4EAaCtrQ05OTnY2NigjbExlv7zDxSEQuoa+/lnqtzqGH9y6xZ1V924QT/fmmDrvdUfNuuH5UukpqwftnsyS72Rl6cprVVhGGr5rygWJk0Cpk2jZnorqzfrZQXJ1qyhMZSPH1OPRVW2bqXP5Lt36dhV2buXukyuXKGiBaAZrgoKdAkJATxb54K39DAKt+yBS8k1HNYZh9XNtkNBnuD35QX4X0dNXLtGn/kKCvT6ZK9z51Kx9GT1EVj8PAAlihq422EGYtynAlpaGDKElvlISKA13ioeL0vZVVSkxoTcXLotMJCKKgUFej/qLfREIhrIu2gRLR07dSodtCxVZ8qUn7Ft23aIxflQUTHDtGmjMOU7BxgMGEA/pH796DFt29IPpqJZjBCa53zuHGBmRjOcXr4EMTZGkmYrHMzthidmXeEf/D1c2ytWmZYI++fPhyQqCn9LpeDFx2NCVhZ0Ro/GTzt3orCwEK6urrCxsYGNjQ2sra1hY2MDe3t7qKur13rJqanAyZNlwbkv6GWrqNBLWbv2P2rR+4x8CULF2NjYUVVVVSIrCx8bG1vtHD5ll+WuXbs2T0lJURQIBJzc3Fw5Y2NjIQBs2rTpedeuXV+/6/iEhASF8PBwtQkTJuTUtE9QUFDjZcuWmfD5/Ac6Ojr/+fL2H5PPkZ7M8pWybBl9gMs0rqIi/be1NfWeyB7S8vIoj6dQU6PFwiqKAAUFmiAD0AfNrl2VH/Ly8oCjI91uY0Mzd6sKCd2yPqbt2tHQEnn5KlaJ8eOBvn/BRiikgwxfhgHDhmFAUwBgAGgCoPOQzaWc+HggNQdo2hYW/t2A0iAoTZ6MttraaFtlV2vr6oWWDD09ugDU1TFhwptSIOn1LYQtL0/V39ChwPz5IL/+itTz52Fy/z6uXGGwa1cxpFIvTJs2GmvXdgSXW3ZDnj2jAmfHDhqE26oVDQq5fp36pExNaeqwzHzh50eFioEBmJwcWGhqwvEEsHUi8HdH6mlauhRQVyPA9euQX7UKI06dAnR0MColBVBWRm5uLiRllecKCwthY2ODhIQEnDx5EuIytbt582ZMnDgRz549w4oVKyqJGDMzM3C5XJiY0Hv24AGwfXs6GGYIiosPQkPDgBUpDczChdB3c4PA2xuFsnVhYVC/cwcqS5ei2iZ6deXKlSuPDQ0Nq/nZ82mQSqUghIBb1mfr/PnzSQBw8uRJ9XXr1umHh4c/qc94iYmJigcPHmxUm1A5fPhwIwcHh9d79+7Vmjp16qsPuoBvBFaosNSZp0+piyIkhD4rZbEWpaX0x/dPP9G2Nfb2VEhURE0N+PXXmsfW0KDPxZpQVa3eoiKDywW4HEKDHcLCqJ+FYWigx4QJtDaHs3Pd3A4JCTQAIiSEHhMZCair00qyH4GK3pX3LQUiFotxLioKu/LykMbhoCQmBt9PisPhbQbwbPIjAo5/J6sH94YmTWjAb2AgDQSJjqYLQANvAarytmyhQTLNKzTE1aSCrndvarmaP582ME48GI192pOhzbtFVeMvv1AzWllXQ21t7fIhjIyMcOzYMQDU+vLs2TMkJCTAsUyNvnjxAkePHsWrV2/+disoKOD06dPo3LkzEhMTERl5G2Zmx5GcfB12dkF4+ZINUmlo3Nwg+PFHNAsOxlNvbxSGhUFd9v5TziM/P5/To0cPi/z8fK5YLGYCAwP5P/zwQ960adOMGjVqJA4MDMwEgClTphg3btxYFBAQkBkQEKB/7NixRkKhkOnVq1fe+vXr+QkJCQrdu3e3atmyZdHDhw9VT58+nWhlZVVjjwo+ny/n5+fXNC0tTQEAfv311xfdunV7ferUKbWZM2c2AWhQ+s2bN3kLFiwwfvr0qZKNjY2dr69v9qJFizIrjhUXF6coEAi4v/322/Ply5cbyoRKfn4+Z/To0U1iYmJUAGD+/Pn8kSNH5h0+fFgjMDDQWCKRMI0aNRLfunXr7ZS+bwDW9cNSZ7ZsoW6aadOop+Bp2Z8pNTVqzZC5gxQUqCXE2ZkurVrR94qKNY/9QTx9Sn1Ae/fSVGElJfrT28qqfuMkJVGBsncvHWPyZHrBX1hG2YMHD9CzZ0/w+Xzo6uqiX7/huHfPD1FRjjhtNws94n8FM3o0NX3V0E1w88KF8Ll9GwayroRKSsho0waH27TBpOqCaSpSWgrk5eFmkj6W/ZiA35J64arzdPQ65Ad989qznepCdnY2EhISkJCQAB6PhylTpsDU1BTy8vLlVpiKKCkpoZgNUqkXFV0/w4a9Eicm6pTUtn9BAbhJSVDS04MoKwvyzZujREMDNbotHBwg2LWrUi2stzA2NnbU1NQUMwwDPz+/rFmzZmVXt5/M9SMSiVBYWMhp1KiRND09Xc7Nzc0mOTk5NjExUaFfv37NHz16FC+RSGBmZuYQGRkZf/PmTdVDhw5p79u37zkhBF26dLGYM2fOy2bNmgltbW0dz58/z+vcuXO17pyKFhVvb2/zyZMnZ3Xv3r0oMTFRoXv37pZPnz6N8/DwsJg7d256t27dXufn53NUVFSk//77b62WmJ9//tlAKpUyK1euTDc1NXW8c+dOvKmpqdjf39+4tLSUs2vXrhQAyMrK4opEIqZVq1Z2ly9f5tnY2AgzMjK4X0Mn5NpgXT8s9eb1a1pptEkTWjJ97FjaA65v39V4+tQFSkrumDGDui8WLw5HRkYkWrWag+hoGlMSGkq3AdQC4+DwRrg4O9Mg1ao95upNeDjtoAvQn/pz59Jc3DILQL24dQs4dIh25Zs9+zO3DH7D69evcfjwYSgpKWHw4MGwsrJCmzZt4OvrC3l5L4wapQCBgLYP8uwbACwBDeY4dIhaOCZOpB9ABew6d8aZtWsxUigEo6QEUlqKUzduwG7hwponUlBAA3k3bABat0abI0dw7JE1Vi5/jGUrOFB1pgHLI0d+WL02XV1d6Orqom3byg62pKQkTJo0CefOnYNQKISKigr69euHtWvXvv/JWOqEhgYkenoQpadDwdAQwtpESl25fv06z9zcXJSWlibn4eFhZW9vX+Lp6VlU0/5SqZSZNm2aye3bt9U4HA4yMzMVUlNT5aytrYVaWlriGzduKKenp8vb29sLDAwMJGfPntW4evWqhp2dnR0ACAQCDo/HU2rWrJnQ0NBQWJNIqcqNGzc0EhMTlWXvyxoJclq3bl00a9Ys00GDBuX4+vrmNm/eXFrbOABw9OhRnaNHjz7hcrno2bNn7p49e7Tnz5+fdfXqVY0DBw6UW6j09PQk+/fv13R1dS20sbERAsDXLlJqgxUqLG8hEtF4kcWLaazlhAlUqKSkUA2QkOACYBCWLQvFjBnu0NEJx6xZg7B2bSiGDKGxmQCNW3n2jIoW2XL0KG2KB1B3jb39G8uLTLzUWIJEKKTN/vbseVOvo00bWpZeVgOlPiQn0yALBwdqJvL1pS4PWWrtZ4QQgtu3b2PXrl04cOAAioqK0LNnTwwePBjKysrYv/8QFi6kl+7oSC1c9AeyJo0uHTOGBsxOm0avc/36SuO7u7sjy8UFf0ZEIMbVFU537qC3iwv0qlbNBWgQzcaNNLI5P58KwwkTAFDrWeBiDgYOpjE3o0ZRg9T27e+ukltfmjRpAhMTE4jFYigpKZWnVBuwQSofxLx56UIHB52E2vaRuXumTkX6339DLyAA/IoxK++Dubm5CACMjY3FvXr1yrt165aqpaVlqZeXlyUAjBo1KmvOnDnllTy3b9/e6NWrV3IPHz6MV1RUJMbGxo7FxcUcAPDz88veuXOnbmZmpryfn98rgP4fmjZtWvrs2bMrWWoSEhIUVFRU3ikqZBBCEB0dHa+iolLJ/bB8+fKXffv2zT9+/Lhm+/btbU6dOpVY2zgRERHKz58/V+zRo4cVAIhEIsbExEQ4f/58tlrpO/jclWlZvjAuXqTP7QkTaIjCjRv0+XT1KuDqSlOIx4xxx4oVwVi8uA9cXFwQGOiNSZMCIRC4VRqLYWiDvIEDaUfe8+dpuZJnz2gs588/00KkYWHUy/L99zRWxdGR/irfuJGev/jyHWoVMHjtPc4AACAASURBVDSkaR7Xr1OVA1B/0uzZ9RMpskZ4lpZU9Mg6HnO5X4RIAYBx48ahTZs2CAkJwcCBA3Ht2jWcPHkSANUdHTpQkTJhAm0SWGbFf4ONDa2c9s8/VLAA9MaXBcrev38fo7W1MVYoxKarVzGFw8EuLy8UFVXzg3bLFnqybt1ovM7Fi29K/Zdha0szr7Zto7XeHB1pOEzFmjEfg4yMDEyYMAG3b9/GhAkT8JKt+tbgVIxJ2bAB/OBgPP3xRzQLC0PtqVq1UFBQwMnNzeXI/h0eHq7RokWLYgsLCxGPx3vE4/EeVRQpAJCfn8/V1dUVKSoqkrCwMHU+n18eCTd8+PC88PBwzQcPHqj6+PjkA4Cnp2fBnj17dPPz8zkA8OzZM/m0tLR6/zhv165dwYoVK8rNqzdv3lQGaLyJq6tr8bJly162aNHidWxsrJKmpqakqKio2u7NwcHBjWbOnMlPS0t7mJaW9jAzMzMmIyND/vHjxwodO3YsWL9+ffk5srKyuJ06dXodERGhzuPxFAAgIyOjXl2hvya+6RiV1atp+mjFH5Hh4fRv8bfWjFUqpXGUp0/TsIyVK2ljOYahFhB/f6BZMxFmzjyHq1dDcPz48bcealwuFw4ODnBxcYGrqytcXFzg4OAAObna/zYQQtNPZVaX6GggLSIND7Jpe6ej6IcezL+417QvMrsNR6PBXdHSRQ7vyGitnt9/p64dgPqy5s17k5r0CUlPT8eQIUNw8OBB6Ojo4PTp09i9ezd+//13mJiY4NKlS0hOTsbAgQMrpe4eO0atFlIpTd4ZNKgeJ+3bF9KzZxHarBn84uPBVVUFIQQ+Pj44cOAARCIRdHV1sW7IEAxNSYHc6NH0S/DqFRVzdTSR8Pk0I+joUdrgeefO2gOhWT499UlPboisn0ePHin069fPAgAkEgnj4+PzatWqVdWqTlmMSnp6upynp6eFQCDgtGjRQhAdHa165syZRGtrayEADB06tImWlpZky5Yt5VXMlyxZ0njPnj26ZeNI9+3b90xOTo54eXlZJiYmxtU0v4oxKunp6XJjxoxpkpiYqCSRSBg3N7fC/fv3vxgxYoTpzZs3NRiGIdbW1sWhoaHJHA4HHTt2tMzNzZUbOnRopWBaExMTx7CwsMSWLVuWxwONGTPGRF9fXzxnzpxMPz+/Jg8fPlTlcDhk/vz5/BEjRuSFhoZqLFq0yEQqlUJHR0d08+bNWq02/3XYOirVEB5O/9Bv2kTdFbL3FZvbfu3ExdFntYMD7b9HCH0Icrk0OHbWLCl+++0qTExC8Pr1YeTm5kBbWxvff/89bty4gcmTJ2Pr1q2YMWMGSkpKEBkZiYiICOSWWSmUlZXRsmXLcuHi6uqK5s2bl5dur0RODvVh7N0L3LyJl9efIDKnOZ5cfI5bPG3ceKgBPp/uyjA0VlYW7+LsDLRsWUNoCp9PYzT09KhpaP9+mrZSX1fRR8Tf3x/bt2+Hk5MT0tPTkZGRAQMDA+zbtw8espibCpSUUMPR77/Th/7Bg9RaVVcSEhKwafZstA8Lw2AARfLy2MTlovWpU3D38ED4pUu40qsXxkilMBEKkccwuO3jg/Z//QXVWnoW1caxYzQBKCODGnWWLKm1/RHLJ+RLqKPyMZFIJLC3t7c7dOhQkqOjY+m7j2D5EmGFSg0EBwMjRtBmbU+efDsiJTWV1gv76y+atbN4MTB9Ot1GCMGVK3fh5xeC5OQDAPhQUVFBnz594OvrC0VFRQwbNgyhoaFwd3dHeHg4Bg0aVP6eEIKnT58iIiKiXLhER0eXZ2Zoa2vDxcWlXLi01tND49Wrac10kYiqpuHDqelAViiljJcv31hdZBaY1NQ32y0s3giX1mYv4XJpFZT+2katJxs3fpJ7KyM2NhYpKSlISUlBamoqUlNTsWfPnmozV+Tl5SEQCKq1PiUm0hCce/foZ7Ry5dvp3zXx5MkTLFmyBHv37oWSkhJ++uknzG3dGlI/P2jn5tIYlvXrafG3mzchUFFB5ujRmBYXh+OXLqFx48aYM2cO/P39ofKO/kXVkZ9P45u3baMp7Nu20YK6LJ+Xr0mo3L17V6lPnz6Wnp6euTt27Eh99xEsXyqsUKkBiYSKlKgo+ny8e7fuD4H/Knv20MBHqZTGhsyfT/vMxMfHIyQkBMHBIXj+/AkAeTg5eWLuXF94e3uX/7JevXo1XFxc4F5B0YWHhyMyMhJzavCZicVixMXFUeFy5w6Ely8j+elTXJFK0QjAAy4X0ebmyPb0RNPevfGdiws065i5k5n5RrhERwPJEZnwTV2NidgCBQhxTO1HXG63EKYdm5VnHenofOhdBC5evIjHjx+Xi5DU1FRYW1tjS1mZWRMTE6SlUSs0h8OBoaEhvLy8UFhYiH/++QcCgQDKysro378/1q5dW21Q6P79NJxGQYGKSm/vus3t+fPnWLJkCf766y/Iy8tj0qRJmDNnDhrLMpnEYurfDA6m8T8bNlD/3pIl5f8Bbt68icWLF+P8+fNo3Lgxfv75Z0yYMOG9BMu1a/Q7x+PRSsLr139xWd/fFF+TUGH5emCFSg3I3D0tWtAmsC1bApcvl1cj/2ooKQGKiqiB4uFDWro+KAhgmOc4cOAAQkJC8ODBA3A4HHA47lBU9EVISH94e2u/e/C6kpj4pt7J06eQdOqEO8uWUctLRAQiIiPx5Mmb8gPW1taVXEZOTk5Qqks+s58fSHAw0j1+wAmnAFx8boG7d2ksqYymTSunSjs7Azo6UuTl5aFRo0YAgKNHjyIyMrKSENHT08PNmzcBAN9//z1u374NLpcLIyMjmJiYoEOHDli5ciUA4MKFC1BVVYWJiQkMDQ3LrSX+/v74448/oKCgAKFQiPHjx5eLGxkCAS2g9+ef1NgREkILx76L1NRULFu2DH/++ScYhsH48eMxb948GBoaVn+ArAlRQMCbVs5VuH79On755RdcuHAB+vr65YJFWVm52v1rorSUuhdXrKD/v9avB3744cNSmVneD1aosHyJsEKlGqrGpMybR83qzZvTX4A1/W3/LyGRUF0QEEDLzO/fTzMnDh06hJCQkPKHbuvWrdGkiS+OHBkEKysDhIVVLkz6wYwfT4uqMAwtxjJ8OM3gqRIRm5OTg6ioqHKXUURERHlmh7y8PFq0aFEpWNfW1hbcvDxawGPwYBq9+fw5VWYVatpLJBI8fpyJy5f5KCx0RnQ0cPnyPmRknAKQCiAFQBoUFDSxcGEWnJ2BrVsH4t9/j8PY2BgmJiYwMTGBnZ0dAsoq1D558gQqKirQ19cvL8FdF97VDDAujn4v4+OptWvxYuAd8ch4+fIlVqxYge3bt0MqlWL06NFYsGABTGoLFJb9B/D3p6ld7/B7Xrt2Db/88gsuXrwIAwMD/Pzzzxg/fny9BUtcHPXE3bpFk4e2batfvA3Lh8MKFZYvEVaoVEN1WT+rV9My8cbGNLuztv4tXzKEAGfO0PiAhw8BJ6c8dOt2DPfvh+DixYuQSqVwdHSEr68vBgwYgk2bzLFpE9CzJxUz71MvrZySEtpBLiSEmgS0tGjxseRk2p/G2Lge10GQlpZWLlwiIyMRGRmJgoICaAGYKy+PyVIplCUSXPT0RKKXF0aNGgUlJSXs2bMH27ZtQ2pqKvh8fnlsiMzlMm/ePBw8eAgaGibgck1QXGyCV69MkJk5CbQPUBEMDVXw3XecSpYXI6MPuDe1Xiu9XT/9RPXb3r1vZQG/RVZWFlavXo3NmzdDKBRixIgRCAgIgJmZWe0HVlXp9Ygkv3r1KhYvXozw8HAYGBhg7ty5GDduXL0Ei1RKBcrcudQLFRREw2XeJchYPg6sUGH5EmGFSj2IiqK92MRi+rz9/vuPMuwnZf16YMYMAfT1T6JJkxA8eHAaQqEQzZo1g6+vL3x9fWFvb4/cXPp8unABmDmT1r6os3EgPf1N593GjWnRkz176MMuP5+apP75hxZgeU9EIhHS09MruV98fX3BXb8e6r/9BmWhEKEAfgHwqOwYWVaSgoICnj59Cmtra1hYWMDU1BQmJibo1q0bFGup519QANy/Xzlgl8d704TRwKCyy6hVK5rh/CEujIICWhMlJIQanPburb0jcE5ODtauXYuNGzeiuLgYw4YNQ2BgICzqWmXtI+TmX7lyBYsXL8bly5dhaGhYLljq5J4rIzWVZgadOEHv444d9JWlYWGFCsuXCCtU6klSEtCjB5CWRp/DdQ1i/JwkJgKFhSKkp5/D7t0hOHnyOEpLi2BoaIjBgwfD19cXLi4u5anBjx/T63r2jP66HTWqfud7PWIElIODUTxiBFTnz6fmJ1VVoH9/6trx8KhV9YjF4koZMampqUhJScGYMWPQokULnDhxAn379oXsO6oGoAjApUuX4H7+PLJu3MBGLS2gRQsYGBhALBYjKysLKSkpiI6ORlxcXPmxZmZmleJdWrVqBTU1tTpfa1ERbR9UsdbLo0fUMgDQwNCqMS9NmrwtXqrTB9u3AwsW0FIlQUHUylDTbcvPz8f69euxfv16FBYWYtCgQVi8eDFsbGzqfC0fm8uXL2PRokW4evUqjIyMMG/ePIwZM6bOgoUQ4MgRWnslK4uWuVm8uJYKxSwfzJcgVIyNjR1VVVUlHA4HcnJyJDY2tto5yOqofKp5hYSEaAYFBRlLpVKIxWJmwoQJGbNnz87es2ePlp2dXYmzs3OtfZGq4urqar127dqUDh06COo7l5MnT6orKipKu3btWqnc/2+//aazdetWfQBISkpSMjc3L+FwOPDw8MivWEemNoKCghpPnz49W11dvdoqvenp6XKmpqYtli9fnlK1+F5DwQqVanhX9kpmJuDlRR9M28oyXL9E0tOl8Pe/ihMnQiAndxgiEa11MmDAAPj6+qJDhw5vxVBcuEArxsrJ0cJc7dvX44TKytS9UxV5eVoLpUwAlJSU4Pbt25WESGpqKsaOHYtevXrhzp07aN26daUhNDQ08Pfff6Nv37548uQJ9uzZg2Z6evg+KgrN/vkHpX/8AZWBA8EA7zRhFBUVITo6ujzWJTIyEsnJyQBoFo6dnV2leBdHR0co1CPlSyCg4qWi5SUujsYFATSzSCZcZK/JyTSUJjSUtib66SdaG0VXt/bPobCwEBs3bsTatWuRl5eH/v37Y/HixeWdh78EwsPDsWjRIly7dg3GxsaYN28eRo8eXWfBkptLjTk7d9KYle3bgS5dGnjS3yjvI1SeP4f8gAFoduQIkpo0wds59vXE2NjYMSoqKt7Q0LDWsRpSqEilUhBCyv8+lpaWMqampo63bt2Kb968uai4uJh5/PixgpOTU6mPj4+Zl5dXvp+fX259zvEhQmXGjBlGampqkqCgoBoL69X1Ptb3uFWrVumFhoY24nA4iIyMrLXFwseiJqECQshXsTg7O5P6cunSJaKrq0suXbpU7XtCCCksJMTTkxCAkEWLCJFK632aBkEqlZLw8AjSuvV0wjBGBACRk1Mh/fr5khMnTpDS0tIaj/39d0K4XEIcHAh5+rT+5zZTVCSR9IcwIQApAsgegBgyDPnf//5HNmzYQAghJDU1lQAoX7S1tYmjoyMJCQkhhBCSm5tLdu3aRc6dO0cePXpE8vPzK5+osJCQlSsJ0dGh5/LyIiQmpv4TrkBmZiY5deoUWbRoEenZsyfR1dUtn5+ioiJxc3MjU6ZMIcHBwYTH4xGJRFKv8YuLCblzh5AtWwgZM4aQli0JkZcvv1VES4uuU1YmxMqKrmvdmpCsrOrHKyoqIqtXryY6OjoEAPH29ibR0dEfdA8aEqlUSi5evEjatWtHABBjY2OyefNmUlJSUucxLl8mxNKS3psRIwjJzm64+X6rPHr0qPzfDx8+fE0IiXrXMmwYyWQYQoYNI5l12f9di5GRUSmfz7//rv2UlZUlhJCovLy86NatWxfY2tq+trS0FOzZs+cJISRq6tSp/F9++eWFbP/JkyenBwUFvSCERC1cuDDF3t7+taWlpWDatGl8QkgUj8eLadq0aUnfvn2zmzdvXpyQkBAjO/bly5f3tLW1RYWFhXcrzuHcuXPxGhoaYiMjo1Jra2tBbGzsQxcXl8IrV648IoRE8fn8+0ZGRqWEkKjCwsK7vXr1yjE3Ny/u0qVLrqOjY5FsvyNHjjx2cnIqsrW1fd2jR4+cvLy8aNm9mDZtGl92bdHR0bE8Hi9GR0dHpKenJ7S2thacOXOG9677WN315ufnR3fs2DHPyspKYGFhUfzHH38kLVmy5IWcnJzU0tJS4OrqWlDduM7OzoWXLl16ZGpqWvLkyZMHsvWbNm16ZmlpKbCyshL06dPnFSEk6sWLF/e7dOmSa2VlJbCyshKcO3cu/n2+E/fv308m1TzfP7vA+FjL+wgVQgg5d+4cUVFRIZ6enkRDQ4Ns3ryZpKSkEKFQWL6PUEiInx+9W2PGECISvdepPgpxcXFk4cKFxMLCouwBK0+MjHqTX38NIUVFRbUeKxQS4u9Pr8Pbm5CCgrf3kUgkpKDCho0bN5Jp06YRHx8f4uLiQvT19UlIq1aEAEQKEAFAxADZyuEQe3t74uXlRfbt20cIIUQsFpMLFy4QHo9HCgsL63ehUikhZechnp706d8ASKVS8uzZM3Lw4EEya9Ys0qFDB6KqqlouXjQ1NUnnzp3J3LlzydGjR0lKSgqR1lOtlpQQEhVFyPbthIwbR8h33xHC4dBL69q1evFbXFxM1q9fT/T19QkA0r17d3Knge5BQyCVSsmFCxdI27ZtCQBiYmJCtmzZUmfBUlxMyIIFhMjJEaKnR8i+fV/Oj4SvgapCxcWFFFZdVqwgzwkhUQoKRFrhd0n5IidHpISQKD6f3K96LKmjULG1tX1tZ2f3es2aNck17ScTKkKhMOrVq1fRpEwYmJqalkgkkigejxdja2v7mhASJRaLo0xMTErS09PvHTly5PGQIUOyJBJJlFgsjurUqVPe6dOneTweL4ZhGHLhwoVqH6aDBg3K0tbWFnl5eb3asmXLU7FYHEUIierfv3/2rl27kmT71SRUFi1alDJgwIBsQkjU7du347hcLrly5cojPp9/39nZuTA/Pz+aEBI1f/781JkzZ6bJ7sXSpUtfEEKiVqxY8XzQoEFZhJCo6dOn8wMCAlLedR/5fP79mq539+7dTwYPHpwl2z87O/texeOqGzMxMfFBkyZNSgghUZMmTUoPDAxMIYRERUZGxjZt2rREdtzLly/vEUKievbsmSMTiyKRqPwc9V1qEirffIy9vb09iouLcebMGQDApEmTMGnSJDAMg8aNG8PY2BhGRkYwNDRC+/ZG2LnTCA8eGOG334zRvLkRdHV1weE0bG/H5OTk8lonMTEx4HA4cHd3x8yZc2Fp2R+dO7+71klODnX1XLpUCH//PGzaZAouF1i3bh0ePHiAlJQUvHjxAikpKejatStOnToFAFizZg1ycnLQpEkTmJqaYhbDYFBEBHJVVHBQIMCf8vLwE4nwfdOmmBAbW+mcXC4XnTt3rvuFFhfTqmajR9OiY7/8Qv0nDRjNzDAMzMzMYGZmhkFljXMkEgni4+MrZRqtXbu2PGvI0NCwksvIxcUF2to1fwaKim/iVoA3CTajRtEu1Zcvv4lZKS0txZ9//olly5aBz+fDw8MDR44cQdu2bRvsHjQEDMOgc+fO8PDwwMWLF7Fo0SJMnDgRK1aswIIFC+Dn51erm01JiTa2HjyYNoIeNox+HRYvpk2uZXyrvbk+JffuIbZdO9jm5UGOEOpx1daGeOpUpH/IuNevX+eZm5uL0tLS5Dw8PKzs7e1LPD09q+mKSZFKpcy0adNMbt++rcbhcJCZmamQmpoqZ21tLdTS0hLfuHFDOT09Xd7e3l5gYGAgOXv2rMbVq1c17Ozs7ABAIBBweDyeUrNmzYSGhobCzp07v67uPAcPHnweERGReebMGfWNGzcaXLhwQePIkSPJ9bgutZ9++ikTANzc3IqtrKwEAHD58mXVpKQkJVdXVxuAdk92dnYuv96hQ4fmAoCrq6vgxIkT9S5gVdP1du7cuXDBggWm/v7+xn369Mnv0aNHjfdYRnBwcKPevXvnAsDw4cNzRo8ebfbLL79k/Pvvvxre3t65MneRvr6+BABu3rypfvjw4WcAICcnBx0dHUl9518b37xQSUhIgI6ODoYPH47du3dj9uzZ0NXVBZ/PR1paGvh8PlJTUxEREYHMTNpfKjISaNOGHi8nJwdDQ0MYGRmVLzJxU3HR0tKqvr8Nqo+VOXLkCIKDg5GVlYVbt24BAFRVWwP4DR4eg3D+/NspISKRCGlpaXj16hWcy56K69atQ1hYOG7degGh8AWAfNy40QJc7gMAwIkTJ/Ds2TM0adIEbm5uGDBgAFpVSLuIi4uDmpram7lfugTs34+x2dnQNzbGzrJaIBfS03G06oTqSkkJrbGyYgWtkW9gQGuseHm974gfhKy5ooODA/z8/MqmWIIHDx5Uagtw4sSJ8mMsLCwqBeu2bNmy2nTdqlnAPXrQ9/v3i5Cc/BeWLl2KFy9eoF27dti3bx86der0qS67QWAYBl26dEHnzp1x/vx5LFq0CBMmTMDy5cuxYMECjBw5slbB4ugI3LwJbN5Mu20PHUqbZ2/cSNs2ye4ly4cREYEaYxDs7CD09ERuSAj0FBRARCIwnp7IDQxEJgAYGkJc2/E1YW5uLgIAY2Njca9evfJu3bqlamlpWerl5WUJAKNGjcqqGMS5ffv2Rq9evZJ7+PBhvKKiIjE2NnYsLi7mAICfn1/2zp07dTMzM+X9/PxeAdRbMG3atPTZs2dnVzxvQkKCgoqKSrUBpDJcXV2LXV1di8eNG5djYWHhCCC56j5ycnJEUhaQJhAI3pnzRwhBu3btCsLCwp5Vt11JSYnIxhWLxfXOIazpegEgOjr60ZEjRzQDAgKML1y4ULB27dpaReaRI0caZWVlyR89erQRAGRmZso/fPiw5lTJBuabFiqyHjVbt4Zi0yZ37NzpjQkTaM+acePGvbW/UChERkYGQkL4WLgwDVpafAwYwIdAwAefz8fjx49x+fLl8oZ8FVFSUqpRxMjLy8PHxwerV6/GmjVroKioiIcPHwIALC0dYWm5HImJg6GpqYHZs1/AySkSAE1D+u2333Dw4EG8ePECfD4fhBBoa2sjJycHAHDx4mNcu5YGOTlz+Ph0hKurKSwtLcvndfny5RoFFADauZcQmrP93Xc0k8fDA4cr7LN58+b3uPugUafbtwPLltHGgR070hSrDh3eb7wGRElJCW5ubnBzcytfl5+fX6k43dWrV7F//34AVOw4OjpWsrzY29tjzZpfMW/eG1Havr0YXbosRJ8+O1BcnAM3Nzfs2LEDXbt2rfVz+a/BMAy6deuGrl274ty5c1i0aBHGjx9fLlhGjBhRo2DhcmnQcd++VJhs2UKz3oXCb6c31+cmKwvyw4Yha+JEZG3ZAr2MDMh/yHgFBQUciUQCbW1taUFBASc8PFxjwYIFfAsLCxGPx3tU3TH5+flcXV1dkaKiIgkLC1Pn8/nlX5jhw4fnLVu2zFgsFjM+Pj5PAcDT07Ng8eLFRuPGjcvR1NSUPnv2TF5BQaHW7JH8/HzOtWvXVL28vAoB4M6dO8pGRkZCAFBTU5MUFBSUm89NTU1LIyIiVN3d3QX79u0rt4C0a9euaN++fY169+5dGBkZqfT48WMVAOjUqdPrmTNnNomNjVV0cHAoLSgo4CQnJ8u3aNGixiaK6urqkoKCgjoVjKjpekUiEdO4cWPxxIkTc7S1tSV//vmnLgCoqqpK8vPzOVWrVsfExCi+fv2am5mZGSNbN336dKO///670ZAhQ3IHDBhgsWDBgpcGBgaSjIwMrr6+vqRt27aFa9as0QsMDMwUi8XIz8/nflSrSnX+oP/i8j4xKqtWrSKXLl0i/v40ZsDfnwbUrlq16p3HXr9OiLY2IQYGhFSNbXz9+jV58uQJuXr1Kjlw4AD59ddfyaxZs8jQoUNJx44diaWlJVFRUakUaFp1GTx4MImNjSVjx24jHI4VkZNTqrRdFvOxevVq0rlzZzJy5EgSGBhIdu7cSf79918ikUjJhg30upycCElOrvftoUilhCxcSJ3SFYKMPwhZsIEsDqV9+4839meGz+eT48ePkwULFpBu3boRbW3t8s9MWVmZ2NvbE2VlZbJgwQISHBxMTExMCABiaWlJTp48We/4l/8qUqmUnDlzhri6uhIAxMzMjOzYsaNSbFj1xxHSvz/9OgYEfKLJfoW8TzDtx1zi4uJiZIGXzZs3L54zZ05qTfvKYlT4fP59JyenIktLS4GPj0+2ubl5MY/HKw+E9fX1zfT390+veGxQUNALS0tLgaWlpcDJyakoNjb2IY/Hi7GwsCiu7lw5OTnRHTp0yGvatGmJtbW1oGXLluWBsP/++298s2bNim1sbASxsbEPo6OjYy0tLQU2NjaCKVOm8KsLpu3atWulYNrjx48nyIJdLS0tBXv37k0kVeJFrly58sjFxaWQEBL14MGDh5aWloK6BtNWd72HDx9+LBvD3t7+tWwuS5cufdG0adOSqsG0M2bMSKt6H2/fvh1nbm5eTAiJ2rhx4zMLC4tiKysrQf/+/bMJocG0Hh4eubLznD9//qMG037T6ck1ZdkqKNBU02bNaC2H4mK6KCrSbXJy1E8bH09N97m5NLW0PqmUhBAUFhaCz+fDyckJQqHwrX2UlJTw99/BCAk5hObNm5THiTRp0gROTk7VdtoF6C/NSZNommffvrQGWz1KhlScJK3hvnIlDRTYvh34kHgckYjGoGzaRAMzGjWiN09L66tt+EIIQVJSUiWXUWRkJEQiEQBqeQkMDERAQMBXZUGpK4QQnD17FosWLUJkZCTMzMywcOFC/Pjjj5CXf/tHez2r/rPUwJdQR+VjIpFIYG9vb3fo0KEkR0fHqlqWNAAAIABJREFUGi0ULF82bB2VakhPB2bNAg4fpg/3qty6RTsr79pF4ztlMAwVLXfv0lLzbm60MJyRES38paBAtx8+DOjr09dDh96sl70uWwZIJIXQ0PACcLXK2T2gqLgPJSW1lCethuxsYMAA4MoVWkQsKOg9tQUhNEJx7Vrap2fLlvcXKWIxVUtLltDqcq6uwN9/A5+xSNnnRCQSYdKkSdixYwcWLlyIJUuWfO4pfXYIIThz5gwWLVqEqKgomJubY+HChRg+fHi5YPmAqv8sVfiahMrdu3eV+vTpY+np6Zm7Y8eO1M89H5b3pyah8k3HqBga0i6uYjEVDyIR7XUzbhwVLlZWdD83N2DDBrqutPTNq64urRy/cSMwcSINs9DWpoKltPRNddGsLCAmpvKxQiEVEaqqqtDXlyAjQw6ABIAigFJwODewb188gLoLlbg4WmmWzwf27aOBh+/NlStUpEyaRC0g7/trv7CQVjt78oSmvfz+O+Dp+dVaUOrC9evXcezYMQQEBGDr1q3w8PCoFEj9LcIwDHr27AlPT0+cPn0aixYtwujRo7Fs2TIEBATghx9+QGSkXCVR4u5ORUpkJCtUvmWcnZ1LUlNTH37uebA0HA2bV/sfICOD9liJiKDmZAUFoHdvapVo1IjuY28PTJ0KzJ5NGxYGBdGeOI0b0+39+9OGvYMGUbFgbQ2cP0+FDEDHjY8Hnj6lvU0yMwmWL9+M/PxUcDgcTJ3qDX391gD8oaBwG4A/Gjd2QVJSZJ2v49QpmsVbXEw1xgeJFICWTT1//v1EikRCUzUA2l2vf3/azCUykirBb1ikyAK4Q0NDERQUhNDQUAwaNAjh4eGfe2pfBAzDoFevXoiMjMSJEyegpaUFPz8/2NjY4O7dwZBILlQ5IhzA6s8xVRYWlk9EgwoVhmF6MAyTwDDME4Zh5taynw/DMIRhmO/K3psxDFPMMMz9smVbQ83x6FGa+ujkRF+PvmeOraIibSg3bRq1vvj6UstJVQoKCjBw4EBMnjwZf/zxBwBg3ryf0abNNUycuBkREU6YOHEzvv/+GubUoTgEIdTw4e0NWFpSLVAhMaV+SKVUjd25Q9936VI/USGR0Jvg4EBrwScl0fWrVtEJfsMCRUZkZCRCQ0PLLSju7u4IDQ1FZGTdRem3AMMw8Pb2RlRUFI4fPw4NDQ2Ehoaie/fumDdvHsRicbnoc3Fx+dzTZWFhaUAaLEaFYRgugMcAugJIBRAJwJcQ8qjKfuoATgFQADCZEBLFMIwZgJOEEIe6nu9jNyX8ENato7EvnTrRNEpNTbo+JiYGAwYMwNOnT7Fy5UrMnDnzgwIoS0uptWb3bmoB+usv2hPwvZBK6WB//AEsWkQra9VE1c56Uindf/t2IDOTmqAWL6aWlAYuhsfybUAIwYkTJzBz5kwkJSVBt8xcWVH0sdSdrylGheXroaYYlYZ8irgCeEIIeUoIEQI4AKBPNfstAbAKQL06Un7JzJwJ7N0L3LhBDQtpabTjr5ubG4qKihAeHo5Zs2Z9kEjJzKQGj927gcBAWn7kg0TK2LFUpMyfT4VKbbi4UD+XzF1x5AgNlFVSAg4coAE5AwawIoXlo8EwDPr06YPExEQMHDgQ2dnZ8Pf3Z0UKC8s3QEM+SYwBpFR4n1q2rhyGYVoBMCWEnKrmeHOGYe4xDHOFYZj69Pb9Ihg2DDh9mnbL/f57QE3NGb6+vrh37x7a16tV8ds8fEgTZ6KiqC745ZcP0AQSyZta7gEBtG75uwSUuzvw55/UnRMQQCOJt22jQTiDB7MChaXBuHz5MsLDw8sDkdnYnv82YrEYtra2du7u7hbVbU9ISFCwtLS0/9TzOnLkiIaNjY2djY2NnYqKSkszMzMHGxsbu379+pnVdYyNGzfqJCcn11gYTyQSQVtb22nixInGNe3DQvlsTxSGYTgAfgUws5rN6QCaEEJaApgBYD/DMBrVjDGOYZgohmGisrKy3hrkc2NunoSOHUdAKCxGjx6aGDVqF/T19T9ozBMnaPl+kQi4do3qgg9CKgUKCqjaCQqqWxzJjRvAlCmAQECFjb8/TWHm1qmAIgvLe8EGIn8eFi5cqB8WFqZecV1YWJj6woULP+yPGYClS5fqW1hYFH/oOB8DWW0jAPDx8Sng8XiPeDzeIwcHB0FwcPBTHo/36NixY8l1HW/v3r26L168qFGoHDt2TMPc3Lw0LCxMWyqttaL/N09DCpU0AKYV3puUrZOhDsABwGWGYZIBtMb/2TvvsCjO9e9/h6ULi3QRVBC2AqJhQVHRgMdOiSKJikKOBYVYjtHkaCxJNCcaIyf+sL7mBBRRLFgQYiyxJUSNNAsgIIKCgEhnacvuMu8fj4uIVAWxzOe69oJ5duaZexbd+c793AU4RVGUiKZpCU3Tin4NCQDuA+A2PwFN03tomhbRNC0yNDTspst4OU6ePAl7e3v89Vc0/ve/NBgaAmPHAidOvNx8NE3qrn30ESAQkKBZkegVDJTJSKdCFRVS5GXduvaPkcuB778npe6lUhJ8s3YtqbzF3CwYuhkmELlnGDp0aI2vr+9AhViJjo7W9vX1HTh06NCaV5n3/v37KmfPntWZP3/+C71p2iMoKMjAxsZGwOPxhOPHj7cUi8VKZWVlSqamprYSiYQCgNLS0sbtlJQUNWdnZ461tbXA3t6el5SUpA4AXl5e5jNnzuw/aNAgfkBAgFl75925c6eera2tgM/nC2fOnDlAJpNBJpPBy8vLnMPhWHO5XOG3335rFBoaqpucnKzp6+s7kM/nC6uqql54AoyIiNALDAws7Nu3b/2FCxcaF+4jIyPZQqFQwOPxhE5OTlyAlPafNm2aOZfLFXK5XOHevXt7d/Yze5vpzjoqcQA4FEVZgAiU6QAak2Zpmq4AYKDYpijqMoAVT4NpDQGU0jQtpyhqIAAOgKxutLXLkEql+Oqrr7BlyxaIRCIcPXoU5ubmGDaMrJRMm0ZKiQQEdHzOujpS22X/fmD6dLJK00K/u84YCcyaBaSmkrzsjk7m40OCYVxcSBzK8ePkdxcXpvIWQ7fTUhaci4sLE6fyimzcuFH13r17vLb2MTY2lk6dOpVjaGgoLSoqUrG0tKzbsGFD39aKFdrY2NSEhITktvjmUz777LN+mzdvflRRUdFpV6yPj0/Z8uXLiwFgyZIlfYODgw1Wr179xMnJSXzkyBGd2bNnl4eEhOhNmjSpTE1NjZ43b96APXv2PLS1tZVcvHixV0BAQP/r169nAEBBQYFqYmJiWmuVvhUkJiaqR0ZG6sXHx6epqanRs2bN6r979259Ozu72oKCApV79+6lAEBxcTHLwMBAvmvXLqMtW7bkjho16gVBV1NTQ/3111/s/fv3PywvL2eFh4frjR07tjo/P1950aJF5pcvX07j8/n1hYWFLABYuXKlCZvNlmdkZKQCQFFR0Xvlvu42jwpN0zIAiwCcBXAXwBGaplMoilpPUZRHO4ePAnCboqibACIBLKRpurS7bO1KFi1ahC1btiAwMBCxsbEwNzcHQGqqXLgATJ5MQjrWrCFekvZ4/Jjc+/fvJyszBw92gUiZMYOICj+/zk02axaJTRk/nnhhWqq8xcDA8M7BZrPlhoaG0oKCAlVDQ0Mpm81+pYZzEREROgYGBjJnZ+eX8sokJCRo2Nvb87hcrvDYsWP6KSkp6gDg7+9ftHfvXn2ALL34+/sXV1RUKCUlJWl5e3tb8vl8YWBg4IAnT540LslMnTq1rD2RAgBnzpzRTk5O1rSzsxPw+XxhbGwsOysrS43P50tyc3PV/Pz8+kVGRrJ1dXXb/WwOHz7ce9iwYWItLS161qxZZWfPntWVyWS4fPlyL0dHRzGfz68HAGNjYzkA/PHHH+xly5Y9URxvaGjYdQ3/3gK6tTItTdOnAZxuNtbiGgNN0x82+f0YgGPdaVtXQ9M0KIrC8uXLMXr0aMxsoeKapiZxQgQGPmsY/P/+H1l9aYmbN0nxuZISUobfy+sVjayvJ0EtJ08CP/1Eir60t//q1aSy3RdfAG5ure+r8KwwMDC8VaxatarexsYmva19FMs9S5cuLdi3b5/h2rVr893d3cUve87Y2Fit8+fP9zY1NdWRSCRK1dXVSp6enhZLly59EhgYOAAA1q5dmycSiVqMX/H397eIjIzMdHJyqg0ODta/cuWKNgCMGzeuevHixWoxMTHacrmccnBwqCstLVXS1taWtdaVWUtLq0MBIjRNU97e3iU7duzIa/5ecnJy6okTJ9i7d+82PHz4sN7Ro0cftDXXoUOH9OLj47VMTU1tAdIZOjo6+oU4TAYCk57xijQ0NOD777/H7NmzQdM0uFxuiyJFgbIyESfffENSiz09gerqF/c7fhwYMYJ4XWJju0CkAKR3z8mTpNpseyIlKwsYOZJUk8vJ6YKTMzAwvI0oREpYWFjW1q1b88PCwrKaxqy8DDt27MgrLCy8nZeXd2fv3r1Zw4YNE0dFRWW7urpWK4JYfXx8Klo7vqamRql///5SiURCHTp0SK/pe9OnTy+ZM2eOxaxZs4oBQE9Pr8HMzKw+JCREFyDf2deuXeu0X3rChAmVMTExunl5ecoAUFhYyMrIyFAtKChQlsvl+PTTT8s3btyYd+fOHU0A0NLSkre0rFVaWqoUFxen9ejRo9t5eXl38vLy7mzatCnn4MGDeh9++GH1jRs3tNPS0lQV5wCA0aNHV/70009GijmYpR+GDlNaWgp3d3esXr0aDQ0Nz0WNtwVFkVIle/YAZ8+S3nyKirg0TbwtXl6Avj5ZTRkypIsM/ve/yRrSokVt73f4MDlpRgZx5Wzb1kUGMDAwvG38/fffmmFhYVkKD4q7u7s4LCws6++//9Z8HefPzs5WMzY2HqR4hYSE6K5cuTLf0dFRIBKJ+BwO57kaXHPnzi2prKxUnjt3bmO4QERERFZoaKgBj8cTcjgc62PHjnU6GNXe3r5uzZo1eWPGjOFyuVyhq6srNzc3V+XBgwcqI0eO5PH5fOHs2bMHrl+//hEA+Pr6Fi9evHhA82DaAwcO6A4fPlysoaHRuPg/ffr08t9//11HV1dXHhwc/GDKlClWPB5POGXKlIEAsHHjxoLy8nIWh8Ox5vF4wtOnT7+0SHwbea+7J78KcXFx8Pb2RkFBAbZu3YqFCxe+VAG36GgSYCuTAf/7H2mvExFBSvJHRZFwkFeitpYIjc8/J+6c9rh3jyinoUNJQMzTGBsGBoZ3h3e5Mm1oaKhuVFRU75MnT2b3tC0MnYPpntyF1NXVwdPTEyoqKoiNjX2lXiPu7qSJ4PjxpO4aQCrMnjoFuLq+oqE1NWRt6cKF50vet0RREWBoSBoGnT9PSuq2FjzDwMDA8Abi5+fX79KlSzoxMTH3etoWhq6DWfrpBNXV1WhoaIC6ujqOHz+OxMTELmmINmwYyRK2tCTbn3/eBSKlupoEv164QJoAtSZSaJoEzZibA+fOkTFXV0akMDAwvHXs27cvNycnJ3nQoEEttIRleFthhEoHuXv3LhwcHLB5M2kpP2zYMOjr63fZ/Pn5QEVFF9VPq6oiedBXrpCYFF/flvcrLydZQAsXEg+Knd0rnJSBgYGBgaHrYYRKB4iIiICDgwNKSkrg6OjY5fNfuvSsXtr69eRn055/nSYjg+Q2HzxIirS1xPXrJGD2xAnSDfn0aeAVy/szMDAwMDB0NUyMShtIJBJ8/vnn2LlzJ0aOHInDhw+jb9++XX6euLjni7o2rZ/WqdIkUilZsvngAyA7G9DVbX3fxETyMzaWBM4yMDAwMDC8gTAelTa4desW9uzZgy+++AIXL17sFpECkPImzQWJiwsZ7zDl5WT5Zvt2st2SSHn8GLh4kfweEEDaMDMihYGBgYHhDYYRKi1w7x4JGHd0dERaWho2b94MlTc5uLSsjHQ8TEwE+vVreZ9z50gMyowZJGWZogAtrddrJwMDA0MTZDIZBAKB0MXFxaql99PT01U5HI7167YLAMRisZKHh4cFl8sVcjgca3t7e15FRYVScXExa9OmTZ3ughsTE6Pd2nV2hJUrV/ZpaXzQoEF8Pp8vNDExsdXV1bXj8/lCPp8vTE9PV+3IvFevXtU4fPiwTlv7zJkzp5+RkdEgubxnKvczQqUJMpkMq1evBp/Px8WnngdLRSrOm0pJCTBmzLMmgZ6ez78vlQIrV5L8Z0XDoVdqFsTAwPA+8vDhQxUHBwdeTk5Ol4UMfPfdd8ZWVlYtlsl/3TQv2Pn9998bGRkZSTMyMlLv3buXEhIS8kBVVZUuKSlh/fLLL0atTNNtBAcHm7Q0fvv27bS0tLTUVatW5bu7u5cpKvvyeLz6jswbHx+v+euvv7YqVORyOc6cOdPbxMSkvqcKzTFCBUBBQQGcnJwwevRofP/995gzZw6cnJx62qz2qa8H/vEP0gX5xIkXe/HU1ACjRgE//ADMn0+CXmxsesZWBgaGt5rVq1ebJCQkaH311VddsgZ+//59lbNnz+rMnz+/uLPHBgUFGdjY2Ah4PJ5w/PjxlmKxWKmsrEzJ1NTUViKRUAApVa/YTklJUXN2duZYW1sL7O3teUlJSeoA4OXlZT5z5sz+gwYN4gcEBJg1PUdBQYGKqalpo3qxs7OTaGho0MuXLzfLzc1V4/P5wgULFpg195T4+vr2Dw4O1geAyMhItoWFhbVQKBRERkY2VsOtrKxU8vb2Nre1tRUIBAJheHh4bwAIDg7WHzdunKWzszNnwIABNgsXLjQDgMDAQFOJRKLE5/OFHh4eFu19Pq1db0hIiK6iuq1IJOLV1dVRGzdu7BsdHa3L5/OFP//88wsxA7/++qs2h8OpnTdvXtHBgwcb2xXk5uYqjx071pLH4wl5PJ7w/PnzvQBg+/bt+lwuV8jj8YQfffRRu7Z2BCaYFkBAQACuX78OFouF0NBQfPrppz1tUsdQVQXmziVF2loqYaupCTg5kb4+n3zy+u1jYGB4K3B0dOQ1H5s6dWrpypUri9TU1D6or69vWgLe8MCBA4bKysq0VCpNLCgoUPb09HzO9Xzjxo02mxwCwGeffdZv8+bNj1rqh9MePj4+ZcuXLy8GgCVLlvQNDg42WL169RMnJyfxkSNHdGbPnl0eEhKiN2nSpDI1NTV63rx5A/bs2fPQ1tZWcvHixV4BAQH9r1+/ngEABQUFqomJiWnNOyj7+/sXu7m5caOionRHjRpVOX/+/BJbW1tJUFDQIzc3Nw1Fk8OYmJgWvQw1NTXUokWLzM+fP59ubW0tcXNzG6h476uvvjJxcXGpPHr06IPi4mKWSCQSeHh4VAJAamqq5q1bt1I1NDQarKysbFasWFG4c+fOvL179xq11lixOa1d76ZNm0zOnTuXYWFhIS0uLmapq6vTq1atyo+Pj+8VFhbWYlO3gwcP6n388celM2bMKN+wYYOpRCKh1NTU6IULF/Z3dnYWr1u37r5MJkNFRQUrPj5efcuWLSbXrl1LMzExkSl6Fb0q77VHRUNDAxRFISoqCgBxcf3zn/+Expu+NFJYCPz9N/l90aLnRUptLbB4MUlPBoD//pcRKQwMDC9NUlJSsq6urkzRIoSiKOjp6cnWrl376GXnjIiI0DEwMJA5OzvXvMzxCQkJGvb29jwulys8duyYfkpKijoA+Pv7F+3du1cfAMLDww38/f2LKyoqlJKSkrS8vb0t+Xy+MDAwcMCTJ08agw6nTp1a1lykAMDw4cNrs7Oz7yxbtuxxaWmp8vDhwwWJiYnqHbXx5s2b6mZmZhJbW1uJkpISfHx8ShTvXb58mf3TTz+Z8Pl84ciRI3kSiYTKzMxUBYCRI0dW6uvryzU1NWkrK6u6+/fvq3Xms2nrekUiUZWPj495UFCQgUwma3euuro66uLFizozZ84s19PTaxg8eHD18ePH2QBw9epV7S+++KIIAJSVlaGvry8/e/Ys293dvczExEQGAMbGxl0S1PJee1SysrKwYsUKnDx5EjU1NdDU1MSUKVOwZcuWnjatdQoKSOXYsjLS4VizSV+w1FQiSpKTSZnbwYN7zk4GBoa3hrY8IEKhsH7ixIllERERhqqqqrRUKqUmTpxYtm7duicAYGJiIuuIB6UpsbGxWufPn+9tamqqI5FIlKqrq5U8PT0tli5d+iQwMHAAAKxduzZPJBK1GL/i7+9vERkZmenk5FQbHBysf+XKFW0AGDduXPXixYvVYmJitOVyOeXg4FBXWlqqpK2tLWvNG6GlpdXQmp06OjoNfn5+5X5+fuW+vr6IiorSmTlzZlnTfVRUVOiGhmdTKJae2oKmaURGRmba2dk9V0E3Nja2l6qqamMDPhaLRUul0k41kZPL5Wjteg8ePJhz8eLFXqdOndKxt7cXJiQktOmhOX78OFssFrNsbGysAaC2tlZJXV29YcaMGa12tu4O3muPiomJCdhsNurq6qCuro66ujqw2Wz06dNicHXPk5cHfPghkJtLOhwrRApNk46GIhHxtpw5Q5Z7GBgYGLqAoqIiFR8fn6LLly/f9fHxKWrqkXgZduzYkVdYWHg7Ly/vzt69e7OGDRsmjoqKynZ1da1WBIP6+Pi0ejOsqalR6t+/v1QikVCHDh3Sa/re9OnTS+bMmWMxa9asYgDQ09NrMDMzqw8JCdEFgIaGBly7dq1dt/m5c+d6FRUVsQDiWcjIyFA3Nzev19HRkVdXVzfeOy0tLSWZmZkatbW1VHFxMSs2NpYNAIMHD67Ly8tTTUlJUQOApna6uLhUBgUFGSsEzl9//dWuPcrKynRHRFBb15uSkqLm6upavXXr1nxdXV1ZVlaWKpvNlldVVbWoBSIiIvS2bt36MC8v705eXt6dBw8e3ImNjWWLxWKlESNGiH/88UdDgCSilJSUsMaPH18ZHR2t+/jxYxYAMEs/XURhYSEWLlyI69evY+HChXj8+HFPm9Qyjx4RkZKfT4TI6NHP3ouIIMGyw4cDt251QctlBgYGhmecO3fu/v79+3OcnJxq9+/fn3Pu3Ln7r+vc2dnZasbGxoMUr5CQEN2VK1fmOzo6CkQiEZ/D4dQ13X/u3LkllZWVynPnzi1VjEVERGSFhoYa8Hg8IYfDsT527FjvF8/0PBkZGeojRozgcblcoY2NjXDw4ME1fn5+ZX369JHb29tXcTgc6wULFphZWVlJ3d3dy/h8vrWnp+dAa2vrGgDQ1NSkt23b9tDNzc1KKBQKDAwMGtdaNm3alC+TySg+ny+0srKyXrNmjWl79vj4+BQJBIIOBdO2dr3Lli0zU6RbOzg4VA0bNqx24sSJ4oyMDI3mwbRisVjpjz/+0PH29i5XjLHZ7AaRSFR16NAhnV27duVcuXJFW/H5JCUlqYtEorrly5cXODs783k8njAwMLCVehmdg6Jpuv293gJEIhEdHx/f02Z0HytWAHv2AGfPkgBZAKirA9TVSQry/v3Ap58CSu+99mRgYGiHu3fvQiAQAACSk5NrbGxs7vawSV1GaGioblRUVO+TJ09m97QtDJ3j1q1bBnZ2dubNx5m72tvCpk0kgNbJCWhoALZsAYRCUkdFRQWYM4cRKQzvNps3v9gA69IlMs7AAMDPz6/f119/bbp+/fr8nraFoetg7mxvAq19Aa9cCUyYQAJolZUBgQB48oR0Rv7iCxIsy4gThvcFB4fnu3Uqunk6OPSsXQxvDPv27cvNyclJHjRokKT9vRneFt7rrJ83BsUXsKIz4aVLgJcX8ZTIZEScmJiQqrKzZpGMn507gYULSSl8Bob3ARcXEkQ+dSopdHj58vPdPBkYGN5JGKHyJmBnRzoQuruTL+GYGIDFAuRy0kTQzo7s99//kmaDZ88Cgwb1rM0MDK8LqRT44w8gKoq8ysuByEhg9WpGpDAwvAcwQuV1U1lJmgfGx5NXXByph6Jg/37yU00NWLWKlMl/9AgwMwPCwkjwbK9ePWM7A8ProrKSZLdFRQGnTxNxoq4OfPABUFoK+PsD/+//kT5XjFhhYHinYYRKd1JTQyrExsU9Eybp6aTuCQAMGEBqn8yfT5Z5Vq8GJE+XVjU0gG++IS82m1SbnTQJGDq0p66GgaF7yc8HTp0i4uTiRSLSDQyAjz4izTZVVQE/P7KPiwvpbdV0yZSBgeGdhBEqXYVEQjoYN/WUpKSQDB2AxJg4OAAzZxJxIhIBhk87hSsrk2WeppQ/TV03MwP69CFZP//5D6CnR+qkTJ78rCMyA8PbCE2T/yOKJZ24ODJuaUmEuacnqQ3EelozavNm4MgRFIj4mL53NA5PO4w+R46Q4xih8lZRU1NDDR06lF9fX0/J5XLK3d297KeffnohUyc9PV3Vzc2Nc+/evZTXad+xY8fYq1evNgOAnJwcNSMjI6m6unqDQCCoOXHixIOOzBEcHKzv4eFRaW5uLm3pfalUCiMjI7sZM2YU79y5M68LzX/nYITKyyCVknL1TT0lt2+TcYCIB5GIPAkqREnfNhqOTp9OirbR9DNvC0CyfG7eJE+SZWXA+fPEDf7bb2R/iiIelkmTyGvIECYLiOHNRiYDrl59Jk7uP60b5uhIhLinJ0m7bylI/MsvAQAbfg1EbE4s1l9Zj52TdzIipbtZs8YYQ4fWwN1d3DgWHa2Nv//WxHffFb7MlOrq6nRsbGy6jo5Og0QioRwcHHgXLlyoGDNmTHWX2d1JpFIpVFRIwV0vL69KLy+vVIA0bNyyZUvuqFGjOtWXKDw83GDw4MG1rQmVEydOsC0sLCTR0dG627dvz1NivrtbpVs/GYqiJlAUlU5RVCZFUSvb2M+LoiiaoihRk7FVT49Lpyiqe0qtdqQug1xORElYGLBkCaljwmaT1OD584FDh4DevYHPPweOHgUePCBZOr/9BqxfD3h4tC1SAJKG3NBARIri6XHoUHJeVVWyratL3Nx795J05bg44OuvyXFff03EkKkpqacSGQlUvNZ+LFCaAAAgAElEQVRWDAwMrVNdDZw4QQoS9ulDqipv3w5wucDu3aQ1xN9/A199BVhbt5rJpvEfDVDfUtgVvwsNdAN2xe8C9S0Fjf+84U1E33aGDq2Br+9AREeTLsHR0drw9R2IoUNfqqEgACgpKUFHR6cBAOrr6ymZTEZRnchgDAoKMrCxsRHweDzh+PHjLcVisVJZWZmSqampraLMfGlpaeN2SkqKmrOzM8fa2lpgb2/PS0pKUgcALy8v85kzZ/YfNGgQPyAgwKy98+7cuVPP1tZWwOfzhTNnzhwgk8kgk8ng5eVlzuFwrLlcrvDbb781Cg0N1U1OTtb09fUdyOfzhVVVVS9cXEREhF5gYGBh37596y9cuNAYeBgZGckWCoUCHo8ndHJy4gKk0eC0adPMuVyukMvlCvfu3dtuZd13iW7zqFAUxQKwA8BYAI8AxFEUdYqm6dRm+2kDWArg7yZjQgDTAVgD6Avgd4qiuDRNd0knxkaapwVfvAhMmwZ89hmwfDnxlCQmAlVVZP9evUgwX2DgM0+JpeWrezFWrCBz2NgQz4y9fdviRknp2fm//poIo7NnibflxAkgNJQsJ40YQZaIJk1q/SmVgaE7KCwEoqOJ1+T330kV5d69yb9HT09SH0hbu8PTSeVSbJ+4HesurUN+FVkh0FTWxBTBFGwZ9wY3EX0LMNm4URX37vHa3MnYWIqpUzkwNJSiqEgFlpZ12LChLzZsaHl/G5sahITktjWlTCaDjY2NMCcnR83Pz++Jq6trh70pPj4+ZcuXLy8GgCVLlvQNDg42WL169RMnJyfxkSNHdGbPnl0eEhKiN2nSpDI1NTV63rx5A/bs2fPQ1tZWcvHixV4BAQH9r1+/ngEABQUFqomJiWktdVBuSmJionpkZKRefHx8mpqaGj1r1qz+u3fv1rezs6stKChQUSxPFRcXswwMDOS7du0yas0TU1NTQ/3111/s/fv3PywvL2eFh4frjR07tjo/P1950aJF5pcvX07j8/n1il45K1euNGGz2fKMjIxUAFD0IHpfaFeoUBTlDuBXmqZb7TDZCo4AMmmazno6zyEAngCad2vcAOAHAF80GfMEcIimaQmAbIqiMp/Od62TNrSNiwvw88/ky7NPH+INoWngu+9IhsHgweQp0MGBiAIe75nHo6s4e5a8ACAzE1i7Fti1C/jxx47PYWQEzJ5NXjIZcP06ES2nTxN3+ZdfAv37P1sicnVlMocYup709GdLOteukf9LAwaQDB1PT8DZmQSNd5Kcihw4/OyAJ9VPoKmsCQoUVFmqqJPXga3GRh+tN7SJ6LsEmy2HoaEUBQWqMDGpB5v9yg+NysrKSEtLSy0uLmZNnjzZMi4uTt3BwaGu/SOBhIQEjXXr1pmKxWJWdXU1a/To0RUA4O/vX/TDDz/0mT17dnl4eLjBzz///KCiokIpKSlJy9vb21JxfH19feNT29SpU8vaEykAcObMGe3k5GRNOzs7AQDU1dUpGRkZyT755JPy3NxcNT8/v37u7u4VU6ZMqWxvrsOHD/ceNmyYWEtLi541a1bZ4MGD+8pkstzLly/3cnR0FPP5/HoAMDY2lgPAH3/8wT506FBjeqihoWHXPrS/4XTEo/IJgK0URR0DEELTdFoH5zYF0FRRPwLwXMoKRVEfAOhH0/SvFEV90ezY682OfaFpE0VR/gD8AaB///4dNKsZY8aQ7ILsbOItCQggosTa+qW+VDvN6tXkp7IycPw4CZB1cXn5bAZlZWDkSPL6/nuS2vzbb0S07N9PXO1qaqTBoUK4WFl1+WUxvAc0NBBRrBAn6elkfMgQ4unz9CQ1gDrpyauqr8KRlCOoqq/CkqFL0I/dD14CL0ziTMIvib+gr3Zf+Nv7Y0/CHhRUFXTDhb1fFKxaVa9vY5Pe5k6K5Z6lSwuwb58h1q7Nfy5m5RUwMDCQOzs7i6Ojo3XEYjErMDBwAACsXbs2TyQS1bZ0jL+/v0VkZGSmk5NTbXBwsP6VK1e0AWDcuHHVixcvVouJidGWy+WUg4NDXWlpqZK2trYsLS2t+UMyAEBLS6tDD+E0TVPe3t4lO3bseCHwNTk5OfXEiRPs3bt3Gx4+fFjv6NGjD9qa69ChQ3rx8fFapqamtgBQUVHBio6OZnfEjveRdtcsaJqeBWAIgPsA9lIUdY2iKP+nSzYvDUVRSgD+C2D5y85B0/QemqZFNE2LDBUZNJ0lPp7Ef6xdC+TkkKWcwYNfj0iJiwPS0kjwrUKkAEScKLIZXhUzMxJLc+IE6Qv0++9kaevBA2DpUoDDIbEC//oXCdaVMJWnGdqgtpYUJJw/nyxPjhhBChH26wds2wY8fEiWS7/+mvw/6qBIoWkaV3OvYm7UXPTZ0gdzT83FoeRDoGkaFEVh5+SdcOO64cT0E9gxeQfs+thhx+QdOP7J8W6+YIZGkRIWloWtW/MRFpb1XMzKS5Cfn69cXFzMAoCqqirq0qVLbIFAUOfq6lqdlpaWmpaWlurj49NqoF1NTY1S//79pRKJhDp06JBe0/emT59eMmfOHItZs2YVA4Cenl6DmZlZfUhIiC4ANDQ04Nq1a50ObJowYUJlTEyMbl5enjIAFBYWsjIyMlQLCgqU5XI5Pv300/KNGzfm3blzRxMAtLS05BUVFS+44EtLS5Xi4uK0Hj16dDsvL+9OXl7enU2bNuUcPHhQ78MPP6y+ceOGdlpamqriHAAwevToyp9++slIMcf7tvTToeAKmqYrAUQCOATABMAUAIkURS1u47A8AE1bPJs9HVOgDcAGwGWKoh4AGAbg1NOA2vaO7RoUvUKOHCGBr0eOPN9LpDupqgJ8fMiyze3bpCptU1xcGrMcugw1NeJBCgoiAikzk9xcrKxI8axx40j6s6cn2c7J6drzM7ydlJQA+/aRqskGBuTf6uHDJCj2wAGgqIiI3EWLyBLjS7D20lqMCBmBwymH8Yn1J/hrzl/4a85f6EyAJUM38fffmggLy2r0oLi7ixEWloW//9Z82Slzc3NVnJ2deVwuVzhkyBChi4tL5YwZM1oUJtnZ2WrGxsaDFK+QkBDdlStX5js6OgpEIhGfw+E8t1w0d+7cksrKSuW5c+eWKsYiIiKyQkNDDXg8npDD4VgfO3as08Go9vb2dWvWrMkbM2YMl8vlCl1dXbm5ubkqDx48UBk5ciSPz+cLZ8+ePXD9+vWPAMDX17d48eLFA5oH0x44cEB3+PDhYg0NjcYUz+nTp5f//vvvOrq6uvLg4OAHU6ZMseLxeMIpU6YMBICNGzcWlJeXszgcjjWPxxOePn36lRwFbxsU3TQdtqUdKMoDwD8BWAEIA7CPpuknFEVpAkiladq8leOUAWQAGAMiMuIAzKRpusV8eIqiLgNYQdN0PEVR1gAOgsSl9AVwAQCnrWBakUhEx8fHt3ktL7B5M4k/abq8cukS8WR0tUhozpo1ZCkmKoo8efY0NTWkd8qvv5LXw4dk3MbmWUCukxPxNPXk58bQNbT3N8zKerak8+efZJnH1JRksXl6kqVDNbWXOrWsQYazmWfxS9IvWDlyJRxNHXGn8A5u5N3Ax9YfQ1vtvfoO7hHu3r0LgUAAAEhOTq6xsbG528MmdRmhoaG6UVFRvU+ePJnd07YwdI5bt24Z2NnZmTcf70iMiheAn2ia/qPpIE3TNRRFzW3tIJqmZRRFLQJwFgALJL4lhaKo9QDiaZo+1caxKRRFHQEJvJUB+KzLM36Alm+qLi7dW5ehtJTEiWzZQp5Q3wSRAgCams9iVrZvJx6X06eJaAkKAn74AdDRIV4XCwuSHRUZ+ayJosIzxdA2b4rIa57xduEC+ZtOngzY2gLJyWQ/W1uSNuzpSbLRXsHDkVmaiZCkEOy7tQ/54nwY9TJCbkUuHE0dYWtsC1tj2y66OIb3FT8/v36XLl3SiYmJudfTtjB0HR3xqFgAKKBpuu7ptgYAY5qmH3S/eR3npTwqr5uaGmDsWBKAyGIB9+6RrIg3ncpKEtuiyCQqeBrAqKxMCnXdukWWsRRZUYqXktLz222Nd/VYa+M9vZTQVNQ1F3mdEcg0TYLA6+tJXFFnf0okpCrs3r0Anw8kJRGviZISyc7x9CSvgQNf6XIVMSZSuRTGW4xRIanARKuJmDtkLty4blBhvYZYMIYXeJc9KgxvL6/iUTkKYHiTbfnTMYeuMe09QSYDPvnkWdrml1++HSIFIAXupk4lL5omwuT0aZJGffUq2WfPnp61sTO8DkHU1tiQIcDEiUQgpKWR4n4//US8Vh0VG/X1Xfd5JCQQW1atIh4Vff1Xmo6maSQUJOCXxF+Q+DgR1+dehwpLBRFeEbAxsoEp+4UEPgYGBoZW6YhQUaZpuvFbkabpeoqiVLvRpncPmia1JGJiyNNqWhq5KbyNUBRZriorIzfX1atJ4O2+fSQlWi5//tXQ8OJYa+Ovc9/uOJdUSoRER/ZVUyOCT1eXBKNWVpIxVVWyDNe797Pttn52ZJ/Wjrlxg1QyXriQ/A379XslkVJaW4rw2+H4JekX3C68DXVldUwTTkNVfRW01bQx3qp7CkwzMDC823REqBRRFOWhiCmhKMoTQHH3mvWOER9PbuRffw2sW0f6m7Df4pT55ssVY8YwXWw7g+LzUxT327Hj9X9uly4Bc+eStg+v8DdsoBsgkUmgoaKBi9kXsfTMUoj6irBz0k7MsJ2B3urvVaVvBgaGbqAjQmUhgAMURW0HQIEUcfPtVqveNRwcSFyKhQVx/3M4PW3RqxEX9/wNrWndF0aotE1zkfcqxf1ehVf8Gz4sf4jQm6EIvRmKeUPmYe3otfDgeeDmgpuw62PXzcYzMDC8T3Sk4Nt9mqaHARACENA0PZym6czuN+0d4MAB0u8EILEpHM6ztN+3mS+/fPFm1h11X95FngqEAhEfo/eOxmMHQdcV9+sML/k3PJZ6DOP2j4PF/1lg/ZX14OnzYN/XHgCgylJlRApDh6ipqaFsbW0FPB5PaGVlZb1s2bIWm5ulp6ercjgc69dtHwCIxWIlDw8PCy6XK+RwONb29va8iooKpeLiYtamTZs6XWE0JiZG28XF5aXLgK9cubLFXhGDBg3i8/l8oYmJia2urq4dn88X8vl8YXp6eodCNK5evapx+PBhnbb2mTNnTj8jI6NBcnnPVO7vUME3iqImAwgE8DlFUesoilrXvWa9A/z2G+kTtH07SUn+9luS3vmypf4Z3g2eCoQNf2xAbE4s1l9Z/8aLvKyyxhYjCLsdhvSSdKwbvQ5ZS7NwbvY5TOJM6kHrGF4bDx+qwMGBh5ycV25mq66uTsfGxqanp6enpqSkpF64cIHdtINwTyCVSp/b/v77742MjIykGRkZqffu3UsJCQl5oKqqSpeUlLB++eUXo1am6TaCg4NNWhq/fft2WlpaWuqqVavy3d3dyxSVfXk8Xoci7uPj4zV//fXXVoWKXC7HmTNnepuYmNT3VKG5doUKRVG7Qfr9LAZZ+vEG8Jakq/QQ16+TmhSDBpEYgP/8hwSfBgX1fHosQ4+i8R8NUN9S2BW/Cw10A3bF7wL1LQXVDaqok5ECmxKZBA2d7gHatVTUVWB3/G44/OwAy2BLZJeR2lm/ePyCrCVZ+ObDb2De27xHbWR4zaxebYKEBC189VUbrd07hpKSEnR0dBoA0iBQJpNRnalCHBQUZGBjYyPg8XjC8ePHW4rFYqWysjIlU1NTW4lEQgGkVL1iOyUlRc3Z2ZljbW0tsLe35yUlJakDgJeXl/nMmTP7Dxo0iB8QEGDW9BwFBQUqpqamjerFzs5OoqGhQS9fvtwsNzdXjc/nCxcsWGDW3FPi6+vbPzg4WB8AIiMj2RYWFtZCoVAQGRnZGLBVWVmp5O3tbW5raysQCATC8PDw3gAQHBysP27cOEtnZ2fOgAEDbBYuXGgGAIGBgaYSiUSJz+cLPTw8LNr7fFq73pCQEF1FdVuRSMSrq6ujNm7c2Dc6OlqXz+cLf/75Z93mc/3666/aHA6ndt68eUUHDx5sbFeQm5urPHbsWEsejyfk8XjC8+fP9wKA7du363O5XCGPxxN+9NFH7draETqijIfTND2IoqjbNE1/S1FUEIDfuuLk7yR375IUTxMTksJbVETK1P/zn6RBG8N7TdaSLEw+OBlJj5OeG5c2SCGRSaCurI51l9Zhy7Ut0NfQh76mPgw0DWCgaYBI70iwlFi4mH0RD8ofNI7ra5B99DU7n7FTIC7A9GPTcXjaYfTR6oOcihysubgGkamRqJXVYpDxIPzfhP+Dngb5fjLQNOiSz4HhDcPRkffC2NSppVi5sghqah+gSbdhHDhgiAMHDKGsTEMqTURBgTI8PS2fO/bGjbabHAKQyWSwsbER5uTkqPn5+T1xdXWt7qi5Pj4+ZcuXLy8GgCVLlvQNDg42WL169RMnJyfxkSNHdGbPnl0eEhKiN2nSpDI1NTV63rx5A/bs2fPQ1tZWcvHixV4BAQH9r1+/ngEABQUFqomJiWnNOyj7+/sXu7m5caOionRHjRpVOX/+/BJbW1tJUFDQIzc3Nw1Fk8OYmJgWvQw1NTXUokWLzM+fP59ubW0tcXNzayxK9NVXX5m4uLhUHj169EFxcTFLJBIJPDw8KgEgNTVV89atW6kaGhoNVlZWNitWrCjcuXNn3t69e41aa6zYnNaud9OmTSbnzp3LsLCwkBYXF7PU1dXpVatW5cfHx/cKCwtrsWfKwYMH9T7++OPSGTNmlG/YsMFUIpFQampq9MKFC/s7OzuL161bd18mk6GiooIVHx+vvmXLFpNr166lmZiYyBS9il6VjggVRR+FGoqi+gIoAen3w9AShw6R1M9z5wBjYxKnoqoKbNjQ05Yx9BD3S+9jR9wOjLMchwlWE2BtaI2bj29CTVkN9bJ6zLCdgaVDl4KtRjLB/jHwH1BlqaK4phgltSUorilGvjgfLCXyfz70ZijCb4c/dw5ddV2U/pu0Nll2Zhni8uOIyNEgYsa8tzkCHAIAAHeL7oKiKBhoGuDbK9/iz4d/YslvS3DE+wg0lDXwW+Zv8LPzw9wP5sLexJ7pt/O+k5SUjJEjBSgvVwZNE6+wrq4MS5e+UutqZWVlpKWlpRYXF7MmT55sGRcXp+7g4FDX/pFAQkKCxrp160zFYjGrurqaNXr06AoA8Pf3L/rhhx/6zJ49uzw8PNzg559/flBRUaGUlJSk5e3t3Sim6psIr6lTp5Y1FykAMHz48Nrs7Ow7J0+eZJ8/f549fPhwwZUrV9J69erVIXfnzZs31c3MzCS2trYSAPDx8Sn53//+ZwgAly9fZp89e7Z3cHBwHwCQSCRUZmamKgCMHDmyUl9fXw4AVlZWdffv31ezsrKStnae5rR1vSKRqMrHx8fcy8urzMfHp6y9uerq6qiLFy/q7Nq1K1dXV7dh8ODB1cePH2fPmDGj4urVq9qRkZHZAPlb6uvry3fv3q3v7u5eZmJiIgMAY2PjLglq6YhQiaYoqjeAHwEkAqAB/NwVJ38n+eYbUpfC5KmW+/xzUuit7yt7SxneIhroBvye9Tu23diGXzN+BUuJBUNNQ0ywmoBqaTUCRAHwt/fHnoQ9KKgqgIPps/qJYy3HYqzl2Fbn3j15Nza4bCBCpoYIGWnDs+8xXQ1dqCmr4UH5AyTkJ6C4phhWelaNQmVe9Dxczb363JxHU4+C+paCurI6xKvEUFZ65TAEhreJtjwgQmE9Jk4sQ0SEIVRVaUilFCZOLMO6dU8AACYmso54UFrDwMBA7uzsLI6OjtYRi8WswMDAAQCwdu3aPJFIVNvSMf7+/haRkZGZTk5OtcHBwfpXrlzRBoBx48ZVL168WC0mJkZbLpdTDg4OdaWlpUra2tqy1rwRWlparQoPHR2dBj8/v3I/P79yX19fREVF6cycOfO5G7yKigrd0PBsCsXSU1vQNI3IyMhMOzu759rVx8bG9lJVVW0sF89isWipVNqpJwW5XI7WrvfgwYM5Fy9e7HXq1Ckde3t7YUJCQpsemuPHj7PFYjHLxsbGGgBqa2uV1NXVG1prINldtBmjQlGUEoALNE2X0zR9DCQ2hU/TNBNM25TqapJievcuedowMSFF3rKeBiGaMpU43zcmH5yM8eHjcSPvBtaMWoOH/3qIVc6kyN/xT45jx+QdsOtjhx2Td+D4J8c7NXcv1V4w720OUV8RxluNh88gH3w6+NPG99eNXocLvhdwa+EtPPr8EWpX1yLe/1l7ic3/2IztE7fD3sS+UZCoK6vDx9YH2UuzGZHC8CJFRSrw8SnC5ct34eNThCdPXqn3QX5+vnJxcTELAKqqqqhLly6xBQJBnaura7UiGNTHx6fVm2FNTY1S//79pRKJhDp06JBe0/emT59eMmfOHItZs2YVA4Cenl6DmZlZfUhIiC4ANDQ04Nq1axrt2Xju3LleRUVFLIB4FjIyMtTNzc3rdXR05NXV1Y33TktLS0lmZqZGbW0tVVxczIqNjWUDwODBg+vy8vJUU1JS1ACgqZ0uLi6VQUFBxgqB89dff7Vrj7KyMt0REdTW9aakpKi5urpWb926NV9XV1eWlZWlymaz5VVVVS1qgYiICL2tW7c+zMvLu5OXl3fnwYMHd2JjY9lisVhpxIgR4h9//NEQIMt4JSUlrPHjx1dGR0frPn78mAUAXbX006ZQoWm6AcCOJtsSmqZfq5J645FKAW9v4NgxICPj2fjhwwCXSwJrGd55Mkoy8OX5LxsDYv3s/LB/yn7k/CsH613Wo692z3nUKIp4ShSM6D8Cnzl+Boe+DmigG6CurI56eT3Yamz00WoxA5LhfefcufvYvz8HTk612L8/B+fO3X+V6XJzc1WcnZ15XC5XOGTIEKGLi0tla0/p2dnZasbGxoMUr5CQEN2VK1fmOzo6CkQiEZ/D4Ty3XDR37tySyspK5blz55YqxiIiIrJCQ0MNeDyekMPhWB87dqzdSoQZGRnqI0aM4HG5XKGNjY1w8ODBNX5+fmV9+vSR29vbV3E4HOsFCxaYWVlZSd3d3cv4fL61p6fnQGtr6xoA0NTUpLdt2/bQzc3NSigUCgwMDGSKuTdt2pQvk8koPp8vtLKysl6zZk27T7M+Pj5FAoGgQ8G0rV3vsmXLzBTp1g4ODlXDhg2rnThxojgjI0OjeTCtWCxW+uOPP3S8vb3LFWNsNrtBJBJVHTp0SGfXrl05V65c0VZ8PklJSeoikahu+fLlBc7OznwejycMDAzs156tHaEjTQm3ALgG4Djd3s49SI80JWxoAPz8gPBw0utm/nwyXldHeqfo6pI+KkodygJneMtooBtwJvMMtt3YhjOZZ6CipILffX/HqAGjetq0DjH18FSYaJk8twTVWe8Ow9vJu9yUMDQ0VDcqKqr3yZMns3vaFobO8SpNCRcA+ByAjKKoOpAUZZqm6be4BnwXQNPAF18QkfLdd89ECgD83/+Rwm4hIYxIeUcprCrEyNCRyCzNRB+tPvj2w2/hb+//VnkkmoqSHZN3tLEnA8PbgZ+fX79Lly7pxMTE3OtpWxi6jnaFCk3TPVLg5Y2nvp708Fm8GPjqq2fjRUXA998D7u6Aq2vP2cfQ5dwtuos7T+7gY+uPYdTLCCP7j8T6D9fDS+gFVRbTp5OBoafZt29fLkibF4Z3iHaFCkVRLfqxaZr+o+vNeUugadKB9uxZknrcNH3zzz8BmQzYvLnn7GPoMuQNcpy+dxrbbmzD+azz0NfQx0f8j6DKUkWoZ2hPm8fAwMDwztORpZ8vmvyuDsARQAKA99NdEB0N/PQTcPw40LuFeKypU0lJdN0XCvwxvGWcv38eC39diKyyLJhqm+I7l+8w334+4z1hYGBgeI10ZOnHvek2RVH9AGztNoveZGJjSRqyrS3QQoEgJCUBQ4YwIuUtJuVJClRZquDoc2CsZYy+2n2xacwmfMT/CCqsV8rIZGBgYGB4CV4m0vMRAEFXG/LGc+cOiTvp3x/49VdAS+v59y9cAD74gPT2YXirkDfIceLuCbjuc4XNLhts+INUER5kPAh//vNPeFt7MyKFgYGBoYfoSFPCbRRFBT99bQfwJ0iF2veHhw+BCRMATU0Sl2LYrMO3XA4sXw6YmxMxw/DWsCtuFyyDLTH1yFTcL7uPTWM24afxP/W0WQwM7zQ1NTWUra2tgMfjCa2srKyXLVvWYqGh9PR0VQ6HY/267QNIHREPDw8LRd0Re3t7XkVFhVJxcTFr06ZNhu3P8DzNmxd2lpUrVzamFGZmZqoMHTqUa2lpaW1lZWW9YcOGF7o5//vf/+7D5/OFfD5fyGKx7BW/f/fddx3u/Nz0nC1x9epVDYqi7CMjI7s1C7gjHpV4kJiUBJB6Kv+maXpWdxr1xiGREHFy5gwRI80JCwNu3QI2bQLU1V98n+GNIvlJcmN34uzybFjoWuD4x8dxf8l9/Hvkv1+quR8DwzvLmjXGiI5+PvszOloba9YYv+yU6urqdGxsbHp6enpqSkpK6oULF9gXLlzo9cq2vgJS6fPtdL7//nsjIyMjaUZGRuq9e/dSQkJCHqiqqtIlJSWsX375pcM3+64iODi4sceeiooKgoKCHt2/fz8lLi7u7i+//GKUkJDw3M3nhx9+eKyo8qumptag+H3NmjVPXuacLbF//369Dz74oKppV+XuoCNCJRJAOE3T+2iaPgDgOkVRmt1p1BtDXR3J8OFygcREEpvSnOpqYPVqYNgwEr/C8EYia5AhMjUSo0JHwXaXLc7fPw8A2DhmIy75XcIUwRSmdDwDQ0sMHVoDX9+BjWIlOlobvr4DMXRozctOqaSkBB0dnQaANMyTyWRUZ5pfBgUFGdjY2Ah4PJ5w/PjxlmKxWKmsrEzJ1NTUVlFmvrS0tHE7JSVFzdnZmWNtbS2wt7fnJSUlqQOAl5eX+cyZM/sPGjSIHxAQYNb0HAUFBSqmpqaN6sXOzk6iofaXSlgAACAASURBVKFBL1++3Cw3N1eNz+cLFyxYYNbcU+Lr69s/ODhYHwAiIyPZFhYW1kKhUBAZGdmYfVFZWank7e1tbmtrKxAIBMLw8PDeABAcHKw/btw4S2dnZ86AAQNsFi5caAYAgYGBphKJRInP5ws9PDwsBgwYIB05cmQNAOjq6jZYWlrW5uTktBvlL5PJsGDBAjMbGxsBl8sV/vjjjwYA8PDhQxWRSMTj8/lCDodjfebMGa3m52w+V0NDA6Kjo/XCwsIexMbGsmtqahr/gKtXr+7D5XKFT6vTmgJAcnKy2vDhw7k8Hk8oFAoFitYCHaEj38wXAPwDQNXTbQ0A5wAM7+hJ3krq6wEPDyJStm9vvXBbSgopox8U9HyaMsMbQa20Fluvb8XO+J14VPkI5r3N8ePYH+Fo6ggAjR2JGRjeaxwdeS+MTZ1aipUri/Dhh9UwNpZi6lQODA2lKCpSgaVlHbKzyY2xoEAZnp6Wzx3bgSaFMpkMNjY2wpycHDU/P78nrq6u1R0118fHp2z58uXFALBkyZK+wcHBBqtXr37i5OQkPnLkiM7s2bPLQ0JC9CZNmlSmpqZGz5s3b8CePXse2traSi5evNgrICCg//Xr1zOI+QWqiYmJac07KPv7+xe7ublxo6KidEeNGlU5f/78EltbW0lQUNAjNzc3DUXTv5iYmBZrjdXU1FCLFi0yP3/+fLq1tbXEzc1toOK9r776ysTFxaXy6NGjD4qLi1kikUjg4eFRCQCpqamat27dStXQ0GiwsrKyWbFiReHOnTvz9u7da9RSo8H09HTV1NRUzdGjR1c1f685W7duNdDR0ZEnJyffra2tpRwcHPju7u6VERERumPGjKn44YcfHstkMojFYqUJEyZUtXZOAPj999979evXT2JtbS0ZOnSo+MiRIzqffvpp+ZEjR9inT5/unZCQkKatrd2g6Pczc+ZMixUrVjz29fUtr6mpoeRyeYdvmB0RKuo0TTd+ADRNV70zHpXNmwEHB5JOrODSJeDGDbKUc/48MGNG23M4OgI5OYBGuz2lGF4jxTXFMNA0gLKSMnbG7wTfgI8dk3ZgMmcyI04YGDoLmy2HoaEUBQWqMDGpB5stf9UplZWVkZaWllpcXMyaPHmyZVxcnLqDg0Nd+0cCCQkJGuvWrTMVi8Ws6upq1ujRoysAwN/fv+iHH37oM3v27PLw8HCDn3/++UFFRYVSUlKSlre3d6OYqq+vb7xJTp06tay5SAGA4cOH12ZnZ985efIk+/z58+zhw4cLrly5ktarV69Wuy035ebNm+pmZmYSW1tbCQD4+PiU/O9//zMEgMuXL7PPnj3bOzg4uA9AOi5nZmaqAsDIkSMr9fX15QBgZWVVd//+fTUrKytpS+eoqKhQmjp1quWmTZty9fT02rXr999/Z6elpWmeOnVKFwDEYjErNTVVfdiwYdULFiwwl0qlStOmTSsbPnx4i12rmxIeHq4/bdq0UgCYPn166f79+/U//fTT8vPnz7NnzZpVrK2t3QAAxsbG8rKyMqXCwkJVX1/fcoD0QQLQ4ZY8HREq1RRFfUDTdCIAUBRlD6Ddi3grcHAgyzVHjhCxcukS2XZ2Bk6cIDEn//xn68dfuQKMHMmIlDcEqVyKY3ePYduNbXhQ/gAPlj6ACksFyQHJ0FHX6WnzGBjeXNrygGhrN2Dt2nz4+g7E0qUF2LfPEGvX5sPdXQwAMDGRdcSD0hoGBgZyZ2dncXR0tI5YLGYFBgYOAIC1a9fmiUSiFu81/v7+FpGRkZlOTk61wcHB+leuXNEGgHHjxlUvXrxYLSYmRlsul1MODg51paWlStra2rLWPANaWlqt3uB1dHQa/Pz8yv38/Mp9fX0RFRWlM3PmzLKm+6ioqNCKLsgAER3tXTNN04iMjMy0s7OTNB2PjY3tpaqq2ngDZ7FYtFQqbXE+iURCTZ482dLb27vUz8+vvKV9WjgvFRQUlOPl5VXZ/L0//vgj/dixYzpz5syxWLRoUeGiRYtKWptHJpPht99+633u3Lne//3vf01omkZ5eblyWVlZt/SM6cik/wJwlKKoPymKigVwGMCi7jDmtePiQkTKxx8D69aRn56eRKQsWwZ8+WXrx968SY7fsuX12cvQIk+qn2D9lfUYsHUAZhybgcKqQnwx/AvIafLQx4gUBoZXQBGTEhaWha1b8xEWlvVczMpLkJ+fr1xcXMwCgKqqKurSpUtsgUBQ5+rqWq0I+vTx8WmxmzIA1NTUKPXv318qkUioQ4cOPRfIOX369JI5c+ZYzJo1qxgA9PT0GszMzOpDQkJ0ARJbce3atXafLs+dO9erqKiIBQB1dXVURkaGurm5eb2Ojo68urq68d5paWkpyczM1KitraWKi4tZsbGxbAAYPHhwXV5enqoiFqOpnS4uLpVBQUHGCoHz119/tWuPsrIyrRBBDQ0NmD59+gAul1v3zTffFLZ3rIKxY8dW7Nq1y1Axz+3bt9UqKyuVMjIyVM3MzKTLly8v9vX1LUpMTNRsfs6mnDp1is3j8WofP358Oy8v705+fv6dCRMmlB04cEB3/PjxleHh4QZisVgJAAoLC1m6uroNffr0qd+/f39vAKitraUU73eEdnekaToOAB9AAICFAAQ0TSd0ZHKKoiZQFJVOUVQmRVErW3h/IUVRdyiKuklRVCxFUcKn4+YURdU+Hb9JUdTujl5QpxkyBNDRATZsAAICSGXZefOIAGkt5oSmSTqyri7g799tpjG0jVROvKG3Ht/C15e/xiDjQYiZEYOMxRn417B/QV2ZycBiYHhl/v5bE2FhWY0eFHd3McLCsvD33y8dApCbm6vi7OzM43K5wiFDhghdXFwqZ8yY0aIwyc7OVjM2Nh6keIWEhOiuXLky39HRUSASifgcDue55aK5c+eWVFZWKs+dO7dUMRYREZEVGhpqwOPxhBwOx/rYsWMtlBV/noyMDPURI0bwuFyu0MbGRjh48OAaPz+/sj59+sjt7e2rOByO9YIFC8ysrKyk7u7uZXw+39rT03OgtbV1DUCWN7Zt2/bQzc3NSigUCgwMDGSKuTdt2pQvk8koPp8vtLKysl6zZo1pe/b4+PgUCQQCoYeHh8X58+e1Tp48qR8bG6utSDs+fPhwu09ky5YtK+bz+XW2trYCDodjPX/+/AFSqZQ6e/astkAgsBYIBMJjx47pffnll4XNz9l0noMHD+p5eHg858Xx8vIqO3LkiN60adMqJ06cWD548GABn88XbtiwoQ8AhIeHZ+/YscOIy+UKRSIRPzc3t8PZCxRNt71MRFHUZwAO0DRd/nRbF8AMmqZ3tnMcC0AGgLEgReLinh6X2mQfNk3TlU9/9wAQSNP0BIqizAHE0DRt09ELEYlEdHx8fEd3J2zeTDJ7vv4aGD2aBMauWkV69bTlTYmJIfVSgoNJU0KGbqVAXIDpx6bj8LTD0NPQw9GUo9h2YxtG9BuBoPFBoGkamaWZ4OhzetpUBoa3grt370IgIHU7k5OTa2xsbO72sEldRmhoqG5UVFTvkydPZve0LQyd49atWwZ2dnbmzcc7omjm0zTd2AOepukyiqLmA2hTqID0BMqkaToLACiKOgTAE0CjUFGIlKf0QieCa7oEZWXgm2/I73/+CcyeDaxY0fZyjlQKfPEFyQZauPC1mPm+s+GPDfjz4Z9wO+iGR5WPUFhdCK4+F9ZGpA4URVGMSGFgYICfn1+/S5cu6cTExNzraVsYuo6OCBUWRVEU/dT18tRT0pGubKZ4vt32IwBDm+/01GPz+dM5mzY6tKAoKglAJYA1NE3/2cKx/gD8AaB///4dMKkZMhmwfj2wdi1ZxomJISJFJmv9mLw88nPzZkCFKavenWj8RwN1smde3YQCsuKoqqSKu5/dhRLVLXFbDAwMbyn79u3LxfP3HYZ3gI58058BcJiiqDEURY0BEAHgt64ygKbpHTRNWwL4N4A1T4cLAPSnaXoIiIg5SFHUCyV6aZreQ9O0iKZpkWHzsvYd4csvgTVrSL2UkhIgMBD4/PO2l33MzUnfHw+Pzp+PoVNkLcnCTJuZ0FQmS+HqyurwsfXBw2UPGZHCwMDA8J7QkW/7fwO4CBJIuxDAHZCib+2RB6Bfk22zp2OtcQjARwBA07SEpumSp78nALgPgNuBc3aeS5eAq1eJV2XXLrLdGmfPAmIxWTJiirt1OybaJmCrsVEnr4O6sjrq5fVgq7HRR6vN9hMMDAwMDO8QHcn6aQDwN4AHIHEnrgA6EngVB4BDUZQFRVGqAKYDONV0B4qimgYWTAZw7+m44dMlJlAUNRAAB0BWB87ZORR1U44cIUtAilTllsTKgwfEi7JqVZebwdA6hdWFWGi/ENfnXsdC+4V4XPW4p01iYGBgYHiNtBqjQlEUF8CMp69ikPopoGnapbVjmkLTtIyiqEUAzgJgAQihaTqFoqj1AOJpmj4FYBFFUf8AIAVQBsDv6eGjAKynKEoKoAHAQpqmS188yysSF/es2BvwrK5KXNzz1WoBIlBYLGDlC1nWDN3I8U+ON/6+Y/KONvZkeNfZ/P/Zu/O4qKv9f+CvMzMw7MiwjOzgMCsDmCCmoWhlgIG5L5FLZrhcb/3U7v2amrcwl2/3Yl1uqWkpoaIZclHIb2m5UFoquCSb7IKALLLvs3x+fwxDiKwKonKejwcPZs7n8zmf98xHmfeccz7nXPgEo21GY5Lzn/83z+aexZWiK/j7C91011IU9VTrbjBtOoBfAAQyDJMFAISQ1X2pnGGYkwBOdijb1O7xu10cdwzAsb6c66F0NhZl0qQHk5RLl4AjRzTjWezsHjyGoqgBN9pmNOZEz8HRWUcx0WkizuWda3tOPV2ysrJ0goODncvLy3UIIVi0aFHZBx980OmqvgYGBs81NDRce5zxXb58WX/hwoXOgGYtICMjI5WxsbGKx+MpL168mNGbOg4cODBMJpM1eXp6drksQOs8Kk3x8fH932PwDOkuUZkBTXfNWULID9CMIRl6AzMYRjPAls/vfpAtRVH9qq6lDrmVuciuzEZ2RTZyKnPgNMwJLx94Geb65mDA4Oiso/e1sFD9b+OZjfwxtmMagsStE74BiLsVZ3yp8JLBxy9+3OtZUdvT0dFBWFjYHR8fn4bKykrWc889J5syZUpNdx/qA02hUECn9U5Ob2/vRu2U+zNnznQKDAysfvPNNyu7raCD2NjYYUqlsrqr13T16lU9tVqNy5cvG9XU1LBMTEx6tYbQUNTlGBWGYWIZhpkHzay0Z6GZSt+KELKLEPLK4wpw0NXUAIaGmplrjR96xmjqIXxy4ROczb1/vNDZ3LP45MIngxQR1Z8YhsHduru4kH8BkTci8eG5D7Hgvwsw7utxGP6v4TDeZgz33e6Y/u10vHf6PRy6eQhqRg2xuRhlDWVY4bWCJimPwRjbMQ0LYxeOiLulmTI/7lac8cLYhSPG2I5peNg6HR0dFT4+Pg0AYGZmphYIBI35+fm9mfYCABAVFWXq7u4ukUqlsnHjxokKCgo4KpUKjo6O8qKiIg4AqFQqODg4yIuKijhFRUUcPz8/gVwul8rlcumpU6cMAWDNmjU206ZNcx41apRkxowZzt2fFYiJiTEZOXKkRCaTSQMCAkZUV1ezAGDlypW2AoHAVSQSyUJCQuxOnz5t+NNPPw3buHGjnUQikWmn0W8vMjKSN2fOnHsTJkyoiYqKapsp9/z58wbPPfecRCwWy9zc3KSVlZUspVKJkJAQO6FQ6CoSiWRbtmyx6u179SzocR4VhmHqAURBc4uwGYDZ0NwJdGqAY3symJpq7vahHrv2Tf2TnCfhbO7Zp76pf6iNs2hWNuN29e22FpHsymxkV2oe51TmoEHx52cdAYGdiR0EPAECRYEYYTYCAjMBBDwBRpiNAE+f1/Zv4IMJH2BX4i5McppEk5VHtO36Nt3M3zLF3e3DN+QrZhydIbQ0sFSUNZTpCMwETZsTNttsTtjc6f5yK3nDvtf29Wo+k1u3bummpqYa+Pr61vU25smTJ9fNmzcvncViYceOHRahoaHD9+7de2fWrFn3vvrqK96mTZtKjx8/biKVShttbGyUQUFBzmvWrCnx8/Ory8zM1PXz8xPm5OSkAEBmZqbepUuX0o2MjLqdcLS4uJizdetW64SEhAwTExP1hg0bhm/evJn/3nvvlZ48edIsJycnmcVioby8nG1hYaF6+eWXq7priYmNjeWdPn064+bNm42ff/651fLlyyuamppIcHCw4NChQ9m+vr4NFRUVLCMjI3VYWJhlfn6+bmpqaoqOjg5KSkqG1BLwvZ5rH9DMSgtgT+vPs+///g+QyQBHx8GOZEia5DwJR2cdxazvZuG54c/h9zu/482RbyKtPA2ZFZnQYemAw+Lc96PD7qTsIfcjA3AL+rOYfFU2VrYlH9kVfyYi2ZXZKKguANNuwml9jr4mAeEJ8LLzyxDwBBCYaRIRp2FO4HIe+OLZpv17Ncl5EiY5TbrvOTVwTLgmKksDS0VxXbGutZF1iwnXRNUf9VZXV7NmzJgh2L59ewGPx+t110dubq7utGnT7MrKynRaWlpY9vb2zQCwYsWK8qlTp7ps2rSpdN++fRaLFy8uB4ALFy6YZGZmtk2rUVdXx9a2hvj7+1f1lKQAwLlz5wyzs7P1vL29JQCgUCiIp6dnnbm5uYrL5arnzp3rFBgYWDV37twuF1PUSkhIMODxeEqhUNji7OzcsmLFCqeSkhL27du3da2srBS+vr4NgGZBRQA4c+aMyfLly8u0XVN8Pr9f3v+nRZ8SlSHl3j3g9deBCROA48cHO5oha5LzJPi7+CPqZhQA4PMrnz+2c7MI65GSoa72HWU9ClOipsDV0hWpZamY6zoXN0puIKcyByZcExhzjWGsa/zA7+4+xPuqLy07KrUKd2ru/NkiUpGNnKo/k5KqpvtXmLcytILATIAJjhMwYtiIthYRgZkAw42GP3QCeKXoyn1JiTaRvVJ0hSYqj+D9ke+3yOXyW93to+3ueXfMu8Xf3PjG8oMJHxS1H7PyMJqbm8mrr74qmD17dsWiRYuqAM0g28DAQCEALFmypOzvf/97WWfHrlq1yuHdd9+9GxwcXB0fH28cGhpqAwAuLi4KCwsL5YkTJ4yvX79uGBsbmwNouhmvXr2aZmBg8EBCYmho2KsEiWEY+Pj41MTFxT2whtD169fTTpw4YRIdHW22a9cuq99//73bAbcHDhzg5eTk6Nna2roBQH19PfvgwYNm48ePr+9NLEMNTVS6EhqqGZ+ydetgRzKknc09i1PZp7DuhXXYe3Uvvp76Ncbaj4VCpYBSrbzvR6HupGyg9mN6PrZR2djlOXRYOkgqTgKbsBFxIwK40fN7ocPS6TKJMeGadFre1e9R1qPua404mXkSb8S8gTXPr8GO33bcl5TkVeVBoVa0xcFhceA0zAkCMwG8bb3bWkS0CYmRrtGA/FvorGtskjPt+hlo2iQlclpkTpA4qPYl55dq2z9/mDrVajXmzZvnKBKJmj788MO2AbkuLi4K7SDW7tTW1rIdHBwUABAREWHeftuSJUvKli5d6jxz5sx7HI7mI87Hx6dm27ZtVps3by4BgIsXL+qPGzeusS8xT5w4sX7t2rUOycnJXLlc3lxTU8PKy8vTcXR0VNTV1bHmzp1b/fLLL9cJBAI3ADAyMlLV1NQ8MA5UpVIhLi6Od/369RQnJycFAMTFxRlv2bLF+i9/+cu90tJSnfPnzxv4+vo2VFZWsoyMjNQvvfRSzZdffmkRGBhYo+36GUqtKjRR6UxGBrBzJ/D224Cr62BHM2R1bOp/RfDKM9HUr31d/+/5/4ddibsQNSMKnjaeqG2uRW1L7X2/a5prHiirbfnzcVVTFQqqC+7bpmZ614LOZXPxUuRLMNAxQL1C80Xug3MfAABMuaYQ8ATwGO6BGdIZ940XsTOxA4dF/3QMFZcKLxm0T0qCxEG1kdMicy4VXjJ42ETl9OnTRrGxseZCobBRIpHIAOCjjz4q7KzbpKmpicXn8921z1esWFGyYcOGovnz5wtMTU2VPj4+tfn5+W3NjfPnz69etWoVOyQk5J62bM+ePQVLly51EIlEMpVKRcaMGVM7bty4/L7EbGNjo/zyyy/z5s2bN6KlpYUAwD/+8Y9CU1NTdWBgoEtzczMBgM2bNxcAQHBwcMWKFSucdu/ezY+Ojs52dXVtBoAffvjBiM/nt2iTFAAICAioffPNN0eUlJRwDh06lP3OO+84NDU1sfT09NQJCQkZq1evLsvIyOBKJBJXDofDLFq0qGz9+vWdtjY9i0jrWoNPPS8vLyYxMbF/Kps+HfjpJyArS3NbMjUonsWBpx2Tr47PHxXDMGhQNHSe3HTy+2zeWVy7ew2TnCYhxDOkrXWEp88bkDE61JMhLS0NUqkUAJCcnNwgl8t7M9v4UyEhIcFg9erV9klJSd12Z1FPnhs3blh4eHg4dSynX4s6Uio1ycnGjTRJGWTPYlP/QI+zIITAUNcQhrqGPa6JdDb3LCL/iGy7g4ZvyMdo29GPHANFDZb169cPj4iIsNy/f/8D40iopxdtUaGoIWigW3aoJ9uz3KJCPb26alHpzerJQ8ePPwK//TbYUVDUgOuuZYeiKOpJQrt+tBoagKVLAWtrzdo+tH+eeoY9i91qFEU9m2iiorVjB3DnDhAVRZMUiqIoinpC0K4fALhxA/jHP4CAAGD8+MGOhqIoiqKoVjRRAYD58wG1Ghg2rOd9KYqiqEeSlZWlM2bMGJFAIHB1cXFx3bx5c5eL7BkYGDz3OGPTUqlUWLx4sb12IUC5XC5NT0/XBYB169Z1f0tdJ27duqUrFAofemKu0NBQq9ra2gc+sydPniyQSCQyBwcHubGx8UiJRCKTSCSy06dPG/Y2rt27d/N6OjeXyx117969QVljaGgnKvr6mm6etNYB74cPa57r63d/HEVR1BBzu+q2zui9o8X51fmPPGRAR0cHYWFhd7Kzs1OuXLmS9vXXX1slJSXp9UecD0uhUNz3/KuvvuLdvXtXJz09PSUjIyP1+PHjWebm5ioACA8Pt37c8X355Zf8urq6Bz6zT58+nZ2enp66c+fO215eXnXp6emp6enpqZMnT+7VdPyZmZncb7/9tttEJTo6mieXy+sPHjw4KN/mh3aikpOjWc/HwEDz3MAACA4Gcukt+BRFUe1tOLPBOqkoyWj9z+ttHrUuR0dHhY+PTwMAmJmZqQUCQWN+fr5ub4+PiooydXd3l0ilUtm4ceNEBQUFHJVKBUdHR3lRUREH0LSIODg4yIuKijhFRUUcPz8/gVwul8rlcumpU6cMAWDNmjU206ZNcx41apRkxowZzu3PUVxcrMPn8xVstqYRQSAQKCwtLVUrV660bW5uZkkkEtnUqVOdO7aUbNq0ib9mzRobAPjll18MxGKxTCwWy3bs2NHWaqRUKrFs2TI7uVwuFYlEsn/+858WABAfH2/s7e0t9vf3H+Hs7Ow6depUZ7VajY8//tiqtLRUx9fXVzRmzBhRT+9PV6/3+++/N9K2uEilUlllZSVrw4YNtomJiUYSiUT20UcfPdCylZKSwm1oaGCHhoYWHj16tC2hqa6uZs2aNctJJBLJRCKRLCIiYhgAREdHm8hkMqlYLJaNHTu2x1h7Y2gPprW2BkxMgKYmQE9P89vEBBje51Y9iqKop5b3Xm9xx7IZ0hkV63zWlXE/5o5qUbW03WFw6OYhy0M3D1lyWBxG8YHianFtMee1I68J2h97+e3LvZ4V9tatW7qpqakGvr6+db09ZvLkyXXz5s1LZ7FY2LFjh0VoaOjwvXv33pk1a9a9r776irdp06bS48ePm0il0kYbGxtlUFCQ85o1a0r8/PzqMjMzdf38/IQ5OTkpAJCZmal36dKl9I4rKC9YsKBiwoQJEolEYjx+/PiaxYsX33vhhRcad+7cWRgREWGlXZPo1q1bXSZYb731ltO///3v/ICAgLply5bZacs/++wzC1NTU1VycnJaY2MjGT16tCQoKKgGANLS0vSvX7+e4+TkpPD09JScPn3aaOPGjaW7du3inz9/PsPa2lrZ0/uzbNky+85eb1hY2PDw8PDbr7zySn11dTXLwMBAvWXLlsKwsDD+2bNnszqrKzIy0mz69OkV/v7+dW+//bZeQUEBx97eXrlu3TprExMTVUZGRioAlJWVsYuKijirVq1yOnfuXLpEImkpKSnpl66ioZ2oAEBJCbB8ORASAuzZAxQXD3ZEFEVRT4xrIdeSffb7SKuaqjgMGBAQmOmZKd99/t1H/mNZXV3NmjFjhmD79u0FPB6vd4tUAcjNzdWdNm2aXVlZmU5LSwvL3t6+GQBWrFhRPnXqVJdNmzaV7tu3z2Lx4sXlAHDhwgWTzMzMtj79uro6dnV1NQsA/P39qzomKYCmBSUrKys5Li7O+OeffzaZMmWKODIyMvu1117r1fpG5eXl7NraWnZAQEAdACxZsuTemTNnTAHgp59+MklPTzc4ceKEGaBZZDE1NVVPV1eXcXNzqxcIBAoAcHV1bcjOzu51S5NWV6/3+eefr3vvvffs58yZUzF//vxKgUDQ43seExNjHhMTk8VmszFlypTKAwcOmK1fv74sISHB5MiRIzna/SwtLVVRUVGm3t7etRKJpAUA+mvhRJqoxMT8+fiLLwYvDoqiqEHSXQuIzErWEiAMqDx887ClLluXUagUJEAYULnJd1MpAFgbWyv70oKi1dzcTF599VXB7NmzKxYtWlQFaAbZBgYGCgHNKsh///vfO114b9WqVQ7vvvvu3eDg4Or4+Hjj0NBQG0Cz+rKFhYXyxIkTxtevXzeMjY3NATRrYF29ejXNwMDggYTE0NCwyw9rfX19Zs6cOTVz5syp4fP5ipiYmGEdExUOh8Oo1X9W0dTU1OOQCoZhSFhYWP7MbZh48wAAIABJREFUmTNr2pfHx8cbc7ncthjZbDaUSmWf58vo6vVu3br17rRp06qPHz9uOn78eMn333+f2V09ly9f1r99+zbX399fBAAKhYLY2dm1PO4FEYf2GBWKoiiqR2X1ZTrB7sFl5xafSwt2Dy4rrS/VeZT61Go15s2b5ygSiZo+/PDDEm25i4uLQjsYtKskBdC0QDg4OCgAICIiwrz9tiVLlpQtXbrUOSgoqILD0XwX9/Hxqdm2bVvb+IuLFy/2eMfEr7/+apCXl6cDaMa73Lx5U9/R0bEF0CQn2tWS7ezslBUVFZy7d++yGxsbyY8//mgKABYWFipjY2PVjz/+aNQaZ9v4jsmTJ1fv2rXLUlvHH3/8wa2pqen289jQ0FClbQXqSVevNyUlhevt7d24ZcuWu+7u7vXJycl6pqamqrq6uk67aCIjI3lr164tKiwsvFlYWHiztLT0j5KSEp2MjAxdX1/fmk8//bTtHGVlZeyJEyfWX7582Vh7dxTt+qEoiqIei1MLTmVrH4+1G5v/qPWdPn3aKDY21lwoFDZKJBIZAHz00UeFc+fOre64b1NTE4vP57trn69YsaJkw4YNRfPnzxeYmpoqfXx8avPz87na7fPnz69etWoVOyQk5J62bM+ePQVLly51EIlEMpVKRcaMGVM7bty4bl/H3bt3OcuWLXNsaWlhAcDIkSPr161bVwoAwcHBZVKpVCaXyxtOnDiRu3bt2uLRo0dL+Xy+wsXFpUlbx9dff523dOlSJ0IIJk6c2NZ6snr16vK8vDyum5ublGEYwuPxFCdPnsx+MIo/LVq0qNzf31/E5/NbLl26lNHdvl293k8++cTq4sWLJoQQRiwWN86aNauaxWKBzWYzYrFY9vrrr5f/4x//KNXWExsby4uLi7uv1SUgIKDym2++4W3btq34zTffdBAKha4sFotZv3590aJFi6rCw8Pzpk+f7qJWq2Fubq64ePFit602vUEXJaQoihpinuVFCRMSEgxWr15tn5SU1OfuKGpwdbUoIW1RoSiKop4J69evHx4REWG5f/9+OsfEM4SOUaEo6qlW3NwM32vXcLe5ebBDoQbZ1q1b7xYVFd308/Pr9a3O1JNvQBMVQog/IeQWISSLELKuk+3LCSE3CSHXCSG/EkJk7ba933rcLUKI30DGSVHU02tzXh5+ra5GaF7eYIdCUdQAGLCuH0IIG8AXACYDuAPgCiHkBMMwqe12i2IYZnfr/lMB7ADg35qwzAPgCsAGwE+EEBHDMP1yTzZFUU+3JpUKRr/8gvZ/EHYVF2NXcTE4hEDh6ztosVEU1b8GskXFG0AWwzA5DMO0ADgC4LX2OzAM0/4eckMA2pG9rwE4wjBMM8MwuQCyWuujKGoIYhgGGQ0NaFJpUpPt+fltSYp2kgkuIdAlBEdaB4lSFPVsGMhExRZAQbvnd1rL7kMI+QshJBvAJwDe6cuxFEU9u2qVShwvL8fKjAwILl2C+PJlnK2qAgAsGD4ccXI5pPr6YKBJVpoZBv48HmZadbkQL0VRT6FBH0zLMMwXDMMIAPwPgI19OZYQEkIISSSEJJaVPdaJ8iiK6mcMw6BOqVnGJKOhAeYXLmBacjIOlJTA3dAQu4RCPGdkBABoUKnw8e3bSGtshAmbDQaAp5ER2KTPk3hSg2T27NlOPB7Po/2Cfp0xMDB47nHFpHX58mV97eJ9pqamI21tbd0kEols3LhxvV5k78CBA8N6WhFaIpHIAgMDRzx6xM+2gUxUCgHYt3tu11rWlSMApvXlWIZh9jAM48UwjJelpeUjhktR1ON2T6HAkZISLE5Lg81vv+FvOZqlQ1z09fG+gwPOenjg3gsvINbNDcttbTGMw8HGnByMSkpCdlMT1js4QJfFwgeOjrjd3Iy/2tKG1/62MSeHH1debty+LK683HhjTg7/UepdsmRJ+YkTJx55MrD+olAo2h57e3s3amfIffnll6s+/vjjO+np6akXL17sdqK19mJjY4f98ccfXc6Ae/XqVT21Wo3Lly8b9TQr7VA3kG/OFQBCQogzIUQXmsGxJ9rvQAgRtnv6KgDtP9oTAOYRQriEEGcAQgCXBzBWiqIeg/YTTM5IToblhQuYn5aGE/fuwdfUFK+YmQEAWITgI2dnTDQzgy5L82cqoaoKHomJ2JKfj9etrLBXJMKe4mIclckQ6uyMozIZ5qSm4mxl5aC8tmfVGBOThoXp6SO0yUpcebnxwvT0EWNMTBoepd6AgIA6S0vLHlcC7kxUVJSpu7u7RCqVysaNGycqKCjgqFQqODo6youKijiAZtp7BwcHeVFREaeoqIjj5+cnkMvlUrlcLj116pQhAKxZs8Zm2rRpzqNGjZLMmDHDuafzxsTEmIwcOVIik8mkAQEBI7RT2q9cudJWIBC4ikQiWUhIiN3p06cNf/rpp2EbN260k0gkspSUFG7HuiIjI3lz5sy5N2HChJqoqKhh2vLz588bPPfccxKxWCxzc3OTVlZWspRKJUJCQuyEQqGrSCSSbdmyZUj1bw7YXT8MwygJIasA/AiADWAfwzAphJBQAIkMw5wAsIoQ8jIABYBKAItaj00hhBwFkApACeAv9I4fino6FTc348eKCvxQUYG0hgZc9/ICIQTexsbwMDKCP48HL2PjLrttqhQK/E9ODvYUF8NZTw+n3N0xmcfDJ/n5OCqTYVJrcjPJzAxHZTJcqa1tK6N6tq2uTjczKUnc3T58HR3FjJQUoaWOjqJModAR6Ok1bb5922bz7dud7i83NGzYJ5EUdLqxH0yePLlu3rx56SwWCzt27LAIDQ0dvnfv3juzZs2699VXX/E2bdpUevz4cROpVNpoY2OjDAoKcl6zZk2Jn59fXWZmpq6fn58wJycnBQAyMzP1Ll26lN7ZCsrtFRcXc7Zu3WqdkJCQYWJiot6wYcPwzZs38997773SkydPmuXk5CSzWCyUl5ezLSwsVC+//HJVYGBg9Ztvvtlp5hwbG8s7ffp0xs2bNxs///xzq+XLl1c0NTWR4OBgwaFDh7J9fX0bKioqWEZGRuqwsDDL/Px83dTU1BQdHZ1+W0PnaTGgM9MyDHMSwMkOZZvaPX63m2O3ANgycNFRFPUoipubMS81Fd/KZBjOfeALI2LLyvBhXh5u1NcDAIbr6sKfx0O9SgUjDgfrHB17PEdMWRlWZWaipKUF79nb40MnJxiyNX+j/+7g8MD+k8zMaJIyAEw4HJWljo6iuKVF11pXt8WEwxnUL465ubm606ZNsysrK9NpaWlh2dvbNwPAihUryqdOneqyadOm0n379lksXry4HAAuXLhgkpmZ2dYNU1dXx9a2hvj7+1f1lKQAwLlz5wyzs7P1vL29JYBmJWFPT886c3NzFZfLVc+dO9cpMDCwqrP1ijpKSEgw4PF4SqFQ2OLs7NyyYsUKp5KSEvbt27d1raysFL6+vg0AwOPx1ABw5swZk+XLl5fp6GjWguTz+UPqizudQp+iqIfSfqK1vzk44IeKCvxYUYEPnZww0tgYOiwWzHR0sH3ECPjzeHA3NATp5WDXwuZmrMrMRGx5OZ4zMkKcmxs8jY17PpDqs/eNjFrkcnm36+Jou3vetbUt/qakxPIDR8eiIAuL2v6OJSsrSycwMFAIaFZB7moF5VWrVjm8++67d4ODg6vj4+ONQ0NDbQDN6ssWFhbKEydOGF+/ft0wNjY2B9B0OV69ejXNwMDggYTE0NBQ3ZvYGIaBj49PTVxc3APT81+/fj3txIkTJtHR0Wa7du2y+v3337sdy3LgwAFeTk6Onq2trRsA1NfXsw8ePGg2fvz4+t7EMtTQATwURfWJfkICyLlz2FVcDDU0E62NuHQJKzMzcaO+HsUtLQCAV83NcXbkSPyPgwM8jIx6laSoGQa7Cwshu3wZP1RU4JMRI3B51CiapAwibZISKZHkfCYUFkVKJDntx6z0JxcXF4V2EGtXSQoA1NbWsh0cHBQAEBERYd5+25IlS8qWLl3qHBQUVMHhaL6L+/j41Gzbtq1tXMfFixe7HOTalYkTJ9YnJiYaJScncwGgpqaG9ccff3Crq6tZFRUV7Llz51bv3r27ID093QAAjIyMVJ0NklWpVIiLi+Ndv349pbCw8GZhYeHNw4cPZ3333Xc8d3f3ptLSUp3z588bAEBlZSVLoVDgpZdeqvnyyy8ttAN+h1rXD01UKIrqk5wxY/C6lRX0Wwe5sqC5NfiXkSORM2YMAszNu6+gC2n19fC9fh0rMjMx2tgYyaNH428ODuCw6J+pwXSppsYgUiLJ0bagBFlY1EZKJDmXamoMHqXeoKAgZx8fH0lubi6Xz+e7f/rppxad7dfU1MTi8/nu2p8PP/yQv2HDhqL58+cLXF1dpebm5vcNyJ0/f351Q0MDOyQk5J62bM+ePQVXr141FIlEMoFA4Pr555/3+TZRGxsb5Zdffpk3b968ESKRSObl5SW5efOmXlVVFdvf318oEolkY8eOFW/evLkAAIKDgyvCw8OHS6XS+wbT/vDDD0Z8Pr/Fycmp7TajgICA2qysLP2SkhLOoUOHst955x0HsVgsmzhxoqihoYG1evXqMjs7uxaJROIqFotlX3/9Na+v8T/NSPtR+E8zLy8vJjExcbDDoKghYcWtW9hTXAxdFgstajWWWVtjp7jb8ZhdalGrsT0/H1tu34Yhm40dAgEWDR/e624iqu/S0tIgbZ3BNzk5uUEul6cNckj9JiEhwWD16tX2SUlJ3XZnUU+eGzduWHh4eDh1LKdjVCiK6rMShQLLbWwQYmODPUVFbd09ffVbdTXevnULKQ0NmG9lhc9cXGClq9vP0VJDxfr164dHRERY7t+//4FxJNTTiyYqFEX1WYxc3vb4C1GvJ+tsU6NUYn1ODnYWFcGOy0W8mxtefcguI4rS2rp1692tW7feHew4qP5FExWKoh6ruPJyrMzMRGHrTLIfOzvDmEP/FFEU1Tn614GiqMfibnMz3s3KwtGyMsgNDfGdTIbnTU0HOyyKop5wNFGhKGpAMQyD/XfvYm12NhpUKmx2csLfW9fooSiK6glNVCiKGjCZDQ1YlpGBs1VVmGBqij1iMcQGj3RXK0VRQwz9SkNRVL9TqNXYfvs23BMTcbW2Fl+KRDg7ciRNUqg2s2fPduLxeB5CodC1u/0MDAyee1wxtadSqbB48WJ77UKAcrlcmp6ergsA69atG97X+m7duqXb02vtTmhoqFVtbe0Dn9mTJ08WSCQSmYODg9zY2HikRCKRSSQS2enTpw17G9fu3bu7nZclNDTUisvljrp3796gTDRHExWKovrVlZoajE5Kwvu5uZjC4yHV2xshNjZg0XlRnmq3m5p0RiclifObmvqlJX7JkiXlJ06cyOyPuvqDdtZXra+++op39+5dnfT09JSMjIzU48ePZ5mbm6sAIDw83Ppxx/fll1/y6+rqHvjMPn36dHZ6enrqzp07b3t5edVpZ/adPHlyr6bjz8zM5H777bfdJirR0dE8uVxef/DgwWHd7TdQaKJCUVS/qFepsCYrC89fvYpShQIxrq44JpfDppMFC6mnz4bcXOuk2lqj9bm5Nv1RX0BAQJ2lpaWy5z0fFBUVZeru7i6RSqWycePGiQoKCjgqlQqOjo7yoqIiDqBpEXFwcJAXFRVxioqKOH5+fgK5XC6Vy+XSU6dOGQLAmjVrbKZNm+Y8atQoyYwZM5zbn6O4uFiHz+cr2K2LYAoEAoWlpaVq5cqVts3NzSyJRCKbOnWqc8eWkk2bNvHXrFljAwC//PKLgVgslonFYtmOHTvapvBXKpVYtmyZnVwul4pEItk///lPCwCIj4839vb2Fvv7+49wdnZ2nTp1qrNarcbHH39sVVpaquPr6ysaM2ZMj/MBdPV6v//+eyNti4tUKpVVVlayNmzYYJuYmGgkkUhkH330kVXHulJSUrgNDQ3s0NDQwqNHj7YlNNXV1axZs2Y5iUQimUgkkkVERAwDgOjoaBOZTCYVi8WysWPH9n3ugk7QMSoURfXJJ/n5GG1sfN8qxZ/k52N7fj4qlUost7HB9hEjYEpvOX5qeCclPTCt8AwLi4p1jo5l3PPnR7UwTFtz2KGSEstDJSWWHEIYha/v1eLmZs5rycmC9sde9vQc0FlhJ0+eXDdv3rx0FouFHTt2WISGhg7fu3fvnVmzZt376quveJs2bSo9fvy4iVQqbbSxsVEGBQU5r1mzpsTPz68uMzNT18/PT5iTk5MCAJmZmXqXLl1K77iC8oIFCyomTJggkUgkxuPHj69ZvHjxvRdeeKFx586dhREREVbp6empgKbrpKs433rrLad///vf+QEBAXXLli2z05Z/9tlnFqampqrk5OS0xsZGMnr0aElQUFANAKSlpelfv349x8nJSeHp6Sk5ffq00caNG0t37drFP3/+fIa1tXWPyd2yZcvsO3u9YWFhw8PDw2+/8sor9dXV1SwDAwP1li1bCsPCwvhnz57N6qyuyMhIs+nTp1f4+/vXvf3223oFBQUce3t75bp166xNTExUGRkZqQBQVlbGLioq4qxatcrp3Llz6RKJpKW/1iSif0koiuqT0cbGmJOaiqMyGeSGhpifmoqfq6pgz+XiuFyO8cMGpXWYGiDXPD2Tfa5fl1YplRwGAAFgxuEo37WzKx6smHJzc3WnTZtmV1ZWptPS0sKyt7dvBoAVK1aUT5061WXTpk2l+/bts1i8eHE5AFy4cMEkMzOzbSHCuro6dnV1NQsA/P39qzomKYCmBSUrKys5Li7O+OeffzaZMmWKODIyMvu1117r1arR5eXl7NraWnZAQEAdACxZsuTemTNnTAHgp59+MklPTzc4ceKEGaBZZDE1NVVPV1eXcXNzqxcIBAoAcHV1bcjOzu7zVM1dvd7nn3++7r333rOfM2dOxfz58ysFAkGPK0fHxMSYx8TEZLHZbEyZMqXywIEDZuvXry9LSEgwOXLkSI52P0tLS1VUVJSpt7d3rUQiaQEAPp+v6mvsnaGJCkVRfTLJzAzfSqV4LTkZSrUajQyDBXw+9ohE0GMPqUVdnxndtYDIjIxaAni8ysOlpZa6hDAKhiEB5uaVm5ycSgHAmstV9lcLSlZWlk5gYKAQ0KyC3NUKyqtWrXJ499137wYHB1fHx8cbh4aG2gCa1ZctLCyUJ06cML5+/bphbGxsDqC5Rf7q1atpBgYGDyQkhoaGXX5Y6+vrM3PmzKmZM2dODZ/PV8TExAzrmKhwOBxGrf6ziqamph6HVDAMQ8LCwvJnzpxZ0748Pj7emMvltsXIZrOhVCr7PLirq9e7devWu9OmTas+fvy46fjx4yXff/99t2OELl++rH/79m2uv7+/CAAUCgWxs7NrWb9+fZcrWw8EOkaFoqg+m2hmhmEcDhoZBsusrREpldIk5RlWplDoBPP5ZedGjkwL5vPLSltadAbiPC4uLgrtYNCukhRA0wLh4OCgAICIiIj71l5YsmRJ2dKlS52DgoIqOK3djz4+PjXbtm1rG39x8eJFffTg119/NcjLy9MBNONdbt68qe/o6NgCaJKT5uZmAgB2dnbKiooKzt27d9mNjY3kxx9/NAUACwsLlbGxserHH380ao2zbXzH5MmTq3ft2mWpreOPP/7g1tTUdPt5bGhoqNK2AvWkq9ebkpLC9fb2btyyZctdd3f3+uTkZD1TU1NVXV1dp/95IyMjeWvXri0qLCy8WVhYeLO0tPSPkpISnYyMDF1fX9+aTz/9tO0cZWVl7IkTJ9ZfvnzZWHt3VH91/dBEhaKoPjtfVYUGlQobHBxwrLwcZysrBzskagCd8vDIPiCV5o81NW08IJXmn/LwyH7UOoOCgpx9fHwkubm5XD6f7/7pp59adLZfU1MTi8/nu2t/PvzwQ/6GDRuK5s+fL3B1dZWam5vfN2Zj/vz51Q0NDeyQkJB72rI9e/YUXL161VAkEskEAoHr559/btlTfHfv3uW8+uqrLkKh0FUikbhyOBysW7euFACCg4PLpFKpbOrUqc5cLpdZu3Zt8ejRo6Xjx48Xubi4NGnr+Prrr/PeeecdB4lEImPajfNZvXp1uUQiaXJzc5MKhULXt99+21GhUHTbcrJo0aJyf3//Xg2m7er1fvLJJ1ba2611dHSYWbNmVXt7ezey2WxGLBY/MJg2NjaWN2fOnKr2ZQEBAZXffPMNb9u2bcVVVVVsoVDoKhaLZSdPnjS2sbFRhoeH502fPt1FLBbLpk+fPqKnWHuDMMwDLWFPJS8vLyYxMXGww6CoZ97Zysq2MSqTzMweeE49+dLS0iCVSgEAycnJDXK5PG2QQ+o3CQkJBqtXr7ZPSkoa0AG9VP+7ceOGhYeHh1PHctqiQlFUn1yprb0vKZlkZoajMhmu1PZqjCFFDZj169cPnzdvnmDr1q2Fgx0L1X/oYFqKovrk7w4OD5RNMjOjrSnUoNu6devdrVu33h3sOKj+RVtUKIqiKIp6YtFEhaIoiqKoJxZNVCiKop5C+Z/ko/Ls/XdbVZ6tRP4n+YMUEUUNDJqoUBRFPYWMRxsjdU5qW7JSebYSqXNSYTzaeJAjo6j+RRMViqKop5DZJDPIjsqQOicVuZtykTonFbKjMphNejoGNUdHR5s4OTnJHRwc5OvXrx/e2T4dF/x7XI4dO2aiXbzPwMDgOScnJ7lEIpFNnz7dqbd1hIeHm2snjOuMQqGAmZmZx8qVK237Jehn2IAmKoQQf0LILUJIFiFkXSfb1xBCUgkhfxBCfiaEOLbbpiKEXG/9OTGQcVIURT2NzCaZwWaFDW5vvg2bFTYDkqTkbMzhl8eV39dMUx5XbpyzMYf/sHUqlUqsXr3a4eTJkxkZGRkpx44d4yUlJek9erQPT6FQtD2eOXNmjXaGXLlc3hAZGZmTnp6e+t///jevt/UdPHjQIj8/v8tE5b///a+Js7Nzc1xcnFn7KfipBw1YokIIYQP4AkAAABmA+YQQWYfdrgHwYhjGHUA0gE/abWtkGGZk68/UgYqToijqaVV5thJFu4rg+IEjinYVPTBmpT+YjDFpSF+YPkKbrJTHlRunL0wfYTLGpOFh6zx37pyho6Njs0wma9HT02NmzJhRER0d3evVLMPCwizkcrlULBbL/Pz8BLW1tazKykqWra2tm3Za+oqKirbnKSkp3PHjxwtdXV2lnp6e4mvXrukBwMyZM51ef/11B3d3d8mKFSvsuj8rsHPnTp6bm5tUIpHIXn/9dUelUgmlUomZM2c6aWd8/eijj6z2799vlpycbLBw4cIREolEVldX98Css4cPH+atXLmyxMbGpuXnn3821JZHR0ebyGQyqVgslo0dO1YEANXV1axZs2Y5iUQimUgkkkVERAyplT8Hch4VbwBZDMPkAAAh5AiA1wCkandgGOZsu/1/B/DGAMZDURT1zNCOSdF29wybNOyhun/qttXpJmUmibvbR4evo0iZkSLUsdRRKMoUOnoCvabbm2/b3N58u9P9DeWGDZJ9koKu6isoKNC1tbVt0T63s7NruXTpklFvYw4ODq5cu3ZtOQC88847NuHh4RYbNmwoHTt2bO3Ro0dNFyxYULVv3z7elClTKrlcLrN06VLHPXv23HZzc2s+c+aM4YoVKxx+//33DAAoLi7WvXr1arp2XaCuXL16VS86OpqXmJiYzuVymTfeeMNh9+7d5h4eHo3FxcU6mZmZKYBm1WQLCwvVrl27rP71r38VTJgw4YGErqGhgVy4cMHkwIEDt6uqqtgHDx7kTZ48ub6oqIizatUqp3PnzqVLJJIW7Vo569atszYxMVFlZGSkApp1dXr7Xj0LBjJRsQXQ/h/qHQBjutn/LQD/1+65HiEkEYASwHaGYWI7HkAICQEQAgAOnUxCRVEU9ayqvVJ7X1KiHbNSe6W237uAOCYclY6ljqKluEVX11q3hWPCUfXrCfooKSlJf9OmTba1tbXs+vp6tq+vbzUAhISElP3v//7v8AULFlQdPHjQYu/evXnV1dWsa9euGc2ePVugPb6lpaWthWPGjBmVPSUpAPDDDz8YJycnG3h4eEgBzRpEVlZWyrlz51YVFBRwFy1aZB8UFFQ9ffr0mp7q+vbbb4c9//zztUZGRswbb7xROXLkSBulUllw7tw5Q29v71qJRNICAHw+XwUACQkJJkeOHMnRHm9paTmo7//j9kTMTEsIeQOAFwDfdsWODMMUEkJGADhDCLnJMMx9C2ExDLMHwB5As9bPYwuYoihqkDn8/cEvZ2aTzPqcpBi9b9Qil8u7XRdH291j+65tcck3JZaOHzgWWQRZPPSaCfb29i2FhYW62ud37tzRtbW1bTlz5ozhypUrHQHggw8+KPTy8mrs7PiQkBDn6OjorLFjxzaGh4ebnz9/3hgAXnnllfq//vWv3Pj4eGOVSkVGjx7dVFFRwTI2Nlamp6endlaXkZFRrwaIMAxDZs+efe+LL754YHr+5OTk1P/+978mu3fvtvz222953333XV53dR05coSXmJhoZGtr6wYA1dXV7Li4OJPexDEUDeRg2kIA9u2e27WW3YcQ8jKADQCmMgzTrC1nGKaw9XcOgHMAnhvAWCmKoqhOaJMUSaQkR/iZsEgSKclpP2blYfj6+tbn5eXppaen6zY1NZGYmBjezJkzq1588cV67SDW4ODg6q6Ob2hoYDk4OCiam5vJkSNHeO23zZs3796SJUuc33jjjXIA4PF4ajs7u5Z9+/aZAYBarcZvv/2m39eY/f39a+Lj480KCws5AFBSUsLOyMjQLS4u5qhUKixevLhq27ZthTdv3jQAACMjI1V1dfUDXTQVFRWsK1euGN25c+ePwsLCm4WFhTe3b9+eHxUVxZs4cWL95cuXjdPT03W152h9v2o+/fTTtpWNh1rXz0AmKlcACAkhzoQQXQDzANx39w4h5DkAX0KTpJS2KzcjhHBbH1vEb6SrAAAScUlEQVQAeAHtxrZQFEVRj0fNpRoDSaQkR9uCYhFkUSuJlOTUXKoxeNg6dXR0EBYWlu/v7y8SCoWu06ZNq/Dy8mrqbN/c3Fwun8931/7s27fPbN26dUXe3t5SLy8viVAovO+4t956615NTQ3nrbfeqtCWHT58OGf//v0WYrFYJhQKXY8dO9bnwaienp5NGzduLHzppZdEIpFI9uKLL4oKCgp08vLydHx8fMQSiUS2YMGCEaGhoXcAYOHCheV//etfHTsOpj106JDZuHHjavX19dt6AebNm1f1008/mZqZmanCw8Pzpk+f7iIWi2XTp08fAQDbtm0rrqqqYguFQlexWCw7efLkkJoshzDMwPWYEEKmAPgMABvAPoZhthBCQgEkMgxzghDyEwA3AMWth+QzDDOVEDIOmgRGDU0y9RnDMF93dy4vLy8mMTFxwF4LRVHUsyItLQ1SqRQAkJyc3CCXy9MGOaR+s3//frPjx48Pi42NzR3sWKi+uXHjhoWHh4dTx/IBHaPCMMxJACc7lG1q9/jlLo67CE0CQ1EURVG9smjRIvuzZ8+axsfHZw52LFT/eSIG01IURVHUo/rmm28KcP/dptQzgE6hT1EURVHUE4smKhRFURRFPbFookJRFEVR1BOLJioURVEURT2xaKJCURT1FGsubsY132tovtvc885PkOjoaBMnJye5g4ODfP369cM72+fWrVu6QqHQ9XHHBgC1tbWsqVOnOotEIplQKHT19PQUV1dXs8rLy9nbt2+37Gt98fHxxpMmTXJ52HjWrVvX6Xvk7u4ukUgkMmtrazczMzMPiUQik0gkslu3bul2tn9HFy9e1P/2229Nu9tnyZIl9lZWVu4q1eDM3E8TFYqiqKdY3uY8VP9ajbzQvAE9T9PtJp2k0UnipvymR75bVKlUYvXq1Q4nT57MyMjISDl27BgvKSlJrz/ifFgKheK+51u3brWysrJSZGRkpGZmZqbs27cvT1dXl7l37x7766+/tuqimgETHh5u3Vn5H3/8kZ6enp76/vvvFwUFBVVqZ/YVi8Utne3fUWJiosH333/fZaKiUqnwww8/DLO2tm4ZrInmaKJCURT1FErQT8A5cg7Fu4oBNVC8qxjnyDkk6CcMyPlyN+Ra1ybVGuWuz7V51LrOnTtn6Ojo2CyTyVr09PSYGTNmVERHR/d6ttiwsDALuVwuFYvFMj8/P0FtbS2rsrKSZWtr69bc3EwAzVT12ucpKSnc8ePHC11dXaWenp7ia9eu6QHAzJkznV5//XUHd3d3yYoVK+zan6O4uFjH1ta2LXvx8PBo1tfXZ9auXWtXUFDAlUgksmXLltl1bClZuHChQ3h4uDmgaTVydnZ2lclk0vavr6amhjV79mwnNzc3qVQqlR08eHAYAISHh5u/8sorgvHjxwsdHR3ly5cvtwOAlStX2jY3N7MkEols6tSpzj29P1293n379plpZ7f18vISNzU1kW3bttnExcWZSSQS2d69ex9YKOr77783FgqFjUuXLi2LiopqW66goKCAM3nyZIFYLJaJxWLZ6dOnDQHg888/NxeJRDKxWCybNm1aj7H2Bp1HhaIo6ik0JmcMst/LRnlsOdQNarAMWLCYbgHBvwQ9H9xBkneSuGOZxQyLCsd1jmXnuedHMS1M2xTwJYdKLEsOlVgSDmF8Fb5Xm4ubOcmvJd93Us/Lnt0uclhQUKBra2vb9o3fzs6u5dKlS0a9jTc4OLhy7dq15QDwzjvv2ISHh1ts2LChdOzYsbVHjx41XbBgQdW+fft4U6ZMqeRyuczSpUsd9+zZc9vNza35zJkzhitWrHD4/fffMwCguLhY9+rVq+kdV1AOCQkpDwwMFB0/ftxswoQJNW+//fY9Nze35rCwsDuBgYH62kUO4+PjO21laGhoIKtWrXI6ffr0LVdX1+bAwMAR2m3r16+3njRpUs13332XV15ezvby8pJOnTq1BgBSU1MNbty4kaqvr692cXGRv/feeyU7d+4sjIiIsOpqYcWOunq927dvtz516lSGs7Ozory8nK2np8e8//77RYmJiYaRkZH5ndUVFRXFmzNnTsX8+fOrNm/ebNvc3Ey4XC6zfPlyh/Hjx9du2rQpW6lUorq6mp2YmKj3r3/9y/q3335Lt7a2VmrXKnpUtEWFoijqKcS15oJtwoa6SQ2WHgvqJjXYJmxwh3P79Tye1zyTOWYcJbSpCgE4PI7S8QPHO/16oj5ISkrS9/T0FItEItmxY8fMU1JS9AAgJCSkLCIiwhwADh48aBESElJeXV3NunbtmtHs2bMFEolEtnLlSsfS0lIdbV0zZsyo7JikAMC4ceMac3Nzb65evfpuRUUFZ9y4cdKrV6/2unvq+vXrenZ2ds1ubm7NLBYLwcHB97Tbzp07Z/Lpp59aSyQSmY+Pj7i5uZlkZWXpAoCPj0+Nubm5ysDAgHFxcWnKzs7u0wXt7vV6eXnVBQcHO4WFhVkolcoe62pqaiJnzpwxff3116t4PJ565MiR9TExMSYAcPHiReO//e1vZQDA4XBgbm6u+vHHH02CgoIqra2tlQDA5/P7ZVALbVGhKIp6SilKFLBZbgObEBsU7SlCS3GvhiU8oLsWECOZUQsvgFdZerjUkugShlEwxDzAvNJpk1MpAHCtucqeWlA6sre3byksLGwb7Hnnzh1dW1vbljNnzhiuXLnSEQA++OCDQi8vr8bOjg8JCXGOjo7OGjt2bGN4eLj5+fPnjQHglVdeqf/rX//KjY+PN1apVGT06NFNFRUVLGNjY2VXrRFGRkbqruI0NTVVL1q0qGrRokVVCxcuxPHjx01ff/31yvb76OjoMGr1n1Vou566wzAMoqOjszw8PO4bAf3rr78a6urqti3Ax2azGYVC0WN97alUKnT1eqOiovLPnDljeOLECVNPT09ZUlJSty00MTExJrW1tWy5XO4KAI2NjSw9PT31/Pnzu1zZeiDQFhWKoqinlDxGDtEXIhh5GEH0hQjyGPmAnEdRptDhB/PLRp4bmcYP5pe1lLbo9HxU13x9fevz8vL00tPTdZuamkhMTAxv5syZVS+++GK9djBocHBwlx+GDQ0NLAcHB0VzczM5cuQIr/22efPm3VuyZInzG2+8UQ4APB5PbWdn17Jv3z4zAFCr1fjtt9/0e4rx1KlThmVlZWxA07KQkZGh5+Tk1GJqaqqqr69v++wUCATNWVlZ+o2NjaS8vJz966+/mgDAyJEjmwoLC3VTUlK4ANA+zkmTJtWEhYXxtQnOhQsXeoyHw+EwvUmCunu9KSkp3BdffLH+s88+KzIzM1Pm5OTompiYqOrq6jrNBQ4fPsz77LPPbhcWFt4sLCy8mZeXd/PXX381qa2tZb3wwgu1//znPy0BzeDoe/fusf38/Gri4uLM7t69ywYA2vVDURRFPRYepzyypQek+aZjTRulB6T5Hqc8sh+lPh0dHYSFheX7+/uLhEKh67Rp0yq8vLyaOts3NzeXy+fz3bU/+/btM1u3bl2Rt7e31MvLSyIUCu877q233rpXU1PDeeuttyq0ZYcPH87Zv3+/hVgslgmFQtdjx471OHA3IyND74UXXhCLRCKZXC6XjRw5smHRokWVw4cPV3l6etYJhULXZcuW2bm4uCiCgoIqJRKJ62uvvTbC1dW1AQAMDAyY//znP7cDAwNdZDKZ1MLCoq2vZfv27UVKpZJIJBKZi4uL68aNG217iic4OLhMKpX2ajBtV6939erVdtrbrUePHl33/PPPNwYEBNRmZGTodxxMW1tby0pISDCdPXt2lbbMxMRE7eXlVXfkyBHTXbt25Z8/f95Y+/5cu3ZNz8vLq2nt2rXF48ePl4jFYtnKlSvte4q1NwjDMD3v9RTw8vJiEhMTBzsMiqKoJ15aWhqkUikAIDk5uUEul6cNckj9Zv/+/WbHjx8fFhsbmzvYsVB9c+PGDQsPDw+njuV0jApFURT1TFi0aJH92bNnTePj4zMHOxaq/9BEhaIoinomfPPNNwUACgY7Dqp/0TEqFEVRFEU9sWiiQlEUNQQ9K+MTqWeDWq0mADq9VfyZ6fpJSkoqJ4TcfoQqTAH0573hD1tfX47rad9H2d7Zts7KLACUd3OOx+VZvH692aer7X0pp9fw4Y97Kq/hnj17XBobG/V0dHRUSqWyV4vXUdRAUavVpKyszBRAcmfbn5m7fh4VIWQPwzAhg11fX47rad9H2d7Zti7KEhmG8epNvAPpWbx+vdmnq+19KafX8OGPe1qvYVJSkhWHw/kKgBy0ZZ0afGoAyUqlcqmnp2dpx43PTItKP4h7Qurry3E97fso2zvb1t/vUX96Fq9fb/bpantfy58E9Bo+WnmvtX4YTH3UeijqcaAtKtQjeVK+jVMPj17Dpx+9htSzjDb5UY9qz2AHQD0yeg2ffvQaUs8s2qJCURRFUdQTi7aoUBRFURT1xKKJCkVRFEVRTyyaqFAURVEU9cSiiQrV7wghhoSQREJI4GDHQvUdIWQiIeQXQshuQsjEwY6H6jtCCIsQsoUQ8h9CyKLBjoeiHgVNVKgeEUL2EUJKCSHJHcr9CSG3CCFZhJB17Tb9D4CjjzdKqjt9vIYMgDoAegDuPO5Yqc718Rq+BsAOgAL0GlJPOXrXD9UjQsgEaD64IhmGkbeWsQFkAJgMzR/CKwDmA7AFYA7Nh1w5wzDxgxI0dZ8+XsN0hmHUhBA+gB0MwwQPUthUO328hlMBVDIM8yUhJJphmFmDFDZFPTI6My3VI4ZhEgghTh2KvQFkMQyTAwCEkCPQfIszAmAIQAagkRBykmGYTheaoh6fvlxDhmFSW7dXAuA+tiCpbvXx/2EBgJbWfVSPK0aKGgg0UaEeli00fwy17gAYwzDMKgAghCyGpkWFJilPrk6vISFkBgA/AMMAfD4YgVG91uk1BPBvAP8hhIwHkDAYgVFUf6GJCjUgGIaJGOwYqIfDMEwMgJjBjoN6eAzDNAB4a7DjoKj+QAfTUg+rEIB9u+d2rWXU04New6cfvYbUM48mKtTDugJASAhxJoToApgH4MQgx0T1Db2GTz96DalnHk1UqB4RQg4D+A2AmBByhxDyFsMwSgCrAPwIIA3AUYZhUgYzTqpr9Bo+/eg1pIYqensyRVEURVFPLNqiQlEURVHUE4smKhRFURRFPbFookJRFEVR1BOLJioURVEURT2xaKJCURRFUdQTiyYqFEVRFEU9sWiiQg0JhBCGEBLW7vl7hJAPH7HOw4SQPwghqx85QIqiKKpTNFGhhopmADMIIRbd7UQI6dX6V4SQ4QBGMwzjzjDMp/0RYF/OT1EUNVTQRIUaKpQA9gB4oPWDEBJBCNlNCLkE4JMO2/QIIfsJITcJIdcIIZNaN50CYEsIud66Qm1n9SUSQjIIIYGt5U6EkF8IIVdbf8a1lk9sLT8BILW1LJYQkkQISSGEhLSru44Q8s/W8p8IId6EkHOEkBxCyNTWfVwJIZdbY/uDECLsrzeRoijqcaPf3qih5AsAfxBCPulkmx2AcQzDqDqU/wUAwzCMGyFEAuAUIUQEYCqAeIZhRnZxLicA3gAEAM4SQlwAlAKYzDBMU2vycBiAV+v+owDIGYbJbX2+hGGYCkKIPoArhJBjDMPcA2AI4AzDMH8jhPwXwMcAJgOQAfgGmnVelgP4N8Mwh1rXf2H34T2iKIp6otBEhRoyGIapIYREAngHQGOHzd91kqQAgA+A/7Qen04IuQ1ABKCmh9MdZRhGDSCTEJIDQAIgF8DnhJCRAFSt9WhdbpekAMA7hJDprY/tAQgB3APQAuCH1vKbAJoZhlEQQm5CkxwBmvVgNhBC7ADEMAyT2UOsFEVRTyza9UMNNZ8BeAualon26vv5PB0X0WKg6XYqAeABTUuKbmfnJ4RMBPAygLEMw3gAuAZAr3WzgvlzgS41NGNv0JoUcVofR0HT4tMI4CQh5MV+e1UURVGPGU1UqCGFYZgKAEehSVZ64xcAwQDQ2uXjAOBWL46bTQhhEUIEAEa0HmMKoLg1qViArrtkTAFUMgzT0Nrd9HwvY0VrnCMA5DAMEw7gOAD3vhxPURT1JKGJCjUUhQHo9u6fdnYCYLV2rXwLYDHDMM29OC4fwGUA/wdgOcMwTa11LSKE3ICmK6irVpwfAHAIIWkAtgP4vZexas0BkEwIuQ5ADiCyj8f//3btmAZgIAaCYMyfRAAE5BcpQuCl7EszCFyuTgbImG9FBnaYmft6H22fv28BOJ1FBQDIsqgAAFkWFQAgS6gAAFlCBQDIEioAQJZQAQCyhAoAkLUAYyYy7mEn7o4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ8bObB6HUUe",
        "colab_type": "text"
      },
      "source": [
        "## Plot validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGPP-nfUpaeD",
        "colab_type": "code",
        "outputId": "a6b127a1-b3c6-4854-fb81-8c26c3906e6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.figure(1)\n",
        "\n",
        "plt.semilogx([0, 1000000], [ensemble_accs, ensemble_accs], '--y', label = \"Ensemble Val Acc\")\n",
        "\n",
        "plt.semilogx(layer5_params, layer5_accs, 'x--b', label = \"5-layer Val Acc\")\n",
        "plt.semilogx(layer5s_params, layer5s_accs, '*-b', label = \"5-layer Student Val Acc\")\n",
        "\n",
        "plt.semilogx(layer4_params, layer4_accs, 'x--k', label = \"4-Layer Val Acc\")\n",
        "plt.semilogx(layer4s_params, layer4s_accs, '*-k', label = \"4-Layer Student Val Acc\")\n",
        "\n",
        "plt.semilogx(layer3_params, layer3_accs, 'x--r', label = \"3-Layer Val Acc\")\n",
        "plt.semilogx(layer3s_params, layer3s_accs, '*-r', label = \"3-Layer Student Val Acc\")\n",
        "plt.semilogx(layer3s2_params, layer3s2_accs, 'x-r', label = \"3-Layer Student2 Val Acc\")\n",
        "\n",
        "plt.semilogx(layer2_params, layer2_accs, 'x--g', label = \"2-Layer Val Acc\")\n",
        "plt.semilogx(layer2s_params, layer2s_accs, '*-g', label = \"2-Layer Student Val Acc\")\n",
        "#plt.semilogx(layer2st_params[2], layer2st_accs[2], '*-g', label = \"2-Layer Student Special Val Acc\")\n",
        "\n",
        "plt.semilogx(layer1_params, layer1_accs, 'x--c', label = \"1-Layer Val Acc\")\n",
        "plt.semilogx(layer1s_params, layer1s_accs, '*-c', label = \"1-Layer Student Val Acc\")\n",
        "#plt.semilogx(layer1mod_params, layer1mod_accs, '*--y', label = \"1'-Layer more filters Val Acc\")\n",
        "\n",
        "plt.semilogx(layer0_params, layer0_accs, 'x--m', label = \"0-Layer Val Acc\")\n",
        "plt.semilogx(layer0s_params, layer0s_accs, '*-m', label = \"0-Layer Student Val Acc\")\n",
        "\n",
        "\n",
        "plt.xlabel(\"Nr of params\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(loc = \"upper right\", bbox_to_anchor = [1.5, 1])\n",
        "#plt.xlim([1000, 30000000])\n",
        "plt.savefig(l+\"Student_val\", dpi = 300, bbox_inches = \"tight\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCDttKz6x4Ag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvRVp8qsx5DX",
        "colab_type": "text"
      },
      "source": [
        "## k1c2, k2c1, k2c2 accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM_k8IaUejHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use test data on some models\n",
        "test_X = tf.convert_to_tensor(np.expand_dims(np.load(test_X_path)['arr_0'], -1))\n",
        "test_y = np.load(test_y_path)['arr_0']\n",
        "test_y = tf.one_hot(test_y, 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR9CROsvBkY3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "0c12d318-2919-49f0-d526-eef9b0c09baa"
      },
      "source": [
        "# k1c2\n",
        "\n",
        "custom_name = \"cnn_k1c2\"\n",
        "times = [\"20-05-12 00.00.33\", \"20-05-12 12.50.16\", \"20-05-17 09.06.11\"]\n",
        "res = [None] * len(times)\n",
        "for i, date_and_time in enumerate(times):\n",
        "  model_location = \"/content/drive/My Drive/DD2424Files/Results/\" + date_and_time + \"/models_\" + custom_name\n",
        "  my_model = tf.keras.models.load_model(model_location)\n",
        "  res[i] = my_model.evaluate(test_X, test_y)[1]\n",
        "print(res)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 1s 46ms/step - loss: 1.6545 - accuracy: 0.4338\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.7927 - accuracy: 0.4550\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.6160 - accuracy: 0.4350\n",
            "[0.4337500035762787, 0.45500001311302185, 0.4350000023841858]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdNjgvmmCep5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "534072ac-1f61-4f45-e266-62c84783faf5"
      },
      "source": [
        "# k2c1\n",
        "\n",
        "custom_name = \"cnn_k1c2_deep\"\n",
        "times = [\"20-05-17 11.01.32\", \"20-05-12 15.13.30\", \"20-05-12 15.39.49\"]\n",
        "res = [None] * len(times)\n",
        "for i, date_and_time in enumerate(times):\n",
        "  model_location = \"/content/drive/My Drive/DD2424Files/Results/\" + date_and_time + \"/models_\" + custom_name\n",
        "  my_model = tf.keras.models.load_model(model_location)\n",
        "  res[i] = my_model.evaluate(test_X, test_y)[1]\n",
        "print(res)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 5s 214ms/step - loss: 1.6959 - accuracy: 0.4200\n",
            "25/25 [==============================] - 5s 216ms/step - loss: 1.7264 - accuracy: 0.4187\n",
            "25/25 [==============================] - 5s 212ms/step - loss: 1.9696 - accuracy: 0.3625\n",
            "[0.41999998688697815, 0.41874998807907104, 0.36250001192092896]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kea7anRKC6pS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "519cdaec-3fa9-409d-857e-86bb19b732a6"
      },
      "source": [
        "# k2c1\n",
        "\n",
        "custom_name = \"cnn_k2c2_deep\"\n",
        "times = [\"20-05-12 17.26.19\", \"20-05-12 16.31.06\", \"20-05-12 16.55.20\"]\n",
        "res = [None] * len(times)\n",
        "for i, date_and_time in enumerate(times):\n",
        "  model_location = \"/content/drive/My Drive/DD2424Files/Results/\" + date_and_time + \"/models_\" + custom_name\n",
        "  my_model = tf.keras.models.load_model(model_location)\n",
        "  res[i] = my_model.evaluate(test_X, test_y)[1]\n",
        "print(res)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7595 - accuracy: 0.4275\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.5116 - accuracy: 0.5038\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.6160 - accuracy: 0.4563\n",
            "[0.42750000953674316, 0.5037500262260437, 0.45625001192092896]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dEr95Pm0DfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k1c2 = \"cnn_k1c2\"\n",
        "model_location = \"/content/drive/My Drive/DD2424Files/Results/\" + date_and_time + \"/models_\" + custom_name\n",
        "k1c2_00 = \"20-05-12 00.00.33\"\n",
        "k1c2_02 = \"20-05-12 12.50.16\"\n",
        "k1c2_04 = \"20-05-17 09.06.11\"\n",
        "\n",
        "k2c1 = \"k1c2_deep\"\n",
        "k2c1_00 = \"20-05-17 11.01.32\"\n",
        "k2c1_02 = \"20-05-12 15.13.30\"\n",
        "k2c1_04 = \"20-05-12 15.39.49\"\n",
        "\n",
        "k2c2 = \"k2c2_deep\"\n",
        "k2c2_00 = \"20-05-12 17.26.19\"\n",
        "k2c2_02 = \"20-05-12 16.31.06\"\n",
        "k2c2_04 = \"20-05-12 16.55.20\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InPQyZrQx8m6",
        "colab_type": "code",
        "outputId": "6c3d8e81-68db-450a-b93e-469f16c22880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "k1c2 = [0.4337500035762787, 0.45500001311302185, 0.4350000023841858]\n",
        "k2c1 = [0.41999998688697815, 0.41874998807907104, 0.36250001192092896]\n",
        "k2c2 = [0.42750000953674316, 0.5037500262260437, 0.45625001192092896]\n",
        "dropouts = [0, 0.2, 0.4]\n",
        "\n",
        "plt.figure(3973289)\n",
        "plt.plot(dropouts, k1c2, '-x', label = \"k1c2\")\n",
        "plt.plot(dropouts, k2c1, '-x', label = \"k2c1\")\n",
        "plt.plot(dropouts, k2c2, '-x', label = \"k2c2\")\n",
        "plt.xlabel(\"Dropout\")\n",
        "plt.ylabel(\"Test accuracy\")\n",
        "plt.ylim([0, 1])\n",
        "plt.xlim([0,0.5])\n",
        "plt.title(\"Accuracy of CNNs on FMA Small\")\n",
        "plt.legend()\n",
        "plt.savefig(\"dropout.png\", dpi = 300)\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz2DSNJ_z9Pd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}